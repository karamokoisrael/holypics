{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85770ba7",
   "metadata": {
    "papermill": {
     "duration": 0.111894,
     "end_time": "2022-04-21T18:17:11.661025",
     "exception": false,
     "start_time": "2022-04-21T18:17:11.549131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021446f",
   "metadata": {
    "papermill": {
     "duration": 0.104832,
     "end_time": "2022-04-21T18:17:11.875477",
     "exception": false,
     "start_time": "2022-04-21T18:17:11.770645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd494e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T18:17:12.099517Z",
     "iopub.status.busy": "2022-04-21T18:17:12.097986Z",
     "iopub.status.idle": "2022-04-21T18:17:12.102173Z",
     "shell.execute_reply": "2022-04-21T18:17:12.103295Z",
     "shell.execute_reply.started": "2022-04-21T15:43:34.260702Z"
    },
    "papermill": {
     "duration": 0.120043,
     "end_time": "2022-04-21T18:17:12.103669",
     "exception": false,
     "start_time": "2022-04-21T18:17:11.983626",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install PyQt5\n",
    "# !pip3 install ipywidgets\n",
    "# !pip3 install scikit-learn\n",
    "# !pip3 install tensorflow_addons\n",
    "# !pip3 install bs4\n",
    "# !pip3 install fake_useragent\n",
    "# !pip3 install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85766e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:43:34.279686Z",
     "iopub.status.busy": "2022-04-21T15:43:34.278058Z",
     "iopub.status.idle": "2022-04-21T15:44:31.537938Z",
     "shell.execute_reply": "2022-04-21T15:44:31.536776Z",
     "shell.execute_reply.started": "2022-04-21T15:43:34.279623Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-04-21T18:17:12.211798",
     "status": "running"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install fake_useragent\n",
    "!pip install imutils\n",
    "!pip install gdown\n",
    "!pip install kaggle --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d4158",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### import main dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a03f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:44:31.540200Z",
     "iopub.status.busy": "2022-04-21T15:44:31.539944Z",
     "iopub.status.idle": "2022-04-21T15:44:39.346863Z",
     "shell.execute_reply": "2022-04-21T15:44:39.345771Z",
     "shell.execute_reply.started": "2022-04-21T15:44:31.540172Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from fake_useragent import UserAgent\n",
    "from matplotlib.widgets import Button\n",
    "import datetime\n",
    "from tensorflow.keras import layers\n",
    "import pathlib\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import requests\n",
    "from IPython.display import clear_output\n",
    "from io import BytesIO\n",
    "from IPython.display import display, clear_output\n",
    "#from ipywidgets import interact\n",
    "#import ipywidgets as widgets\n",
    "from PIL import ImageFilter\n",
    "from bs4 import *\n",
    "import uuid\n",
    "from IPython.display import display, Markdown, clear_output, FileLink, FileLinks\n",
    "from IPython.display import Image as IImage \n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import gdown\n",
    "from random import randrange\n",
    "import ipywidgets as widgets\n",
    "import shutil\n",
    "from io import BytesIO\n",
    "import json\n",
    "import time\n",
    "import mimetypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6121aab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Defining main variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213da627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T16:11:37.091651Z",
     "iopub.status.busy": "2022-04-21T16:11:37.091314Z",
     "iopub.status.idle": "2022-04-21T16:11:37.099489Z",
     "shell.execute_reply": "2022-04-21T16:11:37.098278Z",
     "shell.execute_reply.started": "2022-04-21T16:11:37.091616Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUILD_NEW_DATASET = True\n",
    "REDUCE_DATASET_IMAGES = False\n",
    "USE_DATA_RELATIONSHIP = False\n",
    "DOWNLOAD_ADDITIONAL_IMAGES = False\n",
    "DEPLOY_DATASET_TO_SERVER = False\n",
    "USE_UPDATED_DATASET = True\n",
    "BASE_PATH = \"/kaggle/input/holipics-lite/\"\n",
    "DATASET_PATH = \"images_new\"\n",
    "STORE_PATH=\"save\"\n",
    "DATASET_COPY_PATH = STORE_PATH+\"/images_backup\"\n",
    "TEST_SET_PATH= \"test\"\n",
    "# DATASET_DUMP_PATH = BASE_PATH+(\"/images_backup_lite\" if BUILD_NEW_DATASET else \"/images_backup\")  \n",
    "DATASET_DUMP_PATH = \"images_backup_lite/images_backup_lite\" #if\"images_backup\"\n",
    "CSV_DATASET_PATH = \"image_dataset.csv\"\n",
    "IMAGE_RES = 224\n",
    "MODEL_PATH = \"models\"\n",
    "SAVED_MODEL_PATH = STORE_PATH + \"/\" + MODEL_PATH\n",
    "UNWATED_PATHS = []\n",
    "MAX_IMAGE_PER_CLASS = 2000 #3000\n",
    "MAX_IMAGE_PER_SEVERE_CLASS = 3000 #1500\n",
    "SEVERE_CLASSES = [\"general_not_nsfw_not_suggestive\"]\n",
    "DATASET_NAME = \"isralkaramoko/holipics-lite\"\n",
    "DATASET_URL = \"https://www.kaggle.com/\"+DATASET_NAME\n",
    "DATASET_ZIP = \"holipics-lite.zip\"\n",
    "MODEL_DOWNLOAD_URL = \"https://test.laboutiik.ci/api/public/dl/E4ZGx6fU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852e24f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Kaggle api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ea257",
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2022-04-21T15:44:39.360531Z",
     "iopub.status.busy": "2022-04-21T15:44:39.360007Z",
     "iopub.status.idle": "2022-04-21T15:44:43.179016Z",
     "shell.execute_reply": "2022-04-21T15:44:43.177796Z",
     "shell.execute_reply.started": "2022-04-21T15:44:39.360487Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "credentials = {\"username\":\"jamesdame\",\"key\":\"157e2681cd07fe2460010b340d5a7504\"}\n",
    "kaggle_key_store='kaggle.json'\n",
    "with open(kaggle_key_store, 'w', encoding='utf-8') as f:\n",
    "    json.dump(credentials, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "!rm -rf /root/.kaggle     # when I created the folder, it says the file or dir already exits\n",
    "!mkdir /root/.kaggle        # successful\n",
    "!mv kaggle.json /root/.kaggle/kaggle.json    # not sure if I have to use full destination path, I previously only used /root/.kaggle and it failed. Don't have time to validate this thought.\n",
    "!ls /root/.kaggle/kaggle.json\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504aef9e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce2cdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:44:43.181405Z",
     "iopub.status.busy": "2022-04-21T15:44:43.181143Z",
     "iopub.status.idle": "2022-04-21T15:44:43.256377Z",
     "shell.execute_reply": "2022-04-21T15:44:43.255714Z",
     "shell.execute_reply.started": "2022-04-21T15:44:43.181378Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preview_images_from_directory(path=\"images_new\", group=True):\n",
    "    dimensions=(IMAGE_RES, IMAGE_RES)\n",
    "    data_dir = path\n",
    "    clean_up_data_dir(data_dir)\n",
    "    images_path = []\n",
    "    \n",
    "    if(group):\n",
    "        data_sub_directories = os.listdir(data_dir)\n",
    "        for data_sub_directory in data_sub_directories:\n",
    "#             print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))\n",
    "            for current_dir in os.listdir(os.path.join(data_dir, data_sub_directory)):\n",
    "                images_path.append(os.path.join(data_sub_directory, current_dir))\n",
    "    else:\n",
    "        try:\n",
    "            for current_dir in os.listdir(data_dir):\n",
    "                images_path.append(os.path.join(data_dir, current_dir))\n",
    "        except Exception as wrong:\n",
    "            pass\n",
    "\n",
    "    if not group:\n",
    "        data_dir = \".\"\n",
    "        \n",
    "    current = 0        \n",
    "    output = widgets.Output()\n",
    "    next_button = widgets.Button(description='Next')\n",
    "    prev_button = widgets.Button(description='Prev')\n",
    "    display_current_button = widgets.Button(description='Current')\n",
    "    current_index_text = widgets.Textarea(\n",
    "        value=str(current),\n",
    "        placeholder='current index goes here',\n",
    "        description='index',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    display(current_index_text, display_current_button, prev_button, next_button, output)\n",
    "    \n",
    "    def default_action():\n",
    "        global current\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(\"{0}: {1}/{2}\".format(images_path[current].split(\"/\")[0], current+1, len(images_path)))\n",
    "            image = cv2.imread(os.path.join(data_dir, images_path[current]))\n",
    "            # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "            image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n",
    "            \n",
    "            current_image = Image.fromarray(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA))\n",
    "            display(current_image)\n",
    "            \n",
    "    def on_next_button_clicked(_):\n",
    "        global current\n",
    "        if current+2 > len(images_path):\n",
    "            return None\n",
    "        current+=1\n",
    "        default_action()\n",
    "\n",
    "\n",
    "    def on_prev_button_clicked(_):\n",
    "        global current\n",
    "        if current-1 < 0:\n",
    "            return None\n",
    "        current-=1\n",
    "        default_action()\n",
    "        \n",
    "        \n",
    "    def on_current_index_change(_):\n",
    "        update_index_change(current_index_text.value)\n",
    "\n",
    "    def update_index_change(indexString):\n",
    "        global current\n",
    "        try:\n",
    "            current = int(indexString)\n",
    "            default_action()\n",
    "        except Exception as wrong:\n",
    "            pass\n",
    "\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "    display_current_button.on_click(on_current_index_change)\n",
    "    current_index_text.on_displayed(update_index_change(str(current)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def order_images(main_dir, start=-1, end=-1, figsize=(30, 30), dimensions=(IMAGE_RES, IMAGE_RES)):\n",
    "    %matplotlib inline\n",
    "    from IPython.display import display, Markdown, clear_output\n",
    "    from IPython.display import Image as IImage \n",
    "    import ipywidgets as widgets\n",
    "\n",
    "    current  =  0\n",
    "    del_dir = os.path.join(main_dir, \".ipynb_checkpoints\")\n",
    "    !rm -r $del_dir\n",
    "    if start == -1 and end == -1:\n",
    "        images_path = os.listdir(main_dir)\n",
    "    elif start != -1 and end == -1:\n",
    "        images_path = os.listdir(main_dir)[start:len(os.listdir(main_dir))]\n",
    "    elif start == -1 and end != -1:\n",
    "        images_path = os.listdir(main_dir)[0:end]\n",
    "    else:\n",
    "        images_path = os.listdir(main_dir)\n",
    "        \n",
    "    next_button = widgets.Button(description='Next')\n",
    "    prev_button = widgets.Button(description='Prev')\n",
    "    move_button = widgets.Button(description='Move')\n",
    "    class_names = os.listdir(\"images_new/\")\n",
    "    moving_paths = []\n",
    "\n",
    "    path_selector = widgets.SelectMultiple(\n",
    "        options=class_names,\n",
    "        value=[],\n",
    "        description='Fruits',\n",
    "        disabled=False\n",
    "    )\n",
    "    output = widgets.Output()\n",
    "    display(prev_button, next_button, output, path_selector, move_button)\n",
    "\n",
    "    def on_next_button_clicked(_):\n",
    "        global current\n",
    "        if current+2 > len(images_path):\n",
    "            return None\n",
    "        moving_paths = []\n",
    "        with output:\n",
    "            current+=1\n",
    "            clear_output()\n",
    "            print(\"{0}/{1}\".format(current+1, len(images_path)))\n",
    "            pil_img = IImage(filename=os.path.join(main_dir, images_path[current]), width = dimensions[0], height=dimensions[1])\n",
    "            display(pil_img)\n",
    "\n",
    "    def on_prev_button_clicked(_):\n",
    "        global current\n",
    "        if current-1 < 0:\n",
    "            return None\n",
    "        moving_paths = []\n",
    "        with output:\n",
    "            current-=1\n",
    "            clear_output()\n",
    "            print(\"{0}/{1}\".format(current+1, len(images_path)))\n",
    "            pil_img = IImage(filename=os.path.join(main_dir, images_path[current]), width = dimensions[0], height=dimensions[1])\n",
    "            display(pil_img)\n",
    "    def on_move_button_clicked(_):\n",
    "        with output:\n",
    "            print(path_selector.value)\n",
    "            for current_path in path_selector.value:\n",
    "                os.system(\"cp '{0}' 'images_new/{1}'\".format(os.path.join(main_dir, images_path[current]), current_path))\n",
    "\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "    move_button.on_click(on_move_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075eb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:44:43.258751Z",
     "iopub.status.busy": "2022-04-21T15:44:43.258350Z",
     "iopub.status.idle": "2022-04-21T15:44:43.431779Z",
     "shell.execute_reply": "2022-04-21T15:44:43.430856Z",
     "shell.execute_reply.started": "2022-04-21T15:44:43.258719Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dump_dir = DATASET_DUMP_PATH\n",
    "def clean_up_data_dir(data_dir):\n",
    "    data_sub_directories = os.listdir(data_dir)\n",
    "    for data_sub_directory in data_sub_directories:\n",
    "        path_to_delete = os.path.join(data_dir, data_sub_directory, \".*\")\n",
    "        !rm -r $path_to_delete\n",
    "\n",
    "    !rm -r $data_dir/.ipynb_checkpoints\n",
    "    !rm -r $data_dir/.DS_Store\n",
    "\n",
    "# CREATE FOLDER\n",
    "def folder_create(images, given_folder_name=\"\"):\n",
    "    try:\n",
    "        folder_name = os.path.join(dump_dir, input(\"Enter Folder Name:- \") if given_folder_name == \"\" else given_folder_name)\n",
    "        # folder creation\n",
    "        os.mkdir(folder_name)\n",
    " \n",
    "    # if folder exists with that name, ask another name\n",
    "    except:\n",
    "        print(\"Folder Exist with that name!\")\n",
    "        folder_create()\n",
    " \n",
    "    # image downloading start\n",
    "    download_images(images, folder_name)\n",
    " \n",
    " \n",
    "# DOWNLOAD ALL IMAGES FROM THAT URL\n",
    "def download_images(images, folder_name):\n",
    "   \n",
    "    # initial count is zero\n",
    "    count = 0\n",
    " \n",
    "    # print total images found in URL\n",
    "    print(f\"Total {len(images)} Image Found!\")\n",
    " \n",
    "    # checking if images is not zero\n",
    "    if len(images) != 0:\n",
    "        for i, image in enumerate(images):\n",
    "            # From image tag ,Fetch image Source URL\n",
    " \n",
    "                        # 1.data-srcset\n",
    "                        # 2.data-src\n",
    "                        # 3.data-fallback-src\n",
    "                        # 4.src\n",
    " \n",
    "            # Here we will use exception handling\n",
    " \n",
    "            # first we will search for \"data-srcset\" in img tag\n",
    "            try:\n",
    "                # In image tag ,searching for \"data-srcset\"\n",
    "                image_link = image[\"src\"]\n",
    "                 \n",
    "            # then we will search for \"data-src\" in img\n",
    "            # tag and so on..\n",
    "            except:\n",
    "                try:\n",
    "                    # In image tag ,searching for \"data-src\"\n",
    "                    image_link = image[\"data-src\"]\n",
    "                except:\n",
    "                    try:\n",
    "                        # In image tag ,searching for \"data-fallback-src\"\n",
    "                        image_link = image[\"data-fallback-src\"]\n",
    "                    except:\n",
    "                        try:\n",
    "                            # In image tag ,searching for \"src\"\n",
    "                            image_link = image[\"data-srcset\"]\n",
    " \n",
    "                        # if no Source URL found\n",
    "                        except:\n",
    "                            pass\n",
    " \n",
    "            # After getting Image Source URL\n",
    "            # We will try to get the content of image\n",
    "            try:\n",
    "                print(\"Downloading image: {0}/{1}; store => {2}\".format(count, len(images), folder_name))\n",
    "                r = requests.get(image_link).content\n",
    "                try:\n",
    " \n",
    "                    # possibility of decode\n",
    "                    r = str(r, 'utf-8')\n",
    "                except UnicodeDecodeError:\n",
    " \n",
    "                    # After checking above condition, Image Download start\n",
    "                    with open(f\"{folder_name}/images{i+1}.jpg\", \"wb+\") as f:\n",
    "                        f.write(r)\n",
    " \n",
    "                    # counting number of image downloaded\n",
    "                    count += 1\n",
    "            except:\n",
    "                pass\n",
    " \n",
    "        # There might be possible, that all\n",
    "        # images not download\n",
    "        # if all images download\n",
    "        if count == len(images):\n",
    "            print(\"All Images Downloaded!\")\n",
    "             \n",
    "        # if all images not download\n",
    "        else:\n",
    "            print(f\"Total {count} Images Downloaded Out of {len(images)}\")\n",
    " \n",
    "# MAIN FUNCTION START\n",
    "def download_images_from_url(url, given_folder_name=\"\"):\n",
    "    if url == None or ( url.find(\"http\") == -1 and url.find(\"www\") == -1 ):\n",
    "        return\n",
    "    # content of URL\n",
    "    ua = UserAgent()\n",
    "\n",
    "    # Get list of user agents.\n",
    "\n",
    "\n",
    "    # headers = {'User-Agent': ua.random}\n",
    "    # r = requests.get(url, headers=headers)\n",
    "    r = requests.get(url)\n",
    "    print(url)\n",
    "    print(r)\n",
    "    # Parse HTML Code\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    " \n",
    "    # find all images in URL\n",
    "    images = soup.findAll('img')\n",
    " \n",
    "    # Call folder create function\n",
    "    folder_create(images, given_folder_name)\n",
    "\n",
    "def remove_duplicates(dir, include_src=False):\n",
    "    hashMap = {}\n",
    "    # List to store deleted files\n",
    "    deletedFiles = []\n",
    "    source_dup_file = []\n",
    "    filelist = os.listdir(dir)\n",
    "    for f in filelist:\n",
    "        f = os.path.join(dir, f)\n",
    "        key = hashFile(f)\n",
    "        # If key already exists, it deletes the file\n",
    "        if key in hashMap.keys():\n",
    "            deletedFiles.append(f)\n",
    "            if include_src:\n",
    "                try:\n",
    "                    index = source_dup_file.index(key)\n",
    "                except Exception as e:\n",
    "                    source_dup_file.append(key)\n",
    "            os.remove(f)\n",
    "        else:\n",
    "            hashMap[key] = f\n",
    "    if include_src:\n",
    "        for key in source_dup_file:\n",
    "            deletedFiles.append(f)\n",
    "            os.remove(hashMap[key])\n",
    "            \n",
    "    if len(deletedFiles) != 0:  \n",
    "        for deleted_file in deletedFiles:\n",
    "            print('Deleted Files {0}'.format(deleted_file))\n",
    "        print(\"total deleted => {}\".format(len(deletedFiles)))\n",
    "    else:\n",
    "        print('No duplicate files found')\n",
    "    \n",
    "\n",
    "def remove_small_files(dir, min_size=5):\n",
    "    for root, _, files in os.walk(dir):\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(root, f)\n",
    "            try:\n",
    "                if os.path.getsize(fullpath) < min_size * 1024:   #set file size in kb\n",
    "                    print(fullpath)\n",
    "                    os.remove(fullpath)\n",
    "            except Exception as e:\n",
    "                print(\"Error\" + fullpath)\n",
    "\n",
    "def rename_all_files(dir):\n",
    "    for root, _, files in os.walk(dir):\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(root, f)\n",
    "            try:\n",
    "                filename, file_extension = os.path.splitext(fullpath)\n",
    "                newname = str(uuid.uuid1())+\".\"+file_extension\n",
    "                os.rename(fullpath, os.path.join(dir, newname))\n",
    "           \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Error\" + fullpath)\n",
    "                \n",
    "def delete_unreadable_images(dir):\n",
    "    for root, _, files in os.walk(dir):\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(root, f)\n",
    "            try:\n",
    "                img = Image.open(fullpath)\n",
    "            except Exception as e:\n",
    "                os.system(\"rm {}\".format(fullpath))\n",
    "                print(\"Removing => \" + fullpath)\n",
    "\n",
    "def remove_randomly_dir_files(dir, limit=2, percentage=0):\n",
    "    files = os.listdir(dir)\n",
    "\n",
    "    if(percentage != 0):\n",
    "        limit = int((percentage * len(files)) / 100)\n",
    "\n",
    "    print(\"Total files found : {}\".format(len(files)))\n",
    "    deleted_indexes = [-1]\n",
    "    count = 0\n",
    "    if limit >= len(files):\n",
    "        print(\"limit >= len(files)\")\n",
    "        return \n",
    "\n",
    "    for i in range(0, limit):\n",
    "        if len(deleted_indexes) > limit:\n",
    "            print(\"len(deleted_index) > limit\")\n",
    "            break\n",
    "\n",
    "        random_index = -1\n",
    "\n",
    "        while ( random_index in deleted_indexes) == True:\n",
    "            random_index = random.randint(0, len(files)-1)\n",
    "\n",
    "        deleted_indexes.append(random_index)\n",
    "        count+=1\n",
    "\n",
    "        print(\"deleting {0}/{1}; index => {2}\".format(i+1, limit, random_index))\n",
    "        os.remove(os.path.join(dir, files[random_index]))\n",
    "\n",
    "    print(\"Total deleted files {}\".format(count))\n",
    "    print(\"Total files remaining {}\".format(len(os.listdir(dir))))\n",
    "    \n",
    "def hashFile(filename):\n",
    "    # For large files, if we read it all together it can lead to memory overflow, So we take a blocksize to read at a time\n",
    "    BLOCKSIZE = 65536\n",
    "    hasher = hashlib.md5()\n",
    "    with open(filename, 'rb') as file:\n",
    "        # Reads the particular blocksize from file\n",
    "        buf = file.read(BLOCKSIZE)\n",
    "        while(len(buf) > 0):\n",
    "            hasher.update(buf)\n",
    "            buf = file.read(BLOCKSIZE)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def predict_at_random_download(base_url=\"https://picsum.photos/{0}/{0}\".format(IMAGE_RES), store=DATASET_PATH, group=True):\n",
    "    selected_class = class_names[0]\n",
    "    selected_image = []\n",
    "    again_button = widgets.Button(description='Again')\n",
    "    download_button = widgets.Button(description='Download')\n",
    "    class_selector = widgets.Dropdown(\n",
    "        options=class_names,\n",
    "        value=selected_class,\n",
    "        description='Select a class',\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "    output = widgets.Output()\n",
    "    display(again_button, class_selector, download_button, output)\n",
    "\n",
    "    def on_again_button_clicked(_):\n",
    "        global selected_image\n",
    "        with output:\n",
    "            clear_output()\n",
    "            to_print, image = predict_single_image_from_url(base_url)\n",
    "            selected_image = image\n",
    "            print(to_print)\n",
    "            display(image)\n",
    "            \n",
    "    def on_download_button_clicked(_):\n",
    "        global selected_image\n",
    "        global selected_class\n",
    "        with output:\n",
    "            try:\n",
    "                if group:  \n",
    "                    export_path = \"{}.jpg\".format(os.path.join(store, selected_class, str(uuid.uuid1())))\n",
    "                else:\n",
    "                    export_path = \"{}.jpg\".format(os.path.join(store, str(uuid.uuid1())))\n",
    "                print(\"selected class => \", selected_class)\n",
    "                print(\"export path => \", export_path)\n",
    "                selected_image.save(export_path)\n",
    "                local_file = FileLink(export_path, result_html_prefix=\"Click here to download model: \")\n",
    "                display(local_file)\n",
    "            except Exception as wrong:\n",
    "                print(\"error while moving file to =>\", selected_class)\n",
    "                print(wrong)\n",
    "    def on_class_change(change):\n",
    "        global selected_class\n",
    "        try:\n",
    "            selected_class = class_names[change[\"new\"][\"index\"]]\n",
    "        except Exception as wrong:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    with output:\n",
    "        clear_output()\n",
    "        to_print, image = predict_single_image_from_url(base_url)\n",
    "        selected_image = image\n",
    "        print(to_print)\n",
    "        display(image)\n",
    "    \n",
    "    again_button.on_click(on_again_button_clicked)\n",
    "    download_button.on_click(on_download_button_clicked)\n",
    "    class_selector.observe(on_class_change)\n",
    "    \n",
    "def download_collection_from_unsplash(collection_id = \"500522\", selected_class=\"\", store=DATASET_COPY_PATH, group=True, perPage=10, page=1, image_width=IMAGE_RES, image_height=IMAGE_RES, fit=\"crop\", download_link=False):\n",
    "    api_key = '3E1O5xqWI-Opz3W81XdmIvZwPJ2qFTHggE5YUxZysDg'\n",
    "    url = \"https://api.unsplash.com/collections/{0}/photos?page={1}&per_page={2}\".format(collection_id, page, perPage)\n",
    "    # ua = UserAgent()\n",
    "    # headers = {'User-Agent': ua.random, 'Authorization': \"Client-ID {}\".format(api_key)}\n",
    "    headers = {\n",
    "        'Authorization': \"Client-ID {}\".format(api_key),\n",
    "        }\n",
    "    images = []\n",
    "    count = 0\n",
    "    total = 0\n",
    "    total_pages = 1\n",
    "    current_page = page\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url.format(collection_id, current_page, perPage), headers=headers)\n",
    "        total = int(response.headers['X-Total'])\n",
    "        \n",
    "        while(total_pages * perPage < total):\n",
    "            total_pages+=1\n",
    "    except Exception as wrong:\n",
    "        print(\"count error\")\n",
    "        print(wrong)\n",
    "        \n",
    "    while current_page <= total_pages:\n",
    "        print(\"processing page \", current_page, \"/\", total_pages)\n",
    "        try:\n",
    "            response = requests.get(url.format(collection_id, current_page, perPage), headers=headers)\n",
    "            response_json = response.json()\n",
    "            for image_data in response_json:\n",
    "                print(\"downloading image \",count+1, \"/\", total)\n",
    "                try:\n",
    "                    if group:  \n",
    "                        export_path = \"{}.jpg\".format(os.path.join(store, selected_class, str(uuid.uuid1())))\n",
    "                    else:\n",
    "                        export_path = \"{}.jpg\".format(os.path.join(store, str(uuid.uuid1())))\n",
    "                    image_response = requests.get(image_data[\"urls\"][\"raw\"]+\"&w={0}&h={1}&fit={2}\".format(image_width, image_height, fit))\n",
    "                    #raw,full, regular, small, thumb, small_s3    \n",
    "                    image = np.asarray(bytearray(image_response.content), dtype=\"uint8\")\n",
    "                    imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "                    imageRGB = cv2.cvtColor(imageBGR , cv2.COLOR_BGR2RGB)\n",
    "                    cv2.imwrite(export_path, imageBGR)\n",
    "                    if download_link:\n",
    "                        local_file = FileLink(export_path, result_html_prefix=\"Click here to download: \")\n",
    "                        display(local_file)            \n",
    "                except Exception as wrong:\n",
    "                    print(wrong)\n",
    "                    print(\"error while downloading image\")\n",
    "                count+=1\n",
    "        except Exception as wrong:\n",
    "            print(\"error while loading collections photos\")\n",
    "        current_page+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3f1a0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fae8ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T16:11:50.135368Z",
     "iopub.status.busy": "2022-04-21T16:11:50.134464Z",
     "iopub.status.idle": "2022-04-21T16:12:32.650763Z",
     "shell.execute_reply": "2022-04-21T16:12:32.649531Z",
     "shell.execute_reply.started": "2022-04-21T16:11:50.135319Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if USE_UPDATED_DATASET:\n",
    "    dwd_url = MODEL_DOWNLOAD_URL\n",
    "    splitted = dwd_url.split(\"/\")\n",
    "    dwd_file_name = splitted[len(splitted)-1]\n",
    "\n",
    "    !wget $dwd_url\n",
    "    !mv $dwd_file_name archive.zip\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(\"archive.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"./\")\n",
    "else:\n",
    "    !kaggle datasets download -d $DATASET_NAME\n",
    "    !unzip -n $DATASET_ZIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873435e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### creating directory architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab02df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:27.755392Z",
     "iopub.status.busy": "2022-04-21T15:45:27.754817Z",
     "iopub.status.idle": "2022-04-21T15:45:33.061854Z",
     "shell.execute_reply": "2022-04-21T15:45:33.060669Z",
     "shell.execute_reply.started": "2022-04-21T15:45:27.755355Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir $MODEL_PATH\n",
    "!mkdir $MODEL_PATH/epoch\n",
    "!mkdir $DATASET_PATH\n",
    "!mkdir $TEST_SET_PATH\n",
    "!mkdir $STORE_PATH\n",
    "!mkdir $DATASET_COPY_PATH\n",
    "!mkdir $SAVED_MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985cf19",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Moving files downloaded to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48bab96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:33.063777Z",
     "iopub.status.busy": "2022-04-21T15:45:33.063526Z",
     "iopub.status.idle": "2022-04-21T15:45:34.258708Z",
     "shell.execute_reply": "2022-04-21T15:45:34.257730Z",
     "shell.execute_reply.started": "2022-04-21T15:45:33.063751Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in os.listdir(DATASET_PATH):\n",
    "    cmd = \"rm -r {}/\".format(os.path.join(DATASET_PATH, path))\n",
    "    print(\"deleting => {}\".format(path))\n",
    "    os.system(cmd)\n",
    "    \n",
    "os.system(\"cp -r {1}/* {0}/ \".format(DATASET_PATH, DATASET_DUMP_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e16b3c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Delete unwanted paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6779e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:34.261687Z",
     "iopub.status.busy": "2022-04-21T15:45:34.261379Z",
     "iopub.status.idle": "2022-04-21T15:45:34.267543Z",
     "shell.execute_reply": "2022-04-21T15:45:34.266486Z",
     "shell.execute_reply.started": "2022-04-21T15:45:34.261651Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in UNWATED_PATHS:\n",
    "    cmd = \"rm -r {}/\".format(os.path.join(DATASET_PATH, path))\n",
    "    print(\"deleting => {}\".format(path))\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e628b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### resolving dataset relashionships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f139f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:34.270100Z",
     "iopub.status.busy": "2022-04-21T15:45:34.269130Z",
     "iopub.status.idle": "2022-04-21T15:45:34.282014Z",
     "shell.execute_reply": "2022-04-21T15:45:34.280690Z",
     "shell.execute_reply.started": "2022-04-21T15:45:34.270052Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_RELATIONSHIP = [\n",
    "    {\n",
    "        \"output\": \"male_sexy\",\n",
    "        \"classes\": [\"male_underwear\", \"male_shirtless\"]\n",
    "    },\n",
    "    {\n",
    "        \"output\": \"female_sexy\",\n",
    "        \"classes\": [\"female_swimwear\", \"female_underwear\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "cmds = [] #=> {\"label\": \"\", \"cmd\"}\n",
    "if USE_DATA_RELATIONSHIP:\n",
    "    for data_relationshp in DATA_RELATIONSHIP:\n",
    "        cmds.append({\n",
    "            \"label\": \"creating output dir => {}\".format(data_relationshp[\"output\"]),\n",
    "            \"cmd\": \"mkdir {0}/{1}\".format(DATASET_PATH, data_relationshp[\"output\"])\n",
    "        })\n",
    "\n",
    "        for current_class in data_relationshp[\"classes\"]:\n",
    "            cmds.append({\n",
    "                \"label\": \"copying images from {0} to {1}\".format(current_class, data_relationshp[\"output\"]),\n",
    "                \"cmd\": \"cp -r {0}/{1}/* {0}/{2}\".format(DATASET_PATH, current_class, data_relationshp[\"output\"])\n",
    "            })\n",
    "\n",
    "            cmds.append({\n",
    "                \"label\": \"removing {}\".format(current_class),\n",
    "                \"cmd\": \"rm -r {0}/{1}\".format(DATASET_PATH, current_class)\n",
    "            })\n",
    "        \n",
    "for cmd in cmds:\n",
    "    print(cmd[\"label\"])\n",
    "    os.system(cmd[\"cmd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57773b0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### adding more images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13992482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:34.283564Z",
     "iopub.status.busy": "2022-04-21T15:45:34.283192Z",
     "iopub.status.idle": "2022-04-21T15:45:34.297253Z",
     "shell.execute_reply": "2022-04-21T15:45:34.296632Z",
     "shell.execute_reply.started": "2022-04-21T15:45:34.283529Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "SUP_IMAGES_META = [\n",
    "    {\n",
    "        \"collection_ids\": [\"500522\", \"812584\", \"1450720\"],\n",
    "        \"class_name\": \"general_not_nsfw_not_suggestive\"\n",
    "    }\n",
    "]\n",
    "\n",
    "if DOWNLOAD_ADDITIONAL_IMAGES:\n",
    "    for sum_image_meta in SUP_IMAGES_META:\n",
    "        if not sum_image_meta[\"class_name\"] in os.listdir(DATASET_PATH):\n",
    "            print(\"skipping => \", sum_image_meta[\"class_name\"])\n",
    "            continue\n",
    "        for collection_id in sum_image_meta[\"collection_ids\"]:\n",
    "            print(\"downloading images for class => \", sum_image_meta[\"class_name\"], \"; collection_id => \", collection_id)\n",
    "            download_collection_from_unsplash(collection_id,sum_image_meta[\"class_name\"], store=DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b83bdda",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Handle image opening errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57296a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:34.299145Z",
     "iopub.status.busy": "2022-04-21T15:45:34.298811Z",
     "iopub.status.idle": "2022-04-21T15:45:36.707080Z",
     "shell.execute_reply": "2022-04-21T15:45:36.706199Z",
     "shell.execute_reply.started": "2022-04-21T15:45:34.299103Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_sub_directories = os.listdir(DATASET_PATH)\n",
    "for data_sub_directory in data_sub_directories:   \n",
    "    delete_unreadable_images(os.path.join(DATASET_PATH, data_sub_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fe690",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Preview Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c9964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:36.708745Z",
     "iopub.status.busy": "2022-04-21T15:45:36.708411Z",
     "iopub.status.idle": "2022-04-21T15:45:44.630180Z",
     "shell.execute_reply": "2022-04-21T15:45:44.629251Z",
     "shell.execute_reply.started": "2022-04-21T15:45:36.708703Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preview_images_from_directory(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81612a3f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Order Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc5df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:44.632756Z",
     "iopub.status.busy": "2022-04-21T15:45:44.632254Z",
     "iopub.status.idle": "2022-04-21T15:45:52.896462Z",
     "shell.execute_reply": "2022-04-21T15:45:52.894811Z",
     "shell.execute_reply.started": "2022-04-21T15:45:44.632713Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = DATASET_PATH\n",
    "clean_up_data_dir(data_dir)        \n",
    "data_sub_directories = os.listdir(data_dir)\n",
    "if REDUCE_DATASET_IMAGES:\n",
    "    for data_sub_directory in data_sub_directories:\n",
    "        files = os.listdir(os.path.join(data_dir, data_sub_directory))\n",
    "        total_image_num = len(files)\n",
    "        max_image = MAX_IMAGE_PER_SEVERE_CLASS if (data_sub_directory in SEVERE_CLASSES) else MAX_IMAGE_PER_CLASS\n",
    "        if total_image_num > max_image:\n",
    "            remove_randomly_dir_files(os.path.join(data_dir, data_sub_directory), limit=(total_image_num - max_image))        \n",
    "            print(\"found {0} for class {1}; removing {2}\".format(total_image_num, data_sub_directory, total_image_num - max_image))\n",
    "        else:\n",
    "            print(\"found {0} for class {1}; removing 0\".format(total_image_num, data_sub_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ce646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:52.900349Z",
     "iopub.status.busy": "2022-04-21T15:45:52.899371Z",
     "iopub.status.idle": "2022-04-21T15:45:53.589420Z",
     "shell.execute_reply": "2022-04-21T15:45:53.588066Z",
     "shell.execute_reply.started": "2022-04-21T15:45:52.900296Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_meta = {\n",
    "    \"female_nudity\": {\n",
    "        \"childs\":[\"general_nsfw\"]\n",
    "    },\n",
    "    \n",
    "#     \"general_nsfw\":{\n",
    "#         \"childs\": [\"female_nudity\"]\n",
    "#     },\n",
    "    \n",
    "#     \"female_underwear\":{\n",
    "#         \"childs\": [\"male_underwear\"]\n",
    "#     },\n",
    "#     \"male_underwear\":{\n",
    "#         \"childs\": [\"female_underwear\"]\n",
    "#     }\n",
    "}\n",
    "\n",
    "\n",
    "data_dir = DATASET_PATH\n",
    "data = []\n",
    "data_sub_directories = os.listdir(data_dir)\n",
    "for data_sub_directory in data_sub_directories:\n",
    "    files = os.listdir(os.path.join(data_dir, data_sub_directory))\n",
    "    for file in files:\n",
    "        file_meta = {}\n",
    "        file_meta[\"filenames\"]=os.path.join(data_sub_directory, file)\n",
    "        \n",
    "        class_childs = []\n",
    "        if data_sub_directory in classes_meta and USE_DATA_RELATIONSHIP:\n",
    "            class_childs = classes_meta[data_sub_directory][\"childs\"]\n",
    "\n",
    "        for current_class_name in data_sub_directories:\n",
    "            if current_class_name == data_sub_directory or current_class_name in class_childs:\n",
    "                file_meta[current_class_name] = str(1).replace(\".0\", \"\")                        \n",
    "            else:\n",
    "                file_meta[current_class_name] = str(0)\n",
    "        data.append(file_meta)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(CSV_DATASET_PATH, encoding='utf-8', index=False)\n",
    "\n",
    "print(\"done => \", len(data))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455af1e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:53.591052Z",
     "iopub.status.busy": "2022-04-21T15:45:53.590803Z",
     "iopub.status.idle": "2022-04-21T15:45:53.598978Z",
     "shell.execute_reply": "2022-04-21T15:45:53.597971Z",
     "shell.execute_reply.started": "2022-04-21T15:45:53.591013Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_file = FileLink(CSV_DATASET_PATH, result_html_prefix=\"Click here to download: \")\n",
    "display(local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd4adb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### reduce images  number for a custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f8719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:53.600897Z",
     "iopub.status.busy": "2022-04-21T15:45:53.600663Z",
     "iopub.status.idle": "2022-04-21T15:45:53.609776Z",
     "shell.execute_reply": "2022-04-21T15:45:53.609030Z",
     "shell.execute_reply.started": "2022-04-21T15:45:53.600870Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = DATASET_PATH\n",
    "# clean_up_data_dir(data_dir)\n",
    "# MAX_IMAGE_PER_CLASS = 1668\n",
    "# data_sub_directories = os.listdir(data_dir)\n",
    "# for unwanted_dir in UNWATED_PATHS:\n",
    "#     try:\n",
    "#         del data_sub_directories[data_sub_directories.index(unwanted_dir)]\n",
    "#     except Exception as e:\n",
    "#         pass\n",
    "\n",
    "# for data_sub_directory in data_sub_directories:\n",
    "#     files = os.listdir(os.path.join(data_dir, data_sub_directory))\n",
    "#     total_image_num = len(files)\n",
    "#     if total_image_num > MAX_IMAGE_PER_CLASS:\n",
    "#         remove_randomly_dir_files(os.path.join(data_dir, data_sub_directory), limit=(total_image_num - MAX_IMAGE_PER_CLASS))\n",
    "\n",
    "#         print(\"found {0} for class {1}; removing {2}\".format(total_image_num, data_sub_directory, total_image_num - MAX_IMAGE_PER_CLASS))\n",
    "#     else:\n",
    "#         print(\"found {0} for class {1}; removing 0\".format(total_image_num, data_sub_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09049e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### rename files in datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397dee61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:53.612055Z",
     "iopub.status.busy": "2022-04-21T15:45:53.611073Z",
     "iopub.status.idle": "2022-04-21T15:45:53.628970Z",
     "shell.execute_reply": "2022-04-21T15:45:53.627760Z",
     "shell.execute_reply.started": "2022-04-21T15:45:53.611997Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for data_sub_directory in data_sub_directories:\n",
    "#     print(\"1# renaming files in {}\".format(data_sub_directory))\n",
    "#     rename_all_files(os.path.join(data_dir, data_sub_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499491e4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Send data online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2bac78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:53.631019Z",
     "iopub.status.busy": "2022-04-21T15:45:53.630662Z",
     "iopub.status.idle": "2022-04-21T15:45:53.645170Z",
     "shell.execute_reply": "2022-04-21T15:45:53.643887Z",
     "shell.execute_reply.started": "2022-04-21T15:45:53.630989Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = DATASET_PATH\n",
    "# # clean_up_data_dir(data_dir)        \n",
    "# data_sub_directories = os.listdir(data_dir)\n",
    "# dataset_api_access_token = \"ZWbw9GYgHG616YljqLtfDK9FPwZ\"\n",
    "# dataset_id = \"5710a157-6e60-4818-a749-c577c85d8164\"\n",
    "# dataset_api_url = \"https://4tro8cx1.directus.app/{0}?access_token={1}\"\n",
    "# dataset_id = \"5710a157-6e60-4818-a749-c577c85d8164\"\n",
    "# if DEPLOY_DATASET_TO_SERVER:\n",
    "#     for data_sub_directory in data_sub_directories:\n",
    "#         files = os.listdir(os.path.join(data_dir, data_sub_directory))\n",
    "#         total_files = len(files)\n",
    "#         print(\"processing {0}: {1} files\".format(data_sub_directory, total_files))\n",
    "#         count = 1\n",
    "#         for file in files:\n",
    "#             try:\n",
    "#                 file_path = os.path.join(data_dir, data_sub_directory, file)\n",
    "#                 file_name = id\n",
    "#                 files = {'file': (os.path.basename(file_path), open(file_path, 'rb'), mimetypes.MimeTypes().guess_type(file_path)[0])}\n",
    "#                 r=requests.post(dataset_api_url.format(\"files\", dataset_api_access_token),files=files)\n",
    "#                 image_id = r.json()[\"data\"][\"id\"]\n",
    "#                 payload = json.dumps(\n",
    "#                     {\n",
    "#                     \"dataset_id\": dataset_id,\n",
    "#                     \"class_names\": [data_sub_directory],\n",
    "#                     \"image\": image_id,\n",
    "#                     \"export_path\": file_path \n",
    "#                     }\n",
    "#                 )\n",
    "#                 headers = {\"Content-Type\": 'application/json'}\n",
    "#                 r=requests.post(dataset_api_url.format(\"items/image_dataset_save\", dataset_api_access_token), data=payload, headers=headers)\n",
    "#                 print(\"success: {0}/{1}: {2} => {3}\".format(count, total_files, data_sub_directory, file_path))\n",
    "#             except Exception as e:\n",
    "#                 print(\"error: {0}/{1}: {2} => {3}\".format(count, total_files, data_sub_directory, file_path))\n",
    "#             count+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca26c78",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### log dataset state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e818638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:45:53.647079Z",
     "iopub.status.busy": "2022-04-21T15:45:53.646701Z",
     "iopub.status.idle": "2022-04-21T15:46:01.580339Z",
     "shell.execute_reply": "2022-04-21T15:46:01.578836Z",
     "shell.execute_reply.started": "2022-04-21T15:45:53.647032Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = DATASET_PATH\n",
    "clean_up_data_dir(data_dir)\n",
    "data_sub_directories = os.listdir(data_dir)\n",
    "for unwanted_dir in UNWATED_PATHS:\n",
    "    try:\n",
    "        del data_sub_directories[data_sub_directories.index(unwanted_dir)]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "for data_sub_directory in data_sub_directories:\n",
    "    print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b26bf2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d224742f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:46:01.583200Z",
     "iopub.status.busy": "2022-04-21T15:46:01.582913Z",
     "iopub.status.idle": "2022-04-21T15:46:01.594278Z",
     "shell.execute_reply": "2022-04-21T15:46:01.593346Z",
     "shell.execute_reply.started": "2022-04-21T15:46:01.583171Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEPLOY_DATASET_TO_SERVER:\n",
    "    os.system(\"cp {0} {1}\".format(CSV_DATASET_PATH, STORE_PATH)) \n",
    "    os.system(\"cp {0}/*.h5 {1}/\".format(MODEL_PATH, SAVED_MODEL_PATH))\n",
    "    for path in os.listdir(DATASET_PATH):\n",
    "        cmd = \"rm -r {}/\".format(os.path.join(DATASET_COPY_PATH, path))\n",
    "        print(\"deleting => {}\".format(path))\n",
    "        os.system(cmd)\n",
    "    os.system(\"cp -r {0}/* {1}\".format(DATASET_PATH, DATASET_COPY_PATH))\n",
    "    os.system(\"rm -r {0}/{1}\".format(STORE_PATH, DATASET_DUMP_PATH.split(\"/\")[0]))\n",
    "    os.system(\"cp -r {0} {1}/{2}\".format(DATASET_DUMP_PATH.split(\"/\")[0], STORE_PATH, DATASET_DUMP_PATH.split(\"/\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7738b87",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### updating kaggle dataset version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad2aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:46:01.596082Z",
     "iopub.status.busy": "2022-04-21T15:46:01.595748Z",
     "iopub.status.idle": "2022-04-21T15:46:01.609282Z",
     "shell.execute_reply": "2022-04-21T15:46:01.608324Z",
     "shell.execute_reply.started": "2022-04-21T15:46:01.596036Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEPLOY_DATASET_TO_SERVER:\n",
    "    !kaggle datasets status $DATASET_NAME\n",
    "    !kaggle datasets metadata -p $STORE_PATH $DATASET_NAME\n",
    "    save_path = 'updated_data_{}'.format(time.time())\n",
    "    !kaggle datasets version -p $STORE_PATH -m $save_path --dir-mode zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864d4d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### zip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a4a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T10:20:21.60741Z",
     "iopub.status.busy": "2022-03-30T10:20:21.606642Z",
     "iopub.status.idle": "2022-03-30T10:20:21.616435Z",
     "shell.execute_reply": "2022-03-30T10:20:21.615651Z",
     "shell.execute_reply.started": "2022-03-30T10:20:21.607226Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# os.system(\"cp -r {1}/* {0}/ \".format(DATASET_COPY_PATH, DATASET_DUMP_PATH))\n",
    "# shutil.make_archive(DATASET_COPY_PATH.split()[len(DATASET_COPY_PATH.split())-1], 'zip', DATASET_COPY_PATH)\n",
    "# local_file = FileLink(\"{0}.zip\".format(DATASET_COPY_PATH.split()[len(DATASET_COPY_PATH.split())-1]), result_html_prefix=\"Download dataset: \")\n",
    "# display(local_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ace8f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Training part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b62422",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72f52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:51:09.667885Z",
     "iopub.status.busy": "2022-04-21T15:51:09.667499Z",
     "iopub.status.idle": "2022-04-21T15:51:10.712128Z",
     "shell.execute_reply": "2022-04-21T15:51:10.711388Z",
     "shell.execute_reply.started": "2022-04-21T15:51:09.667852Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow_addons as tfa\n",
    "import pathlib\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "#from imutils.object_detection import non_max_suppression\n",
    "from PIL import Image \n",
    "import scipy\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from IPython.display import Image as IImage \n",
    "import ipywidgets as widgets\n",
    "from PIL import ImageFilter\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a618fce",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867c3348",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Test tensorflow gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144be88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:51:11.235657Z",
     "iopub.status.busy": "2022-04-21T15:51:11.235334Z",
     "iopub.status.idle": "2022-04-21T15:51:11.252774Z",
     "shell.execute_reply": "2022-04-21T15:51:11.252020Z",
     "shell.execute_reply.started": "2022-04-21T15:51:11.235620Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phisical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(phisical_devices)\n",
    "if len(phisical_devices) > 0: \n",
    "    tf.config.experimental.set_memory_growth(phisical_devices[0], True)\n",
    "    print(\"GPU activated with {}\".format(phisical_devices[0]))\n",
    "else:\n",
    "    print(\"No compatible GPU device found\")\n",
    "# print(tf.test.is_gpu_available())\n",
    "# print(tf.config.list_pZZzhysical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767f47",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05580a52",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Defining main variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b40399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T15:51:14.087657Z",
     "iopub.status.busy": "2022-04-21T15:51:14.086918Z",
     "iopub.status.idle": "2022-04-21T15:51:14.092800Z",
     "shell.execute_reply": "2022-04-21T15:51:14.091792Z",
     "shell.execute_reply.started": "2022-04-21T15:51:14.087619Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS=30\n",
    "PATIENCE=3\n",
    "LR = 1e-4\n",
    "dimensions = (IMAGE_RES, IMAGE_RES)\n",
    "batch_size = 32#32\n",
    "data_dir = DATASET_PATH\n",
    "csv_dataset = CSV_DATASET_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff66192",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0275bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T16:28:28.869272Z",
     "iopub.status.busy": "2022-04-21T16:28:28.868934Z",
     "iopub.status.idle": "2022-04-21T16:28:29.744842Z",
     "shell.execute_reply": "2022-04-21T16:28:29.743791Z",
     "shell.execute_reply.started": "2022-04-21T16:28:28.869232Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sliding_window(image, step, ws):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0] - ws[1], step):\n",
    "        for x in range(0, image.shape[1] - ws[0], step):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + ws[1], x:x + ws[0]])\n",
    "            \n",
    "def image_pyramid(image, scale=1.5, minSize=(IMAGE_RES, IMAGE_RES)):\n",
    "    # yield the original image\n",
    "    yield image\n",
    "    # keep looping over the image pyramid\n",
    "    while True:\n",
    "        # compute the dimensions of the next image in the pyramid\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width=w)\n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "        # yield the next image in the pyramid\n",
    "        yield image\n",
    "        \n",
    "def sub_plot_images(image, title,elem_place=1,show = True, figsize=(1, 1), plt_hspace = 0.8, vertical=1, horizontal=5):\n",
    "    if show:\n",
    "        if not figsize == (1, 1):\n",
    "            plt.figure(figsize=figsize)\n",
    "\n",
    "        plt.subplot(vertical,horizontal,elem_place)\n",
    "        plt.subplots_adjust(hspace = plt_hspace)\n",
    "        plt.title(title)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        \n",
    "def detect_adult_picture_from_url(url, prod=True, pass_neutral=True, figsize=(30, 30), WIDTH = 600, PYR_SCALE = 1.5, WIN_STEP = 16, ROI_SIZE = (250, 250), INPUT_SIZE = (IMAGE_RES, IMAGE_RES), probaLimit = 0.5):\n",
    "    req = requests.get(url, stream=True)\n",
    "    image = np.asarray(bytearray(req.content), dtype=\"uint8\")\n",
    "    imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    imageRGB = cv2.cvtColor(imageBGR , cv2.COLOR_BGR2RGB)\n",
    "    detect_adult_picture(imageRGB, prod, pass_neutral, figsize, WIDTH, PYR_SCALE, WIN_STEP, ROI_SIZE, INPUT_SIZE, probaLimit)\n",
    "    \"\"\"\n",
    "    image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "    image_loaded = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    \n",
    "    detect_adult_picture(image_loaded/255, prod, plotprocess)\n",
    "    \"\"\"\n",
    "    \n",
    "def predict_from_file_url(count_start=0, count_set = 10, src=\"validation-adult.txt\"):\n",
    "    figsize = (40, 40)\n",
    "    image_input_file = open(src, \"r\")\n",
    "    image_input_file = [image_input_fileS for image_input_fileS in image_input_file]\n",
    "    total = len(image_input_file)\n",
    "    \n",
    "    for url in image_input_file[count_start:count_set]:\n",
    "        try:\n",
    "            detect_adult_picture_from_url(url, True, False)\n",
    "        except Exception as wrong: \n",
    "            pass\n",
    "        \n",
    "def detect_adult_picture_from_array(array, prod=True, pass_neutral=True, figsize=(30, 30), WIDTH = 600, PYR_SCALE = 1.5, WIN_STEP = 16, ROI_SIZE = (250, 250), INPUT_SIZE = (IMAGE_RES, IMAGE_RES), probaLimit = 0.5):\n",
    "    detect_adult_picture(array, prod, pass_neutral, figsize, WIDTH, PYR_SCALE, WIN_STEP, ROI_SIZE, INPUT_SIZE, probaLimit)\n",
    "\n",
    "\n",
    "def calculate_average(pred):\n",
    "    if pred == 0:\n",
    "        return 1\n",
    "    elif pred < 0.5 and pred !=0:\n",
    "        return (0.5-pred)/0.5\n",
    "    elif pred >= 0.5 and pred !=1:\n",
    "         return (pred-0.5)/0.5\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def decode_prediction(predictions):\n",
    "    decoded_class_index = []\n",
    "    decode_prediction_precision = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        result = 0 if prediction < 0.5 else 1\n",
    "        precision = calculate_average(prediction)\n",
    "        decoded_class_index.append(result)\n",
    "        decode_prediction_precision.append(precision)\n",
    "    return np.array(decoded_class_index), np.array(decode_prediction_precision),predictions\n",
    "\n",
    "\n",
    "def detect_adult_picture(image, prod=True, pass_neutral=True, figsize=(30, 30), WIDTH = 600, PYR_SCALE = 1.5, WIN_STEP = 16, ROI_SIZE = (250, 250), INPUT_SIZE = (IMAGE_RES, IMAGE_RES), probaLimit = 0.5):\n",
    "    plt.figure(figsize=figsize)\n",
    "    orig = image\n",
    "    scanned = orig.copy()\n",
    "    neutral = scanned\n",
    "    orig = imutils.resize(orig, width=WIDTH)\n",
    "    \n",
    "    sub_plot_images(orig, \"input\", 1, prod)\n",
    "\n",
    "    \n",
    "    (H, W) = orig.shape[:2]\n",
    "    pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)\n",
    "    # initialize two lists, one to hold the ROIs generated from the image\n",
    "    # pyramid and sliding window, and another list used to store the\n",
    "    # (x, y)-coordinates of where the ROI was in the original image\n",
    "    rois = []\n",
    "    locs = []\n",
    "    # time how long it takes to loop over the image pyramid layers and\n",
    "    # sliding window locations\n",
    "    start = time.time()\n",
    "    for image in pyramid:\n",
    "    # determine the scale factor between the *original* image\n",
    "    # dimensions and the *current* layer of the pyramid\n",
    "        scale = W / float(image.shape[1])\n",
    "        # for each layer of the image pyramid, loop over the sliding\n",
    "        # window locations\n",
    "        for (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n",
    "            # scale the (x, y)-coordinates of the ROI with respect to the\n",
    "            # *original* image dimensions\n",
    "            x = int(x * scale)\n",
    "            y = int(y * scale)\n",
    "            w = int(ROI_SIZE[0] * scale)\n",
    "            h = int(ROI_SIZE[1] * scale)\n",
    "            # take the ROI and preprocess it so we can later classify\n",
    "            # the region using Keras/TensorFlow\n",
    "            roi = cv2.resize(roiOrig, INPUT_SIZE)\n",
    "            roi = img_to_array(roi)\n",
    "            roi = preprocess_input(roi)\n",
    "            # update our list of ROIs and associated coordinates\n",
    "            rois.append(roi)\n",
    "            locs.append((x, y, x + w, y + h))\n",
    "    end = time.time()\n",
    "    print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(\n",
    "        end - start))\n",
    "    # convert the ROIs to a NumPy array\n",
    "    rois = np.array(rois, dtype=\"float32\")\n",
    "    # classify each of the proposal ROIs using ResNet and then show how\n",
    "    # long the classifications took\n",
    "    print(\"[INFO] classifying ROIs...\")\n",
    "    start = time.time()\n",
    "    preds = model.predict(rois)\n",
    "    end = time.time()\n",
    "    print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
    "        end - start))\n",
    "    # decode the predictions and initialize a dictionary which maps class\n",
    "    # labels (keys) to any ROIs associated with that label (values)\n",
    "    #preds = tf.keras.applications.mobilenet_v2.decode_predictions(preds, top=5)\n",
    "    labels = {}\n",
    "    count = 0\n",
    "    tot = len(preds)\n",
    "    probaLimit = 0.5\n",
    "\n",
    "    for i in range(0, tot):\n",
    "        label = class_names[int(np.argmax(preds[count], axis=-1))]\n",
    "        prob = 1\n",
    "        if prob >= probaLimit:\n",
    "            box = locs[i]\n",
    "            L = labels.get(label, [])\n",
    "            L.append((box, prob))\n",
    "            labels[label] = L\n",
    "        count+=1\n",
    "        \n",
    "    for label in labels.keys():\n",
    "        # clone the original image so that we can draw on it\n",
    "        print(\"[INFO] showing results for '{}'\".format(label))\n",
    "        clone = orig.copy()\n",
    "        # loop over all bounding boxes for the current label\n",
    "        for (box, prob) in labels[label]:\n",
    "            # draw the bounding box on the image\n",
    "            (startX, startY, endX, endY) = box\n",
    "            cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "                (0, 255, 0), 2)\n",
    "        # show the results *before* applying non-maxima suppression, then\n",
    "        # clone the image again so we can display the results *after*\n",
    "        # applying non-maxima suppression\n",
    "        #plt.imshow(clone)\n",
    "        clone = orig.copy()\n",
    "    # extract the bounding boxes and associated prediction\n",
    "    # probabilities, then apply non-maxima suppression\n",
    "    boxes = np.array([p[0] for p in labels[label]])\n",
    "    proba = np.array([p[1] for p in labels[label]])\n",
    "    boxes = non_max_suppression(boxes, proba)\n",
    "    # loop over all bounding boxes that were kept after applying\n",
    "    # non-maxima suppression\n",
    "    \n",
    "    \n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # draw the bounding box and label on the image\n",
    "        cv2.rectangle(scanned, (startX, startY), (endX, endY),\n",
    "            (0, 255, 0), 2)\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.putText(scanned, label, (startX, y),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "        # show the output after apply non-maxima suppression\n",
    "        \n",
    "    sub_plot_images(scanned, \"scanned\", 2, prod)\n",
    "    \n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        if label==\"neutral\":\n",
    "            pass\n",
    "        else:\n",
    "            topLeft =  (startX, startY)\n",
    "            bottomRight = (endX, endY)\n",
    "            x, y = topLeft[0], topLeft[1]\n",
    "            w, h = bottomRight[0] - topLeft[0], bottomRight[1] - topLeft[1]\n",
    "\n",
    "            # Grab ROI with Numpy slicing and blur\n",
    "            ROI = clone[y:y+h, x:x+w]\n",
    "            blur = cv2.GaussianBlur(ROI, (51,51), 50) \n",
    "            clone[y:y+h, x:x+w] = blur\n",
    "            \n",
    "    sub_plot_images(clone, \"output\", 3, prod)\n",
    "    \n",
    "    \n",
    "def detect_adult_picture_no_plot(image, prod=True, pass_neutral=True, figsize=(30, 30), WIDTH = 600, PYR_SCALE = 1.5, WIN_STEP = 16, ROI_SIZE = (250, 250), INPUT_SIZE = (IMAGE_RES, IMAGE_RES), probaLimit = 0.8, ksize = (51,51)):\n",
    "    \n",
    "    main_ids, main_probs, main_preds =  decode_prediction(model.predict(np.array([cv2.resize(image, INPUT_SIZE)])))\n",
    "    if main_probs[0] > probaLimit :\n",
    "        return cv2.blur(image, ksize) \n",
    "    \n",
    "    orig = image\n",
    "    copy = orig.copy()\n",
    "    orig = imutils.resize(orig, width=WIDTH)\n",
    "    \n",
    "    (H, W) = orig.shape[:2]\n",
    "    pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)\n",
    "    # initialize two lists, one to hold the ROIs generated from the image\n",
    "    # pyramid and sliding window, and another list used to store the\n",
    "    # (x, y)-coordinates of where the ROI was in the original image\n",
    "    rois = []\n",
    "    locs = []\n",
    "    # time how long it takes to loop over the image pyramid layers and\n",
    "    # sliding window locations\n",
    "    start = time.time()\n",
    "    for image in pyramid:\n",
    "    # determine the scale factor between the *original* image\n",
    "    # dimensions and the *current* layer of the pyramid\n",
    "        scale = W / float(image.shape[1])\n",
    "        # for each layer of the image pyramid, loop over the sliding\n",
    "        # window locations\n",
    "        for (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n",
    "            # scale the (x, y)-coordinates of the ROI with respect to the\n",
    "            # *original* image dimensions\n",
    "            x = int(x * scale)\n",
    "            y = int(y * scale)\n",
    "            w = int(ROI_SIZE[0] * scale)\n",
    "            h = int(ROI_SIZE[1] * scale)\n",
    "            # take the ROI and preprocess it so we can later classify\n",
    "            # the region using Keras/TensorFlow\n",
    "            roi = cv2.resize(roiOrig, INPUT_SIZE)\n",
    "            roi = img_to_array(roi)\n",
    "            roi = preprocess_input(roi)\n",
    "            # update our list of ROIs and associated coordinates\n",
    "            rois.append(roi)\n",
    "            locs.append((x, y, x + w, y + h))\n",
    "    end = time.time()\n",
    "    print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(\n",
    "        end - start))\n",
    "    # convert the ROIs to a NumPy array\n",
    "    rois = np.array(rois, dtype=\"float32\")\n",
    "    # classify each of the proposal ROIs using ResNet and then show how\n",
    "    # long the classifications took\n",
    "    print(\"[INFO] classifying ROIs...\")\n",
    "    start = time.time()\n",
    "    preds = model.predict(rois)\n",
    "    end = time.time()\n",
    "    print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
    "        end - start))\n",
    "    # decode the predictions and initialize a dictionary which maps class\n",
    "    # labels (keys) to any ROIs associated with that label (values)\n",
    "    #preds = tf.keras.applications.mobilenet_v2.decode_predictions(preds, top=5)\n",
    "    labels = {}\n",
    "    tot = len(preds)\n",
    "    probaLimit = 0.5\n",
    "\n",
    "    for i in range(0, tot):\n",
    "        label = class_names[int(preds[i])]\n",
    "        prob = 1\n",
    "        box = locs[i]\n",
    "        L = labels.get(label, [])\n",
    "        L.append((box, prob))\n",
    "        labels[label] = L\n",
    "        \n",
    "    for label in labels.keys():\n",
    "        # clone the original image so that we can draw on it\n",
    "        print(\"[INFO] showing results for '{}'\".format(label))\n",
    "        clone = orig.copy()\n",
    "        # loop over all bounding boxes for the current label\n",
    "        for (box, prob) in labels[label]:\n",
    "            # draw the bounding box on the image\n",
    "            (startX, startY, endX, endY) = box\n",
    "            cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "                (0, 255, 0), 2)\n",
    "        # show the results *before* applying non-maxima suppression, then\n",
    "        # clone the image again so we can display the results *after*\n",
    "        # applying non-maxima suppression\n",
    "        #plt.imshow(clone)\n",
    "        clone = orig.copy()\n",
    "    # extract the bounding boxes and associated prediction\n",
    "    # probabilities, then apply non-maxima suppression\n",
    "    boxes = np.array([p[0] for p in labels[label]])\n",
    "    proba = np.array([p[1] for p in labels[label]])\n",
    "    boxes = non_max_suppression(boxes, proba)\n",
    "    # loop over all bounding boxes that were kept after applying\n",
    "    # non-maxima suppression\n",
    "    \n",
    "    \n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        if label==\"neutral\":\n",
    "            pass\n",
    "        else:\n",
    "            topLeft =  (startX, startY)\n",
    "            bottomRight = (endX, endY)\n",
    "            x, y = topLeft[0], topLeft[1]\n",
    "            w, h = bottomRight[0] - topLeft[0], bottomRight[1] - topLeft[1]\n",
    "\n",
    "            # Grab ROI with Numpy slicing and blur\n",
    "            ROI = clone[y:y+h, x:x+w]\n",
    "            blur = cv2.GaussianBlur(ROI, (51,51), 50) \n",
    "            clone[y:y+h, x:x+w] = blur\n",
    "            \n",
    "    return clone\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_batch(images):\n",
    "    predicted_indexes, confidences, predictions = decode_prediction(model.predict(np.array(images)))\n",
    "    predicted_labels = []\n",
    "    for predicted_index in predicted_indexes:\n",
    "        #print(predictions[i])\n",
    "        predicted_labels.append(class_names[predicted_index])\n",
    "        \n",
    "    return predicted_labels, confidences, predicted_indexes\n",
    "\n",
    "\n",
    "def predict_from_txt_urls(src='test-urls.txt', start=0, limit=10, figsize=(30, 30), verbose=False):\n",
    "    urls = []\n",
    "    \n",
    "    with open(src) as f:\n",
    "        lines = [line.rstrip() for line in f]\n",
    "        tot = len(lines)\n",
    "        count = 0\n",
    "        for url in lines[start:limit]:\n",
    "            count+=1\n",
    "            urls.append(url)\n",
    "            try:\n",
    "                if verbose:\n",
    "                    print(count, \"/\", tot, \"dwd => \", url)\n",
    "                \n",
    "            except Exception as wrong:\n",
    "                if verbose:\n",
    "                    print(count, \"/\", tot, \"error => \",wrong)\n",
    "                pass\n",
    "\n",
    "    predict_from_urls(urls, figsize=figsize, verbose=verbose)\n",
    "        \n",
    "        \n",
    "def predict_from_urls(urls, figsize=(30, 30), verbose=False):\n",
    "    images = []\n",
    "    tot = len(urls)\n",
    "    count=0\n",
    "    for url in urls:\n",
    "            count+=1\n",
    "            try:\n",
    "                if verbose:\n",
    "                    print(count, \"/\", tot, \"dwd => \", url)\n",
    "                req = requests.get(url, stream=True)\n",
    "                image = np.asarray(bytearray(req.content), dtype=\"uint8\")\n",
    "                imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "                imageRGB = cv2.cvtColor(imageBGR , cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                images.append(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255)\n",
    "            except Exception as wrong:\n",
    "                if verbose:\n",
    "                    print(count, \"/\", tot, \"error => \",wrong)\n",
    "                pass\n",
    "    predicted_labels, confidences, predicted_indexes = predict_batch(np.array(images))\n",
    "    \n",
    "    rangeTot = len(images)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    if len(images) == 1:\n",
    "        plt.title(predicted_labels[0]+\" \"+str(confidences[0]))\n",
    "        plt.imshow(images[0])\n",
    "    else:  \n",
    "        for i in range(rangeTot):\n",
    "            plt.subplot(rangeTot,int((rangeTot)/2),i+1)\n",
    "            plt.subplots_adjust(hspace = 0.8)\n",
    "            #color = \"blue\" if predicted_ids[i] == label_batch[i] else \"red\"\n",
    "            plt.title(predicted_labels[i]+\" \"+str(confidences[i]))#, color=color)\n",
    "            #plt.imshow(images[i]/255 if predicted_labels[i]==\"neutral\" else ndimage.gaussian_filter(images[i]/255, sigma=2))\n",
    "            plt.imshow(images[i])\n",
    "            \n",
    "def clean_up_data_dir():\n",
    "    data_sub_directories = os.listdir(data_dir)\n",
    "    for data_sub_directory in data_sub_directories:\n",
    "        path_to_delete = os.path.join(data_dir, data_sub_directory, \".*\")\n",
    "        !rm -r $path_to_delete\n",
    "\n",
    "    !rm -r $data_dir/.ipynb_checkpoints\n",
    "    !rm -r $data_dir/.DS_Store\n",
    "\n",
    "@tf.function\n",
    "def macro_soft_f1(y, y_hat):\n",
    "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
    "    Use probability values instead of binary predictions.\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        \n",
    "    Returns:\n",
    "        cost (scalar Tensor): value of the cost function for the batch\n",
    "    \"\"\"\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    y_hat = tf.cast(y_hat, tf.float32)\n",
    "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
    "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
    "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
    "    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
    "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
    "    return macro_cost\n",
    "@tf.function\n",
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which wse predict positive\n",
    "        \n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "def interpret_prediction(predicted_batch, get_images=False, image_set=[]):\n",
    "    # np_prediction = predicted_batch.numpy()\n",
    "    decoded_predictions = []\n",
    "    decoded_main_predictions_classes = []\n",
    "    max_indices = [(lambda pr: class_names[np.argmax(pr, axis=-1)])(predicton) for predicton in predicted_batch]\n",
    "    for count in range(0, len(predicted_batch)):\n",
    "        prd_btch = predicted_batch[count]\n",
    "        decoded_part = []\n",
    "        for i in range(0, num_classes):\n",
    "            decoded_prediction = {}\n",
    "            decoded_prediction[\"class_name\"] = class_names[i]\n",
    "            try:\n",
    "                decoded_prediction[\"probability\"] = prd_btch[i].numpy()\n",
    "            except Exception as e:\n",
    "                decoded_prediction[\"probability\"] = prd_btch[i]\n",
    "            decoded_prediction[\"precision\"] = np.sum(prd_btch[i]) / num_classes\n",
    "            \n",
    "            # decoded_prediction[\"count_index\"] = count\n",
    "        \n",
    "            if get_images:\n",
    "                decoded_prediction[\"image\"] = image_set[count]\n",
    "            decoded_part.append(decoded_prediction)\n",
    "        decoded_predictions.append(decoded_part)\n",
    "        \n",
    "        decoded_main_predictions_classes.append(decoded_part)\n",
    "    return decoded_predictions, decoded_main_predictions_classes, max_indices\n",
    "    \n",
    "\n",
    "def predict_single_image_from_path(path, break_line=True):\n",
    "    image = cv2.imread(path)\n",
    "    # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "    image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n",
    "    prediction = model.predict(np.array([image_resized]))\n",
    "    decoded_predictions, decoded_main_predictions_classes, max_indices = interpret_prediction(prediction)\n",
    "\n",
    "    # to_print = \"{0} \\n {1} \\n {2}\".format(decoded_predictions, decoded_main_predictions_classes, max_indices )\n",
    "    to_print = \"\"\n",
    "    for i in range(0, len(class_names)):\n",
    "         \n",
    "        try:\n",
    "            prob_str = str(prediction[0][i]*100)[0:5]\n",
    "        except Exception as wrong: \n",
    "              prob_str = str(prediction[0][i]*100)\n",
    "        str_ouput = \"{0} => {1}%; \\n\" if break_line else \"{0} => {1}%;\"\n",
    "        to_print  += str_ouput.format( class_names[i], prob_str)\n",
    "    # to_print = \"{0} \\n {1}\".format( class_names,  prediction )\n",
    "    return to_print, Image.fromarray(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA))\n",
    "\n",
    "def predict_single_raw_image(image, break_line=True):\n",
    "    prediction = model.predict(image)\n",
    "    decoded_predictions, decoded_main_predictions_classes, max_indices = interpret_prediction(prediction)\n",
    "\n",
    "    # to_print = \"{0} \\n {1} \\n {2}\".format(decoded_predictions, decoded_main_predictions_classes, max_indices )\n",
    "    to_print = \"\"\n",
    "    for i in range(0, len(class_names)):\n",
    "         \n",
    "        try:\n",
    "            prob_str = str(prediction[0][i]*100)[0:5]\n",
    "        except Exception as wrong: \n",
    "              prob_str = str(prediction[0][i]*100)\n",
    "        str_ouput = \"{0} => {1}%; \\n\" if break_line else \"{0} => {1}%;\"\n",
    "        to_print  += str_ouput.format( class_names[i], prob_str)\n",
    "    # to_print = \"{0} \\n {1}\".format( class_names,  prediction )\n",
    "    \n",
    "    return to_print, image\n",
    "\n",
    "\n",
    "def predict_single_image_from_url(url, break_line=True):\n",
    "    image = imutils.url_to_image(url)\n",
    "    # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "    image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n",
    "    prediction = model.predict(np.array([image_resized]))\n",
    "    decoded_predictions, decoded_main_predictions_classes, max_indices = interpret_prediction(prediction)\n",
    "\n",
    "    # to_print = \"{0} \\n {1} \\n {2}\".format(decoded_predictions, decoded_main_predictions_classes, max_indices )\n",
    "    to_print = \"\"\n",
    "    for i in range(0, len(class_names)):\n",
    "         \n",
    "        try:\n",
    "            prob_str = str(prediction[0][i]*100)[0:5]\n",
    "        except Exception as wrong: \n",
    "              prob_str = str(prediction[0][i]*100)\n",
    "        str_ouput = \"{0} => {1}%; \\n\" if break_line else \"{0} => {1}%;\"\n",
    "        to_print  += str_ouput.format( class_names[i], prob_str)\n",
    "    # to_print = \"{0} \\n {1}\".format( class_names,  prediction )\n",
    "    return to_print, Image.fromarray(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA))\n",
    "\n",
    "\n",
    "def predict_from_path(path=data_dir, group=True):\n",
    "    data_dir = path\n",
    "    clean_up_data_dir()\n",
    "    images_path = []\n",
    "    \n",
    "    if(group):\n",
    "        data_sub_directories = os.listdir(data_dir)\n",
    "        for data_sub_directory in data_sub_directories:\n",
    "            # images_path+=os.listdir(os.path.join(data_dir, data_sub_directory))\n",
    "            print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))\n",
    "            for current_dir in os.listdir(os.path.join(data_dir, data_sub_directory)):\n",
    "                images_path.append(os.path.join(data_sub_directory, current_dir))\n",
    "    else:\n",
    "        try:\n",
    "            for current_dir in os.listdir(data_dir):\n",
    "                images_path.append(os.path.join(data_dir, current_dir))\n",
    "        except Exception as wrong:\n",
    "            print(wrong)\n",
    "            pass\n",
    "\n",
    "    if not group:\n",
    "        data_dir = \".\"\n",
    "    \n",
    "    bulk_prediction(data_dir, images_path)\n",
    "    \n",
    "def bulk_prediction(data_dir=\"\", images_path=[], images=[]):\n",
    "    current = 0\n",
    "    output = widgets.Output()\n",
    "    next_button = widgets.Button(description='Next')\n",
    "    prev_button = widgets.Button(description='Prev')\n",
    "    display_current_button = widgets.Button(description='Current')\n",
    "    current_index_text = widgets.Textarea(\n",
    "        value=str(current),\n",
    "        placeholder='current index goes here',\n",
    "        description='index',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    display(current_index_text, display_current_button, prev_button, next_button, output)\n",
    "    \n",
    "    def default_action():\n",
    "        global current\n",
    "        with output:\n",
    "            clear_output()\n",
    "            images_store = images_path if len(images_path) > 0 else images\n",
    "            \n",
    "            print(\"{0}/{1}\".format(current+1, len(images_store)))\n",
    "            if len(images_path) > 0:\n",
    "                to_print, image = predict_single_image_from_path(os.path.join(data_dir, images_path[current]))\n",
    "            else:\n",
    "                to_print, image = predict_single_raw_image(images[current])\n",
    "            print(to_print)\n",
    "            display(image)\n",
    "            \n",
    "    def on_next_button_clicked(_):\n",
    "        global current\n",
    "        if current+2 > len(images_path):\n",
    "            return None\n",
    "        current+=1\n",
    "        default_action()\n",
    "\n",
    "\n",
    "    def on_prev_button_clicked(_):\n",
    "        global current\n",
    "        if current-1 < 0:\n",
    "            return None\n",
    "        current-=1\n",
    "        default_action()\n",
    "        \n",
    "        \n",
    "    def on_current_index_change(_):\n",
    "        update_index_change(current_index_text.value)\n",
    "\n",
    "    def update_index_change(indexString):\n",
    "        global current\n",
    "        try:\n",
    "            current = int(indexString)\n",
    "            default_action()\n",
    "        except Exception as wrong:\n",
    "            print(wrong)\n",
    "            pass\n",
    "\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "    display_current_button.on_click(on_current_index_change)\n",
    "    current_index_text.on_displayed(update_index_change(str(current)))\n",
    "    \n",
    "\n",
    "def predict_at_random(base_url=\"https://picsum.photos/{0}/{0}\".format(IMAGE_RES)):\n",
    "    again_button = widgets.Button(description='Again')\n",
    "    output = widgets.Output()\n",
    "    display(again_button, output)\n",
    "\n",
    "    def on_again_button_clicked(_):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            to_print, image = predict_single_image_from_url(base_url)\n",
    "            print(to_print)\n",
    "            display(image)\n",
    "    \n",
    "    with output:\n",
    "        clear_output()\n",
    "        to_print, image = predict_single_image_from_url(base_url)\n",
    "        print(to_print)\n",
    "        display(image)\n",
    "    \n",
    "    again_button.on_click(on_again_button_clicked)\n",
    "    \n",
    "    \n",
    "def predict_url_batch(urls, figsize=(30, 30), verbose=False, break_line=True):\n",
    "    predictions_output = []    \n",
    "    images=[]\n",
    "    for url in urls:\n",
    "        try:\n",
    "            image = imutils.url_to_image(url)\n",
    "            # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "            image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n",
    "            images.append(np.array([image_resized]))\n",
    "        except Exception as wrong:\n",
    "            pass\n",
    "    bulk_prediction(images=images)\n",
    "    \n",
    "def predict_from_txt_file(src='test-urls.txt', start=0, limit=10, figsize=(30, 30), verbose=False, break_line=True):\n",
    "    urls = []\n",
    "    with open(src) as f:\n",
    "        lines = [line.rstrip() for line in f]\n",
    "        tot = len(lines)\n",
    "        count = 0\n",
    "        for url in lines[start:limit]:\n",
    "            count+=1\n",
    "            urls.append(url)\n",
    "            try:\n",
    "                if verbose:\n",
    "                    print(count, \"/\", tot, \"dwd => \", url)       \n",
    "            except Exception as wrong:\n",
    "                if verbose:\n",
    "                    print(count, \"/\", tot, \"error => \",wrong)\n",
    "                pass\n",
    "    predict_url_batch(urls, figsize=figsize, verbose=verbose, break_line=break_line)\n",
    "    \n",
    "def predict_at_random_download(base_url=\"https://picsum.photos/{0}/{0}\".format(IMAGE_RES), store=DATASET_DUMP_PATH, group=True):\n",
    "    selected_class = class_names[0]\n",
    "    selected_image = []\n",
    "    again_button = widgets.Button(description='Again')\n",
    "    download_button = widgets.Button(description='Download')\n",
    "    class_selector = widgets.Dropdown(\n",
    "        options=class_names,\n",
    "        value=selected_class,\n",
    "        description='Select a class',\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "    output = widgets.Output()\n",
    "    display(again_button, class_selector, download_button, output)\n",
    "\n",
    "    def on_again_button_clicked(_):\n",
    "        global selected_image\n",
    "        with output:\n",
    "            clear_output()\n",
    "            to_print, image = predict_single_image_from_url(base_url)\n",
    "            selected_image = image\n",
    "            print(to_print)\n",
    "            display(image)\n",
    "            \n",
    "    def on_download_button_clicked(_):\n",
    "        global selected_image\n",
    "        global selected_class\n",
    "        with output:\n",
    "            try:\n",
    "                if group:  \n",
    "                    export_path = \"{}.jpg\".format(os.path.join(store, selected_class, str(uuid.uuid1())))\n",
    "                else:\n",
    "                    export_path = \"{}.jpg\".format(os.path.join(store, str(uuid.uuid1())))\n",
    "                print(\"selected class => \", selected_class)\n",
    "                print(\"export path => \", export_path)\n",
    "                selected_image.save(export_path)\n",
    "                local_file = FileLink(export_path, result_html_prefix=\"Click here to download model: \")\n",
    "                display(local_file)\n",
    "            except Exception as wrong:\n",
    "                print(\"error while moving file to =>\", selected_class)\n",
    "    def on_class_change(change):\n",
    "        global selected_class\n",
    "        try:\n",
    "            selected_class = class_names[change[\"new\"][\"index\"]]\n",
    "        except Exception as wrong:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    with output:\n",
    "        clear_output()\n",
    "        to_print, image = predict_single_image_from_url(base_url)\n",
    "        selected_image = image\n",
    "        print(to_print)\n",
    "        display(image)\n",
    "    \n",
    "    again_button.on_click(on_again_button_clicked)\n",
    "    download_button.on_click(on_download_button_clicked)\n",
    "    class_selector.observe(on_class_change)\n",
    "    \n",
    "def build_model_sequence(model_config, cleanup=True):\n",
    "    print(\"working on => \", model_config[\"name\"])\n",
    "    ### LOAD TRAINING DATASET\n",
    "    print(\"LOADING TRAINING DATASET FOR \", model_config[\"name\"])\n",
    "    if cleanup:\n",
    "        clean_up_data_dir()\n",
    "    df=pd.read_csv(csv_dataset)\n",
    "    \n",
    "    base_class_df = df[df[model_config[\"base_class\"]] == 1]\n",
    "    base_class_max_sample = model_config[\"base_class_max_sample\"] if model_config[\"base_class_max_sample\"] != -1 else base_class_df.count[\"filenames\"]\n",
    "    base_class_df = base_class_df[:base_class_max_sample]\n",
    "\n",
    "\n",
    "    general_class_df = df[df[general_class] == 1]\n",
    "    general_class_max_sample = model_config[\"general_class_max_sample\"] if model_config[\"general_class_max_sample\"] != -1 else general_class_df.count[\"filenames\"]\n",
    "    general_class_df = general_class_df[:general_class_max_sample]\n",
    "    \n",
    "    df = base_class_df.append(general_class_df).astype(str)\n",
    "    \n",
    "    display(df.describe())\n",
    "    \n",
    "    columns = []\n",
    "    for column in data_sub_directories:\n",
    "        if column == model_config[\"base_class\"] or column == general_class:\n",
    "            columns.append(column)\n",
    "            \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=model_config[\"featurewise_center\"],\n",
    "        samplewise_center=model_config[\"samplewise_center\"],\n",
    "        featurewise_std_normalization=model_config[\"featurewise_std_normalization\"],\n",
    "        samplewise_std_normalization=model_config[\"samplewise_std_normalization\"],\n",
    "        zca_whitening=model_config[\"zca_whitening\"],\n",
    "        zca_epsilon=model_config[\"zca_epsilon\"],\n",
    "        rotation_range=model_config[\"rotation_range\"],\n",
    "        width_shift_range=model_config[\"width_shift_range\"],\n",
    "        height_shift_range=model_config[\"height_shift_range\"],\n",
    "        brightness_range=model_config[\"brightness_range\"],\n",
    "        shear_range=model_config[\"shear_range\"],\n",
    "        zoom_range=model_config[\"zoom_range\"],\n",
    "        channel_shift_range=model_config[\"channel_shift_range\"],\n",
    "        fill_mode=model_config[\"fill_mode\"],\n",
    "        cval=model_config[\"cval\"],\n",
    "        horizontal_flip=model_config[\"horizontal_flip\"],\n",
    "        vertical_flip=model_config[\"vertical_flip\"],\n",
    "        rescale=model_config[\"rescale\"],\n",
    "        preprocessing_function=model_config[\"preprocessing_function\"],\n",
    "        data_format=model_config[\"data_format\"],\n",
    "        validation_split=model_config[\"validation_split\"]\n",
    "      )\n",
    "\n",
    "    training_set=train_datagen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory=data_dir,\n",
    "        x_col=\"filenames\",\n",
    "        y_col=model_config[\"base_class\"],\n",
    "        target_size=dimensions,\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=\"binary\",\n",
    "        subset=\"training\"\n",
    "    )\n",
    "\n",
    "    validation_set=train_datagen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory=data_dir,\n",
    "        x_col=\"filenames\",\n",
    "        y_col=model_config[\"base_class\"],\n",
    "        target_size=dimensions,\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=\"binary\",\n",
    "        subset=\"validation\"\n",
    "    )\n",
    "    \n",
    "    class_names = columns\n",
    "    num_classes = len(class_names)\n",
    "    num_samples = training_set.samples + validation_set.samples\n",
    "    files_per_class = []\n",
    "    for folder in os.listdir(data_dir):\n",
    "        if not os.path.isfile(folder):\n",
    "                files_per_class.append(len(os.listdir(data_dir + '/' + folder)))\n",
    "    total_files = sum(files_per_class)\n",
    "    class_weights = {}\n",
    "    for i in range(len(files_per_class)):\n",
    "        class_weights[i] = 1 - (float(files_per_class[i]) / total_files)\n",
    "    print (\"class_weights => \", class_weights)\n",
    "    \n",
    "    URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "    # URL = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
    "    try:\n",
    "        MODEL_BASE_NAME = model_config[\"name\"]\n",
    "    except Exception as e:\n",
    "        MODEL_BASE_NAME=\"model_\"\n",
    "    feature_extractor = hub.KerasLayer(URL,\n",
    "                                   input_shape=(IMAGE_RES, IMAGE_RES, 3))\n",
    "    feature_extractor.trainable = False\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    print(\"COMPILING MODEL: \", model_config[\"name\"])\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.RMSprop(learning_rate=LR),\n",
    "      loss=\"binary_crossentropy\",\n",
    "      metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    print(\"TRAINING MODEL: \", model_config[\"name\"])\n",
    "    steps_per_epoch = num_samples//model_config[\"batch_size\"]\n",
    "    checkpoint_filepath = 'models/epoch/chk.h5'\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    stop_training_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "\n",
    "        #min_delta=0,\n",
    "        patience=model_config[\"overfitting_patience\"],\n",
    "        #verbose=0,\n",
    "        #mode=\"auto\",\n",
    "        #baseline=None,\n",
    "        #restore_best_weights=False,\n",
    "    )\n",
    "\n",
    "    history = model.fit(training_set,\n",
    "                        epochs=model_config[\"epochs\"],\n",
    "#                         steps_per_epoch=model_config[\"steps_per_epoch\"],\n",
    "                        validation_data=validation_set,\n",
    "                        callbacks=[model_checkpoint_callback, stop_training_callback],\n",
    "                        # callbacks=[model_checkpoint_callback],\n",
    "#                         class_weight=class_weights\n",
    "                        )\n",
    "    MODELS[model_config[\"name\"]] = {\n",
    "        \"history\": history,\n",
    "        \"configs\": model_config,\n",
    "        \"df\": df,\n",
    "        \"model\": model,\n",
    "        \"class_names\": columns,\n",
    "        \"session_id\": SESSION_ID\n",
    "    }\n",
    "    \n",
    "def plot_training_history():\n",
    "    for model_config in models_config:\n",
    "        try:\n",
    "            model_data = MODELS[model_config[\"name\"]]\n",
    "            print(\"history for => \" , model_config[\"name\"])\n",
    "            history = model_data[\"history\"]\n",
    "            acc = history.history['accuracy']\n",
    "            val_acc = history.history['accuracy']\n",
    "            # acc = history.history['accuracy']\n",
    "            # val_acc = history.history['accuracy']\n",
    "\n",
    "            loss = history.history['loss']\n",
    "            val_loss = history.history['val_loss']\n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history.epoch, acc, label='Training Accuracy')\n",
    "            plt.plot(history.epoch, val_acc, label='Validation Accuracy')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.title('Training and Validation Accuracy')\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history.epoch, loss, label='Training Loss')\n",
    "            plt.plot(history.epoch, val_loss, label='Validation Loss')\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.title('Training and Validation Loss')\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "%matplotlib inline\n",
    "\n",
    "def sequence_predict_raw(image_array):\n",
    "    predictions = {}\n",
    "    to_print = \"\"\n",
    "    for model_name in MODELS.keys():\n",
    "        model_data = MODELS[model_name]\n",
    "        model = model_data[\"model\"]\n",
    "        prediction = model.predict(image_array)\n",
    "        class_name = model_data[\"configs\"][\"base_class\"]\n",
    "        predictions[class_name] = prediction[0][0]\n",
    "        try:\n",
    "            prob_str = str(prediction[0][0]*100)[0:5]\n",
    "        except Exception as wrong: \n",
    "              prob_str = str(prediction[0][0]*100)\n",
    "        to_print  += \"{0} => {1}%; \\n\".format( class_name, prob_str)\n",
    "    return to_print, predictions\n",
    "\n",
    "def sequence_predict_single_image_from_url(url):\n",
    "    image = imutils.url_to_image(url)\n",
    "    imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "    image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n",
    "    to_print, predictions = sequence_predict_raw(np.array([image_resized]))\n",
    "    return to_print, Image.fromarray(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA))\n",
    "\n",
    "def sequence_predict_single_image_from_path(path, break_line=True):\n",
    "    image = cv2.imread(path)\n",
    "    imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "    image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n",
    "    to_print, predictions = sequence_predict_raw(np.array([image_resized]))\n",
    "    return to_print, Image.fromarray(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA))\n",
    "\n",
    "def sequence_predict_single_raw_image(image, break_line=True):\n",
    "    to_print, predictions = sequence_predict_raw(image)\n",
    "    return to_print, image\n",
    "\n",
    "def sequence_predict_from_path(path=data_dir, group=True):\n",
    "    data_dir = path\n",
    "    clean_up_data_dir()\n",
    "    images_path = []\n",
    "    \n",
    "    if(group):\n",
    "        data_sub_directories = os.listdir(data_dir)\n",
    "        for data_sub_directory in data_sub_directories:\n",
    "            # images_path+=os.listdir(os.path.join(data_dir, data_sub_directory))\n",
    "            print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))\n",
    "            for current_dir in os.listdir(os.path.join(data_dir, data_sub_directory)):\n",
    "                images_path.append(os.path.join(data_sub_directory, current_dir))\n",
    "    else:\n",
    "        try:\n",
    "            for current_dir in os.listdir(data_dir):\n",
    "                images_path.append(os.path.join(data_dir, current_dir))\n",
    "        except Exception as wrong:\n",
    "            print(wrong)\n",
    "            pass\n",
    "\n",
    "    if not group:\n",
    "        data_dir = \".\"\n",
    "    \n",
    "    sequence_bulk_prediction(data_dir, images_path)\n",
    "    \n",
    "\n",
    "def sequence_bulk_prediction(data_dir=\"\", images_path=[], images=[]):\n",
    "    current = 0\n",
    "    output = widgets.Output()\n",
    "    next_button = widgets.Button(description='Next')\n",
    "    prev_button = widgets.Button(description='Prev')\n",
    "    display_current_button = widgets.Button(description='Current')\n",
    "    current_index_text = widgets.Textarea(\n",
    "        value=str(current),\n",
    "        placeholder='current index goes here',\n",
    "        description='index',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    display(current_index_text, display_current_button, prev_button, next_button, output)\n",
    "    \n",
    "    def default_action():\n",
    "        global current\n",
    "        with output:\n",
    "            clear_output()\n",
    "            images_store = images_path if len(images_path) > 0 else images\n",
    "            \n",
    "            print(\"{0}/{1}\".format(current+1, len(images_store)))\n",
    "            if len(images_path) > 0:\n",
    "                to_print, image = sequence_predict_single_image_from_path(os.path.join(data_dir, images_path[current]))\n",
    "            else:\n",
    "                to_print, image = sequence_predict_single_raw_image(images[current])\n",
    "            print(to_print)\n",
    "            display(image)\n",
    "            \n",
    "    def on_next_button_clicked(_):\n",
    "        global current\n",
    "        if current+2 > len(images_path):\n",
    "            return None\n",
    "        current+=1\n",
    "        default_action()\n",
    "\n",
    "\n",
    "    def on_prev_button_clicked(_):\n",
    "        global current\n",
    "        if current-1 < 0:\n",
    "            return None\n",
    "        current-=1\n",
    "        default_action()\n",
    "        \n",
    "        \n",
    "    def on_current_index_change(_):\n",
    "        update_index_change(current_index_text.value)\n",
    "\n",
    "    def update_index_change(indexString):\n",
    "        global current\n",
    "        try:\n",
    "            current = int(indexString)\n",
    "            default_action()\n",
    "        except Exception as wrong:\n",
    "            print(wrong)\n",
    "            pass\n",
    "\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "    display_current_button.on_click(on_current_index_change)\n",
    "    current_index_text.on_displayed(update_index_change(str(current)))\n",
    "    \n",
    "def sequence_predict_at_random(url=\"https://picsum.photos/{0}/{0}\".format(IMAGE_RES)):\n",
    "    again_button = widgets.Button(description='Again')\n",
    "    output = widgets.Output()\n",
    "    display(again_button, output)\n",
    "\n",
    "    def on_again_button_clicked(_):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            to_print, image = sequence_predict_single_image_from_url(base_url)\n",
    "            print(to_print)\n",
    "            display(image)\n",
    "    \n",
    "    with output:\n",
    "        clear_output()\n",
    "        to_print, image = sequence_predict_single_image_from_url(base_url)\n",
    "        print(to_print)\n",
    "        display(image)\n",
    "    \n",
    "    again_button.on_click(on_again_button_clicked)\n",
    "    \n",
    "    \n",
    "def sequence_predict_url_batch(urls, figsize=(30, 30), verbose=False, break_line=True):\n",
    "    predictions_output = []    \n",
    "    images=[]\n",
    "    for url in urls:\n",
    "        try:\n",
    "            image = imutils.url_to_image(url)\n",
    "            # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "            image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n",
    "            images.append(np.array([image_resized]))\n",
    "        except Exception as wrong:\n",
    "            pass\n",
    "    sequence_bulk_prediction(images=images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945935cb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465c2f3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-21T15:51:21.165917Z",
     "iopub.status.idle": "2022-04-21T15:51:21.166964Z",
     "shell.execute_reply": "2022-04-21T15:51:21.166699Z",
     "shell.execute_reply.started": "2022-04-21T15:51:21.166664Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_up_data_dir()\n",
    "data_sub_directories = os.listdir(data_dir)\n",
    "for data_sub_directory in data_sub_directories:\n",
    "    print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b9b0e6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Creating model sequence config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d99bd36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T16:55:23.159473Z",
     "iopub.status.busy": "2022-04-21T16:55:23.158861Z",
     "iopub.status.idle": "2022-04-21T16:55:23.187099Z",
     "shell.execute_reply": "2022-04-21T16:55:23.186330Z",
     "shell.execute_reply.started": "2022-04-21T16:55:23.159422Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SESSION_ID = str(time.time()).replace(\".\", \"_\")\n",
    "MODELS = {\n",
    "    \n",
    "}\n",
    "\n",
    "os.system(\"mkdir {0}/{1}\".format(MODEL_PATH, SESSION_ID))\n",
    "general_class = \"general_not_nsfw_not_suggestive\"\n",
    "models_config = [\n",
    "    {\n",
    "        \"name\": \"nsfw_detector\",\n",
    "        \"base_class\": \"general_nsfw\",\n",
    "        \"batch_size\": 32,\n",
    "        \"overfitting_patience\": 1,\n",
    "        \"epochs\": 30,\n",
    "        \"lr\": 0.0001,\n",
    "        \"base_class_max_sample\": 2000,\n",
    "        \"general_class_max_sample\": 2000,\n",
    "        \"featurewise_center\": False,\n",
    "        \"samplewise_center\": False,\n",
    "        \"featurewise_std_normalization\": False,\n",
    "        \"samplewise_std_normalization\": False,\n",
    "        \"zca_whitening\": False,\n",
    "        \"zca_epsilon\": 1e-06,\n",
    "        \"rotation_range\": 0,\n",
    "        \"width_shift_range\": 0.0,\n",
    "        \"height_shift_range\": 0.0,\n",
    "        \"brightness_range\": None,\n",
    "        \"shear_range\": 0.0,\n",
    "        \"zoom_range\": 0.0,\n",
    "        \"channel_shift_range\": 0.0,\n",
    "        \"fill_mode\": 'nearest',\n",
    "        \"cval\": 0.0,\n",
    "        \"horizontal_flip\": False,\n",
    "        \"vertical_flip\": False,\n",
    "        \"rescale\": 1./255,\n",
    "        \"preprocessing_function\": None,\n",
    "        \"data_format\": None,\n",
    "        \"validation_split\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"male_shirtless_detector\",\n",
    "        \"base_class\": \"male_shirtless\",\n",
    "        \"batch_size\": 32,\n",
    "        \"overfitting_patience\": 1,\n",
    "        \"epochs\": 30,\n",
    "        \"lr\": 0.0001,\n",
    "        \"base_class_max_sample\": 429,\n",
    "        \"general_class_max_sample\": 429,\n",
    "        \"featurewise_center\": False,\n",
    "        \"samplewise_center\": False,\n",
    "        \"featurewise_std_normalization\": False,\n",
    "        \"samplewise_std_normalization\": False,\n",
    "        \"zca_whitening\": False,\n",
    "        \"zca_epsilon\": 1e-06,\n",
    "        \"rotation_range\": 20,\n",
    "        \"width_shift_range\": 0.0,\n",
    "        \"height_shift_range\": 0.0,\n",
    "        \"brightness_range\": None,\n",
    "        \"shear_range\": 0.1,\n",
    "        \"zoom_range\": 0.2,\n",
    "        \"channel_shift_range\": 0.0,\n",
    "        \"fill_mode\": 'nearest',\n",
    "        \"cval\": 0.0,\n",
    "        \"horizontal_flip\": True,\n",
    "        \"vertical_flip\": True,\n",
    "        \"rescale\": 1./255,\n",
    "        \"preprocessing_function\": None,\n",
    "        \"data_format\": None,\n",
    "        \"validation_split\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"female_swimwear_detector\",\n",
    "        \"base_class\": \"female_swimwear\",\n",
    "        \"batch_size\": 32,\n",
    "        \"overfitting_patience\": 1,\n",
    "        \"epochs\": 30,\n",
    "        \"lr\": 0.0001,\n",
    "        \"base_class_max_sample\": 747,\n",
    "        \"general_class_max_sample\": 747,\n",
    "        \"featurewise_center\": False,\n",
    "        \"samplewise_center\": False,\n",
    "        \"featurewise_std_normalization\": False,\n",
    "        \"samplewise_std_normalization\": False,\n",
    "        \"zca_whitening\": False,\n",
    "        \"zca_epsilon\": 1e-06,\n",
    "        \"rotation_range\": 20,\n",
    "        \"width_shift_range\": 0.0,\n",
    "        \"height_shift_range\": 0.0,\n",
    "        \"brightness_range\": None,\n",
    "        \"shear_range\": 0.1,\n",
    "        \"zoom_range\": 0.2,\n",
    "        \"channel_shift_range\": 0.0,\n",
    "        \"fill_mode\": 'nearest',\n",
    "        \"cval\": 0.0,\n",
    "        \"horizontal_flip\": True,\n",
    "        \"vertical_flip\": True,\n",
    "        \"rescale\": 1./255,\n",
    "        \"preprocessing_function\": None,\n",
    "        \"data_format\": None,\n",
    "        \"validation_split\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"female_nudity_detector\",\n",
    "        \"base_class\": \"female_nudity\",\n",
    "        \"batch_size\": 32,\n",
    "        \"overfitting_patience\": 1,\n",
    "        \"epochs\": 30,\n",
    "        \"lr\": 0.0001,\n",
    "        \"base_class_max_sample\": 2000,\n",
    "        \"general_class_max_sample\": 2000,\n",
    "        \"featurewise_center\": False,\n",
    "        \"samplewise_center\": False,\n",
    "        \"featurewise_std_normalization\": False,\n",
    "        \"samplewise_std_normalization\": False,\n",
    "        \"zca_whitening\": False,\n",
    "        \"zca_epsilon\": 1e-06,\n",
    "        \"rotation_range\": 0,\n",
    "        \"width_shift_range\": 0.0,\n",
    "        \"height_shift_range\": 0.0,\n",
    "        \"brightness_range\": None,\n",
    "        \"shear_range\": 0.0,\n",
    "        \"zoom_range\": 0.0,\n",
    "        \"channel_shift_range\": 0.0,\n",
    "        \"fill_mode\": 'nearest',\n",
    "        \"cval\": 0.0,\n",
    "        \"horizontal_flip\": False,\n",
    "        \"vertical_flip\": False,\n",
    "        \"rescale\": 1./255,\n",
    "        \"preprocessing_function\": None,\n",
    "        \"data_format\": None,\n",
    "        \"validation_split\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"female_underwear_detector\",\n",
    "        \"base_class\": \"female_underwear\",\n",
    "        \"batch_size\": 32,\n",
    "        \"overfitting_patience\": 1,\n",
    "        \"epochs\": 30,\n",
    "        \"lr\": 0.0001,\n",
    "        \"base_class_max_sample\": 2000,\n",
    "        \"general_class_max_sample\": 2000,\n",
    "        \"featurewise_center\": False,\n",
    "        \"samplewise_center\": False,\n",
    "        \"featurewise_std_normalization\": False,\n",
    "        \"samplewise_std_normalization\": False,\n",
    "        \"zca_whitening\": False,\n",
    "        \"zca_epsilon\": 1e-06,\n",
    "        \"rotation_range\": 0,\n",
    "        \"width_shift_range\": 0.0,\n",
    "        \"height_shift_range\": 0.0,\n",
    "        \"brightness_range\": None,\n",
    "        \"shear_range\": 0.0,\n",
    "        \"zoom_range\": 0.0,\n",
    "        \"channel_shift_range\": 0.0,\n",
    "        \"fill_mode\": 'nearest',\n",
    "        \"cval\": 0.0,\n",
    "        \"horizontal_flip\": False,\n",
    "        \"vertical_flip\": False,\n",
    "        \"rescale\": 1./255,\n",
    "        \"preprocessing_function\": None,\n",
    "        \"data_format\": None,\n",
    "        \"validation_split\": 0.2\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b34bdd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Build model sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847c96f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T16:55:24.270840Z",
     "iopub.status.busy": "2022-04-21T16:55:24.270510Z",
     "iopub.status.idle": "2022-04-21T17:18:38.214930Z",
     "shell.execute_reply": "2022-04-21T17:18:38.214050Z",
     "shell.execute_reply.started": "2022-04-21T16:55:24.270805Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model_config in models_config:\n",
    "    build_model_sequence(model_config, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540a19f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### display training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d229f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T17:18:38.217431Z",
     "iopub.status.busy": "2022-04-21T17:18:38.216883Z",
     "iopub.status.idle": "2022-04-21T17:18:39.964833Z",
     "shell.execute_reply": "2022-04-21T17:18:39.963528Z",
     "shell.execute_reply.started": "2022-04-21T17:18:38.217383Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e35ea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## setup server settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20194cee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = DATASET_PATH\n",
    "# clean_up_data_dir(data_dir)        \n",
    "dataset_api_access_token = \"ZWbw9GYgHG616YljqLtfDK9FPwZ\"\n",
    "dataset_id = \"5710a157-6e60-4818-a749-c577c85d8164\"\n",
    "dataset_api_url = \"https://4tro8cx1.directus.app/{0}?access_token={1}\"\n",
    "dataset_id = \"5710a157-6e60-4818-a749-c577c85d8164\"\n",
    "headers = {\"Content-Type\": 'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dc6520",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Backup project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558184e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model_name in [*MODELS]:\n",
    "    model_data = MODELS[model_name]\n",
    "    try:\n",
    "        file_path = \"{0}/{1}/{2}.h5\".format(MODEL_PATH, SESSION_ID, model_name)\n",
    "        print(\"backup => \", model_name)\n",
    "        model_data[\"model\"].save(file_path)\n",
    "        local_file = FileLink(file_path, result_html_prefix=\"Click here to download model({0}/{1}) \".format(SESSION_ID, model_name))\n",
    "        display(local_file)\n",
    "        file_name = \"{0}_{1}\".format(SESSION_ID, model_name)\n",
    "        files = {'file': (os.path.basename(file_path), open(file_path, 'rb'), mimetypes.MimeTypes().guess_type(file_path)[0])}\n",
    "        r=requests.post(dataset_api_url.format(\"files\", dataset_api_access_token),files=files)\n",
    "        file_id = r.json()[\"data\"][\"id\"]\n",
    "        payload = json.dumps(\n",
    "            {\n",
    "            \"name\": model_name,\n",
    "            \"dataset_id\": dataset_id,\n",
    "            \"file\": file_id,\n",
    "            \"session_id\": SESSION_ID,\n",
    "            \"config\": model_data[\"configs\"]\n",
    "            }\n",
    "        )\n",
    "        headers = {\"Content-Type\": 'application/json'}\n",
    "        r=requests.post(dataset_api_url.format(\"items/models\", dataset_api_access_token), data=payload, headers=headers)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdad777",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Restore project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2572b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T05:37:22.297545Z",
     "iopub.status.busy": "2022-03-30T05:37:22.297064Z",
     "iopub.status.idle": "2022-03-30T05:37:50.779607Z",
     "shell.execute_reply": "2022-03-30T05:37:50.778566Z",
     "shell.execute_reply.started": "2022-03-30T05:37:22.297509Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_id = SESSION_ID\n",
    "!mkdir $MODEL_PATH/$session_id\n",
    "!rm -r $MODEL_PATH/$session_id/*\n",
    "\n",
    "for model_config in models_config:\n",
    "    try:\n",
    "        r=requests.get(dataset_api_url.format(\"items/models\", dataset_api_access_token+\"&filter[name][_eq]={}&sort=sort,-date_created\".format(model_config[\"name\"])), headers=headers)\n",
    "        model_backup = r.json()[\"data\"][0]\n",
    "        print(\"found => \", model_backup[\"name\"])\n",
    "        r = requests.get(dataset_api_url.format(\"assets/{}\".format(model_backup[\"file\"]), dataset_api_access_token), headers=headers, allow_redirects=True)\n",
    "        model_path = \"{0}/{1}/{2}.h5\".format(MODEL_PATH, session_id, model_backup[\"name\"])\n",
    "        open(model_path, 'wb').write(r.content)\n",
    "        model = tf.keras.models.load_model(\n",
    "              model_path, \n",
    "              custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "      \n",
    "        MODELS[model_backup[\"name\"]] = {\n",
    "            \"configs\": model_backup[\"config\"],\n",
    "            \"model\": model,\n",
    "            \"session_id\": session_id\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b07e803",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### image prediction on model sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903159d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_predict_from_path(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3915fe2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_predict_at_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d115c21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_predict_at_random(\"https://random.imagecdn.app/{0}/{0}\".format(IMAGE_RES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b09a24",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "category = \"woman\"\n",
    "# https://loremflickr.com\n",
    "# https://lorempixel.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95990526",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_predict_at_random(\"https://source.unsplash.com/category/{0}\".format(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf6085",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unsplash collections => https://unsplash.com/s/collections/people\n",
    "collections = [\n",
    "    \"8909560\",\n",
    "    \"1242151\", #https://unsplash.com/collections/1242151/sexy\n",
    "    \"1785701\",\n",
    "    \"8991200\", #https://unsplash.com/collections/8991200/sexy\n",
    "    \"5052004\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd35606",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_predict_at_random(\"https://source.unsplash.com/collection/{}\".format(collections[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0461e0d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_predict_at_random(\"https://source.unsplash.com/collection/{}\".format(collections[randrange(len(collections)-1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e868e1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Sample image prediction on single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50d4b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_model_name = \"nsfw_detector\"\n",
    "\n",
    "model_data = MODELS[current_model_name]\n",
    "\n",
    "model = model_data[\"model\"]\n",
    "\n",
    "class_names = []\n",
    "for class_name in data_sub_directories:\n",
    "    if class_name == model_data[\"configs\"][\"base_class\"] or class_name == general_class:\n",
    "        class_names.append(class_name)\n",
    "\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fcdb8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_from_path(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be890593",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_at_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06caab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_at_random(\"https://random.imagecdn.app/{0}/{0}\".format(IMAGE_RES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309dc3a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "category = \"woman\"\n",
    "# https://loremflickr.com\n",
    "# https://lorempixel.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b2af9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_at_random(\"https://source.unsplash.com/category/{0}\".format(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c64e64",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unsplash collections => https://unsplash.com/s/collections/people\n",
    "collections = [\n",
    "    \"8909560\",\n",
    "    \"1242151\", #https://unsplash.com/collections/1242151/sexy\n",
    "    \"1785701\",\n",
    "    \"8991200\", #https://unsplash.com/collections/8991200/sexy\n",
    "    \"5052004\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc888c16",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_at_random(\"https://source.unsplash.com/collection/{}\".format(collections[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa9c07",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_at_random(\"https://source.unsplash.com/collection/{}\".format(collections[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed76aa8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_at_random(\"https://source.unsplash.com/collection/{}\".format(collections[randrange(len(collections)-1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36d75e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### create more data by prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825809f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7049b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T20:34:15.966878Z",
     "iopub.status.busy": "2022-03-29T20:34:15.966627Z",
     "iopub.status.idle": "2022-03-29T20:34:16.946901Z",
     "shell.execute_reply": "2022-03-29T20:34:16.946045Z",
     "shell.execute_reply.started": "2022-03-29T20:34:15.966851Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_at_random_download(store=TEST_SET_PATH, group=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a4a3a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e4541c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T20:34:30.876811Z",
     "iopub.status.busy": "2022-03-29T20:34:30.87609Z",
     "iopub.status.idle": "2022-03-29T20:34:31.558852Z",
     "shell.execute_reply": "2022-03-29T20:34:31.558022Z",
     "shell.execute_reply.started": "2022-03-29T20:34:30.876772Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_at_random_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f21d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-29T20:34:35.986838Z",
     "iopub.status.busy": "2022-03-29T20:34:35.986442Z",
     "iopub.status.idle": "2022-03-29T20:34:36.028494Z",
     "shell.execute_reply": "2022-03-29T20:34:36.026929Z",
     "shell.execute_reply.started": "2022-03-29T20:34:35.986802Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_from_txt_file(src='validation-adult-save.txt', start=30, limit=40, break_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ff9f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### save model for embeded devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90148301",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "from datetime import datetime\n",
    "output_path = 'models/embeded/{}'.format(datetime.now())\n",
    "!mkdir $output_path\n",
    "tfjs.converters.save_keras_model(model, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2a3ed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89520680",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = \"models/holypics/\"+str(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96041e7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save_dir = \"shared/models/holypics/\"+str(version)\n",
    "#!rm -r $save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a002d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def decode_img_bytes(img):\n",
    "    img = tf.strings.regex_replace(img, \"\\+\", \"-\")\n",
    "    img = tf.strings.regex_replace(img, \"\\/\", \"_\")\n",
    "    image = tf.image.decode_jpeg(tf.io.decode_base64(img), channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32) # 0-1\n",
    "    image = tf.image.resize(images=image, size=dimensions)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cebfd2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "class ExportModel(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(self)       \n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.string, name=\"base64\")\n",
    "    ])\n",
    "    \n",
    "    def serving_fn(self, base64):\n",
    "        #a = np.array([x.lower() if isinstance(x, str) else x for x in arr])\n",
    "        base64_image = tf.map_fn(lambda x: decode_img_bytes(x), base64, fn_output_signature=tf.float32)\n",
    "        preds = self.model(base64_image)\n",
    "        \n",
    "        return {\n",
    "            #'base_64': base64,\n",
    "            'prediction': preds\n",
    "            #'precisions': prediction_precision\n",
    "        }\n",
    "\n",
    "    def save(self, export_path):\n",
    "        sigs = {\n",
    "            'serving_default' : self.serving_fn\n",
    "        }\n",
    "        \n",
    "        #tf.keras.backend.set_learning_phase(0) # inference only\n",
    "        tf.saved_model.save(self, export_path, signatures=sigs)\n",
    "sm = ExportModel(model)\n",
    "sm.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d154f2b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "class ExportModel(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(self)       \n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.string, name=\"base64\")\n",
    "    ])\n",
    "    \n",
    "    def serving_fn(self, base64):\n",
    "        #a = np.array([x.lower() if isinstance(x, str) else x for x in arr])\n",
    "        base64_image = tf.map_fn(lambda x: decode_img_bytes(x), base64, fn_output_signature=tf.float32)\n",
    "        preds = self.model(base64_image)\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            print(sess.run(preds))\n",
    "\n",
    "        return {\n",
    "            #'base_64': base64,\n",
    "            'prediction': preds\n",
    "            #'precisions': prediction_precision\n",
    "        }\n",
    "\n",
    "    def save(self, export_path):\n",
    "        sigs = {\n",
    "            'serving_default' : self.serving_fn\n",
    "        }\n",
    "        \n",
    "        #tf.keras.backend.set_learning_phase(0) # inference only\n",
    "        tf.saved_model.save(self, export_path, signatures=sigs)\n",
    "sm = ExportModel(model)\n",
    "sm.save(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce8147",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Send deployement files to host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d0076",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"http://ml.megamaxdevelopment.tech/uploader.php\"\n",
    "\n",
    "payload = {'key': \"tfdmhdsus\", 'path': 'ml.megamaxdevelopment.tech/holypics/'}\n",
    "\n",
    "file = 'models/shared/shared.zip'#'models/shared/shared.zip'\n",
    "\n",
    "files = {'uploaded_file': (os.path.basename(file), open(file, 'rb'), 'application/octet-stream')}\n",
    "\n",
    "r = requests.post(url, files=files, data=payload)\n",
    "\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de11bb0e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Preview model performances on dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e51bcc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### main processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f2aff4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def get_image_from_video(path= \"assets/normal-1.mp4\", start_frame = -1, sequences_number = 50):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    count = 0\n",
    "    image = np.asarray([]);\n",
    "    try:\n",
    "        while True:\n",
    "            if start_frame!=-1 and count < start_frame:\n",
    "                count+=1\n",
    "                pass\n",
    "            else:\n",
    "                ret, frame = cap.read()\n",
    "                height, width, _ = frame.shape\n",
    "\n",
    "                # Extract Region of interest\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #frame[340: 720,500: 800]\n",
    "                \"\"\"decoded_class_index, decoded_prediction_precision,predictions = decode_prediction(model.predict(np.array([cv2.resize(image, dimensions, interpolation = cv2.INTER_AREA)/255])))\n",
    "                print(decoded_class_index[0])\n",
    "                if decoded_class_index[0] == 0:\n",
    "                    image = cv2.GaussianBlur(image, (51,51), 50) \"\"\"\n",
    "                    \n",
    "                count+=1\n",
    "                clear_output(wait=True)\n",
    "                imshow(image)\n",
    "                show()\n",
    "                if sequences_number !=-1 :\n",
    "                    if count == sequences_number:\n",
    "                        break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # Release the Video Device\n",
    "        cap.release()\n",
    "        # Message to be displayed after releasing the device\n",
    "        print(\"Released Video Resource\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def process_video(src = \"assets/sex-4.mp4\", count = 0, limit = 50, hard = True, winStride =(4, 4),padding=(8, 8), scale=1.05):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    \n",
    "    # open webcam video stream\n",
    "    \n",
    "    cap = cv2.VideoCapture(src)\n",
    "\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        # Extract Region of interest\n",
    "        ROI = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        decoded_class_index, decoded_prediction_precision,predictions = decode_prediction(model.predict(np.array([cv2.resize(ROI, dimensions, interpolation = cv2.INTER_AREA)/255])))\n",
    "        if decoded_class_index[0]==0:\n",
    "            # resizing for faster detection\n",
    "            # using a greyscale picture, also for faster detection\n",
    "            if not hard:\n",
    "                (rects, weights) = hog.detectMultiScale(ROI, winStride=winStride, padding=padding, scale=scale)\n",
    "\n",
    "                # draw the original bounding boxes\n",
    "                for (x, y, w, h) in rects:\n",
    "                    decoded_class_index, decoded_prediction_precision,predictions = decode_prediction(model.predict(np.array([cv2.resize(ROI[y:y+h, x:x+w], dimensions, interpolation = cv2.INTER_AREA)/255])))\n",
    "                    if decoded_class_index[0]==0:\n",
    "                    #blur = cv2.GaussianBlur(ROI, (51,51), 50) \n",
    "                        copy = ROI[y:y+h, x:x+w]\n",
    "                        blur = cv2.GaussianBlur(copy, (51,51), 50) \n",
    "                        ROI[y:y+h, x:x+w] = blur\n",
    "\n",
    "                        #cv2.rectangle(ROI, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "                # apply non-maxima suppression to the bounding boxes using a\n",
    "                # fairly large overlap threshold to try to maintain overlapping\n",
    "                # boxes that are still people\n",
    "                rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "                pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "                # draw the final bounding boxes\n",
    "                for (xA, yA, xB, yB) in pick:\n",
    "                    copy = ROI[yA:yB, xA:xB]\n",
    "                    blur = cv2.GaussianBlur(copy, (51,51), 50) \n",
    "                    ROI[yA:yB, xA:xB] = blur\n",
    "                    #cv2.rectangle(ROI, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "            else:\n",
    "                 ROI = cv2.GaussianBlur(ROI, (51,51), 50) \n",
    "\n",
    "        clear_output(wait=True)\n",
    "        imshow(ROI)\n",
    "        show()\n",
    "\n",
    "\n",
    "        if limit !=-1 and count == limit:\n",
    "            break\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "def parallel_process_video(src = \"assets/sex-4.mp4\",inline = True, figsize = (30, 30), count = 0, limit = 50, hard = True, winStride =(4, 4),padding=(8, 8), scale=1.05):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    \n",
    "    # open webcam video stream\n",
    "    \n",
    "    cap = cv2.VideoCapture(src)\n",
    "\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        # Extract Region of interest\n",
    "        ROI = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        COPY = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        decoded_class_index, decoded_prediction_precision,predictions = decode_prediction(model.predict(np.array([cv2.resize(ROI, dimensions, interpolation = cv2.INTER_AREA)/255])))\n",
    "        if decoded_class_index[0]==0:\n",
    "            # resizing for faster detection\n",
    "            # using a greyscale picture, also for faster detection\n",
    "            if not hard:\n",
    "                (rects, weights) = hog.detectMultiScale(ROI, winStride=winStride, padding=padding, scale=scale)\n",
    "\n",
    "                # draw the original bounding boxes\n",
    "                for (x, y, w, h) in rects:\n",
    "                    decoded_class_index, decoded_prediction_precision,predictions = decode_prediction(model.predict(np.array([cv2.resize(ROI[y:y+h, x:x+w], dimensions, interpolation = cv2.INTER_AREA)/255])))\n",
    "                    if decoded_class_index[0]==0:\n",
    "                    #blur = cv2.GaussianBlur(ROI, (51,51), 50) \n",
    "                        copy = ROI[y:y+h, x:x+w]\n",
    "                        blur = cv2.GaussianBlur(copy, (51,51), 50) \n",
    "                        ROI[y:y+h, x:x+w] = blur\n",
    "\n",
    "                        #cv2.rectangle(ROI, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "                # apply non-maxima suppression to the bounding boxes using a\n",
    "                # fairly large overlap threshold to try to maintain overlapping\n",
    "                # boxes that are still people\n",
    "                rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "                pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "                # draw the final bounding boxes\n",
    "                for (xA, yA, xB, yB) in pick:\n",
    "                    copy = ROI[yA:yB, xA:xB]\n",
    "                    blur = cv2.GaussianBlur(copy, (51,51), 50) \n",
    "                    ROI[yA:yB, xA:xB] = blur\n",
    "                    #cv2.rectangle(ROI, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "            else:\n",
    "                 ROI = cv2.GaussianBlur(ROI, (51,51), 50) \n",
    "        \n",
    "        if inline:\n",
    "            clear_output(wait=True)\n",
    "            \"\"\"plt.subplot(vertical,horizontal,elem_place)\n",
    "            plt.subplots_adjust(hspace = plt_hspace)\n",
    "            plt.title(title)\n",
    "            plt.imshow(image)\"\"\"\n",
    "            plt.figure(figsize=figsize)\n",
    "            subplot(1,2,1)\n",
    "            title(\"neutral\")\n",
    "            imshow(COPY)\n",
    "            subplot(1,2,2)\n",
    "            title(\"processed\")\n",
    "            imshow(ROI)\n",
    "            show()\n",
    "        else:\n",
    "            cv2.imshow(\"neutral\", COPY)\n",
    "            cv2.imshow(\"processed\", ROI)\n",
    "\n",
    "\n",
    "        if limit !=-1 and count == limit:\n",
    "            break\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "def local_video_preprocess(videoPath, hard=True,log=False,saveFrame = True, video_title=\"\", winStride =(4, 4),padding=(8, 8), scale=1.05, overlapThresh=0.65, probs=None, size = (0, 0)):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    \n",
    "        \n",
    "        #cap.set(cv2.CAP_PROP_FPS, 25)\n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "    if not size == (0,0):\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, size[0])\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, size[1])\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "        \n",
    "            \n",
    "      # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        try:\n",
    "                height, width, _ = frame.shape\n",
    "   \n",
    "        except Exception as wrong: \n",
    "            pass\n",
    "        \n",
    "        \n",
    "\n",
    "        # Extract Region of interest\n",
    "        \n",
    "        if ret == True:\n",
    "            ENDROI = frame\n",
    "            ROI = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            decoded_class_index, decoded_prediction_precision,predictions = decode_prediction(model.predict(np.array([cv2.resize(ROI, dimensions, interpolation = cv2.INTER_AREA)/255])))\n",
    "            if decoded_class_index[0]==0:\n",
    "            # resizing for faster detection\n",
    "            # using a greyscale picture, also for faster detection\n",
    "                if not hard:\n",
    "                    (rects, weights) = hog.detectMultiScale(ROI, winStride=winStride, padding=padding, scale=scale)\n",
    "\n",
    "                    # draw the original bounding boxes\n",
    "                    for (x, y, w, h) in rects:\n",
    "                        decoded_class_index, decoded_prediction_precision,predictions = decode_prediction(model.predict(np.array([cv2.resize(ROI[y:y+h, x:x+w], dimensions, interpolation = cv2.INTER_AREA)/255])))\n",
    "                        if decoded_class_index[0]==0:\n",
    "                        #blur = cv2.GaussianBlur(ROI, (51,51), 50) \n",
    "                            copy = ROI[y:y+h, x:x+w]\n",
    "                            blur = cv2.GaussianBlur(copy, (51,51), 50) \n",
    "                            ROI[y:y+h, x:x+w] = blur\n",
    "\n",
    "                            #cv2.rectangle(ROI, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "                    # apply non-maxima suppression to the bounding boxes using a\n",
    "                    # fairly large overlap threshold to try to maintain overlapping\n",
    "                    # boxes that are still people\n",
    "                    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "                    #pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "                    pick = non_max_suppression(rects, probs=probs, overlapThresh=overlapThresh)\n",
    "                    # draw the final bounding boxes\n",
    "                    for (xA, yA, xB, yB) in pick:\n",
    "                        copy = ROI[yA:yB, xA:xB]\n",
    "                        blur = cv2.GaussianBlur(copy, (51,51), 50) \n",
    "                        ENDROI[yA:yB, xA:xB] = blur\n",
    "                        #cv2.rectangle(ROI, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "                else:\n",
    "                     ENDROI = cv2.GaussianBlur(ENDROI, (51,51), 50)\n",
    "            if not size == (0,0):\n",
    "                cv2.resize(ENDROI,size,fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "            if log:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                bottomLeftCornerOfText = (70*width//100, 95*height//100)#(height-100, width-100)\n",
    "                TopRightCornerOfText = (15*width//100, 15*height//100)\n",
    "                fontScale = 0.8\n",
    "                fontColor = (255, 99, 71) #(255,255,255)\n",
    "                lineType  = 2\n",
    "                cv2.putText(ENDROI,'{0} : {1}'.format(binary_classes_names[int(decoded_class_index)], float(\"{:.2f}\".format(decoded_prediction_precision[0][0]))),  bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "                if not video_title == \"\":\n",
    "                    cv2.putText(ENDROI,video_title,  TopRightCornerOfText, font, fontScale, fontColor, lineType)\n",
    "            cv2.imshow('Frame',ENDROI)\n",
    "            if saveFrame :\n",
    "                frames.append(ROI)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            \n",
    "\n",
    "          # Break the loop\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def plot_figures(figures, nrows = 1, ncols=1, start=0, end=0):\n",
    "    \"\"\"Plot a dictionary of figures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    figures : <title, figure> dictionary\n",
    "    ncols : number of columns of subplots wanted in the display\n",
    "    nrows : number of rows of subplots wanted in the figure\n",
    "    \"\"\"\n",
    "    if end == 0:\n",
    "        end = len(figures)\n",
    "    count = 0\n",
    "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "    for i in range(start, end):\n",
    "        axeslist.ravel()[i].imshow(figures[i], cmap=plt.jet())\n",
    "        axeslist.ravel()[i].set_title(str(count))\n",
    "        axeslist.ravel()[i].set_axis_off()\n",
    "        count+=1\n",
    "    plt.tight_layout() # optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2d04a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84378306",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# videos => https://www.youtube.com/c/Wedontwatchtv/videos\n",
    "# current_video = \"assets/sex-trip-15.mp4\"\n",
    "current_video = \"assets/sex-trip-15.mp4\"\n",
    "current_sequences_number = 100\n",
    "limit_sequences_number = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4285bf4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parallel_process_video(current_video,count=current_sequences_number, limit=limit_sequences_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df521f66",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Local video preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c9b1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepared_data = {\n",
    "    \"sex-trip\":{\n",
    "        \"local_prep_start\": 1,\n",
    "        \"local_prep_end\": 35,\n",
    "        \"base_name\": \"sex-trip-\"\n",
    "    },\n",
    "    \"porn\":{\n",
    "        \"local_prep_start\": 1,\n",
    "        \"local_prep_end\": 3,\n",
    "        \"base_name\": \"porn-\"\n",
    "    },\n",
    "    \"sex\":{\n",
    "        \"local_prep_start\": 1,\n",
    "        \"local_prep_end\": 5,\n",
    "        \"base_name\": \"sex-\"\n",
    "    },\n",
    "    \"normal\":{\n",
    "        \"local_prep_start\": 1,\n",
    "        \"local_prep_end\": 7,\n",
    "        \"base_name\": \"normal-\"\n",
    "    },\n",
    "    \"normal-sexy\":{\n",
    "        \"local_prep_start\": 1,\n",
    "        \"local_prep_end\": 10,\n",
    "        \"base_name\": \"normal-sexy-\"\n",
    "    },\n",
    "    \"sexy-woman\":{\n",
    "        \"local_prep_start\": 1,\n",
    "        \"local_prep_end\": 13,\n",
    "        \"base_name\": \"sexy-woman-\"\n",
    "    }\n",
    "}\n",
    "\n",
    "key = \"sexy-woman\" #porn, sex, sex-trip,sexy-woman, normal\n",
    "\n",
    "base_name = prepared_data[key][\"base_name\"]\n",
    "\n",
    "local_prep_start = prepared_data[key][\"local_prep_start\"]\n",
    "local_prep_end = prepared_data[key][\"local_prep_end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb35e3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(local_prep_start, local_prep_end):\n",
    "    try:\n",
    "        local_video_preprocess(\"assets/{0}{1}.mp4\".format(base_name, i),log=True,video_title = \"{0}{1}\".format(base_name, i), hard=True, winStride =(4, 4),padding=(20, 20), scale=1.2, overlapThresh=0.25, probs=None, size=(100, 100))\n",
    "    except Exception as wrong: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46ccf5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### video to frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db35d44",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = local_video_preprocess(\"assets/sex-1.mp4\",log=True, hard=True, winStride =(4, 4),padding=(20, 20), scale=1.2, overlapThresh=0.25, probs=None, size=(100, 100))\n",
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f083cbc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_figures(frames, 3, 4, end=12)\n",
    "plt.figsize=(50, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0a645",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### more functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22fded5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_frames(frames,path=\"images_saves/adult\", start=0, end=0, tread=1, random=False, image_number=0):\n",
    "    if random:\n",
    "        if image_number == 0:\n",
    "            image_number = len(frames)-1\n",
    "            \n",
    "        generated = []\n",
    "        for i in range(0, image_number):\n",
    "            current_id = randint(0, len(frames))\n",
    "            while current_id in generated:\n",
    "                current_id = randint(0, len(frames))\n",
    "            filename = path+\"/\"+str(uuid.uuid1())+\".jpg\"\n",
    "            cv2.imwrite(filename, cv2.cvtColor(frames[current_id], cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "    else:  \n",
    "        if end == 0:\n",
    "            end = len(frames)\n",
    "        count=0\n",
    "        while (end - start - count) > 0:\n",
    "            filename = path+\"/\"+str(uuid.uuid1())+\".jpg\"\n",
    "            cv2.imwrite(filename, cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB))\n",
    "            count+=tread\n",
    "\n",
    "        \"\"\"for i in range(start, end):\n",
    "            filename = path+\"/\"+str(uuid.uuid1())+\".jpg\"\n",
    "            cv2.imwrite(filename, cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB))\n",
    "            if tread>1:\n",
    "                i+=(tread-1)\"\"\"\n",
    "        \n",
    "def randomize_frames(frames, image_number=0):\n",
    "    output_frames = []\n",
    "    if image_number == 0:\n",
    "        image_number = len(frames)-1  \n",
    "    generated = []\n",
    "    for i in range(0, image_number):\n",
    "        current_id = randint(0, len(frames))\n",
    "        while current_id in generated:\n",
    "            current_id = randint(0, len(frames))\n",
    "        output_frames.append(frames[current_id])\n",
    "    return output_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e3583",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### save frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cf24a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_frames(frames, tread=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-21T18:17:00.613437",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}