{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dataset Part","metadata":{}},{"cell_type":"markdown","source":"### Install dependencies","metadata":{}},{"cell_type":"code","source":"# !pip3 install PyQt5\n# !pip3 install ipywidgets\n# !pip3 install scikit-learn\n# !pip3 install tensorflow_addons\n# !pip3 install bs4\n# !pip3 install fake_useragent\n# !pip3 install pytest","metadata":{"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-10-01T11:59:57.686862Z","iopub.execute_input":"2022-10-01T11:59:57.689282Z","iopub.status.idle":"2022-10-01T11:59:57.693518Z","shell.execute_reply.started":"2022-10-01T11:59:57.689231Z","shell.execute_reply":"2022-10-01T11:59:57.692326Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install fake_useragent\n!pip install imutils\n!pip install gdown\n!pip install kaggle --user\n# !pip install tensorflowjs","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-04T14:24:34.491800Z","iopub.execute_input":"2022-10-04T14:24:34.492537Z","iopub.status.idle":"2022-10-04T14:25:36.898874Z","shell.execute_reply.started":"2022-10-04T14:24:34.492383Z","shell.execute_reply":"2022-10-04T14:25:36.897586Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting fake_useragent\n  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: fake-useragent\n  Building wheel for fake-useragent (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=038a7473f00592a0d99d2eb0732468e90d9a3c27ed0c3e0c4c4e281f51ad9168\n  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\nSuccessfully built fake-useragent\nInstalling collected packages: fake-useragent\nSuccessfully installed fake-useragent-0.1.11\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting imutils\n  Downloading imutils-0.5.4.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=7ae5330173c22c31535ba6133f49f6efa3cf4061e097bb47333231ea4616c204\n  Stored in directory: /root/.cache/pip/wheels/86/d7/0a/4923351ed1cec5d5e24c1eaf8905567b02a0343b24aa873df2\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting gdown\n  Downloading gdown-4.5.1.tar.gz (14 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.62.3)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.26.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.0.9)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nBuilding wheels for collected packages: gdown\n  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14933 sha256=e19be3cd6027ec1ce3181d91dde8ceff94c35d1d551e2c634af557dbf13db9b2\n  Stored in directory: /root/.cache/pip/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\nSuccessfully built gdown\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.7/site-packages (1.5.12)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.8.2)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle) (2021.10.8)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle) (5.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.26.0)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from kaggle) (4.62.3)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.26.7)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (2.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (3.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### import main dependencies","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport hashlib\nimport sys\nimport random\nimport os\nimport tensorflow_hub as hub\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom fake_useragent import UserAgent\nfrom matplotlib.widgets import Button\nimport datetime\nfrom tensorflow.keras import layers\nimport pathlib\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.applications import imagenet_utils\nfrom imutils.object_detection import non_max_suppression\nfrom PIL import Image\nimport scipy\nimport numpy as np\nimport argparse\nimport imutils\nimport time\nimport cv2\nimport requests\nfrom IPython.display import clear_output\nfrom io import BytesIO\nfrom IPython.display import display, clear_output\n#from ipywidgets import interact\n#import ipywidgets as widgets\nfrom PIL import ImageFilter\nfrom bs4 import *\nimport uuid\nfrom IPython.display import display, Markdown, clear_output, FileLink, FileLinks\nfrom IPython.display import Image as IImage \nimport ipywidgets as widgets\nfrom PIL import Image\nimport pandas as pd\nimport gdown\nfrom random import randrange\nimport ipywidgets as widgets\nimport shutil\nfrom io import BytesIO\nimport json\nimport time\nimport mimetypes","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:27:03.508524Z","iopub.execute_input":"2022-10-04T14:27:03.509341Z","iopub.status.idle":"2022-10-04T14:27:03.521163Z","shell.execute_reply.started":"2022-10-04T14:27:03.509287Z","shell.execute_reply":"2022-10-04T14:27:03.520419Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Defining main variables","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/holipics-lite/holipics-dataset/images","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:27:07.839589Z","iopub.execute_input":"2022-10-04T14:27:07.840161Z","iopub.status.idle":"2022-10-04T14:27:08.971539Z","shell.execute_reply.started":"2022-10-04T14:27:07.840123Z","shell.execute_reply":"2022-10-04T14:27:08.970267Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"ls: cannot access '/kaggle/input/holipics-lite/holipics-dataset/images': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"BUILD_NEW_DATASET = True\nREDUCE_DATASET_IMAGES = False\nUSE_DATA_RELATIONSHIP = False\nDOWNLOAD_ADDITIONAL_IMAGES = False\nDEPLOY_DATASET_TO_SERVER = True\nUSE_UPDATED_DATASET = True\nBASE_PATH = \"/kaggle/input/nsfw-content-moderation/\"\nDATASET_PATH = BASE_PATH+\"images\"\nSTORE_PATH=\"save\"\nDATASET_COPY_PATH = STORE_PATH+\"/images_backup\"\nTEST_SET_PATH= \"test\"\n# DATASET_DUMP_PATH = BASE_PATH+(\"/images_backup_lite\" if BUILD_NEW_DATASET else \"/images_backup\")  \nDATASET_DUMP_PATH = \"images_backup_lite/images_backup_lite\" #if\"images_backup\"\nCSV_DATASET_PATH = \"image_dataset.csv\"\nIMAGE_RES = 224\nMODEL_PATH = \"models\"\nSAVED_MODEL_PATH = STORE_PATH + \"/\" + MODEL_PATH\nUNWATED_PATHS = []\nMAX_IMAGE_PER_CLASS = 2000 #3000\nMAX_IMAGE_PER_SEVERE_CLASS = 3000 #1500\nSEVERE_CLASSES = [\"general_not_nsfw_not_suggestive\"]\nDATASET_NAME = \"isralkaramoko/holipics-lite\"\nDATASET_URL = \"https://www.kaggle.com/\"+DATASET_NAME\nDATASET_ZIP = \"holipics-lite.zip\"\nDATASET_DOWNLOAD_URL = \"http://188.166.126.190:83/filebrowser/api/public/dl/Krp4tZMY\"\nASSETS_DOWNLOAD_URL = \"http://188.166.126.190:83/filebrowser/api/public/dl/rQ6jKE2f\"\nASSETS_PATH=\"assets\"","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:29:53.060493Z","iopub.execute_input":"2022-10-04T14:29:53.060936Z","iopub.status.idle":"2022-10-04T14:29:53.071771Z","shell.execute_reply.started":"2022-10-04T14:29:53.060885Z","shell.execute_reply":"2022-10-04T14:29:53.070565Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Kaggle api","metadata":{}},{"cell_type":"code","source":"credentials = {\"username\":\"jamesdame\",\"key\":\"157e2681cd07fe2460010b340d5a7504\"}\nkaggle_key_store='kaggle.json'\nwith open(kaggle_key_store, 'w', encoding='utf-8') as f:\n    json.dump(credentials, f, ensure_ascii=False, indent=4)\n\n!rm -rf /root/.kaggle     # when I created the folder, it says the file or dir already exits\n!mkdir /root/.kaggle        # successful\n!mv kaggle.json /root/.kaggle/kaggle.json    # not sure if I have to use full destination path, I previously only used /root/.kaggle and it failed. Don't have time to validate this thought.\n!ls /root/.kaggle/kaggle.json\n!chmod 600 /root/.kaggle/kaggle.json","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-10-04T14:29:56.487810Z","iopub.execute_input":"2022-10-04T14:29:56.490126Z","iopub.status.idle":"2022-10-04T14:30:02.026763Z","shell.execute_reply.started":"2022-10-04T14:29:56.490072Z","shell.execute_reply":"2022-10-04T14:30:02.025636Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/root/.kaggle/kaggle.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### main functions","metadata":{}},{"cell_type":"code","source":"def preview_images_from_directory(path=DATASET_PATH, group=True):\n    dimensions=(IMAGE_RES, IMAGE_RES)\n    data_dir = path\n    clean_up_data_dir(data_dir)\n    images_path = []\n    \n    if(group):\n        data_sub_directories = os.listdir(data_dir)\n        for data_sub_directory in data_sub_directories:\n#             print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))\n            for current_dir in os.listdir(os.path.join(data_dir, data_sub_directory)):\n                images_path.append(os.path.join(data_sub_directory, current_dir))\n    else:\n        try:\n            for current_dir in os.listdir(data_dir):\n                images_path.append(os.path.join(data_dir, current_dir))\n        except Exception as wrong:\n            pass\n\n    if not group:\n        data_dir = \".\"\n        \n    current = 0        \n    output = widgets.Output()\n    next_button = widgets.Button(description='Next')\n    prev_button = widgets.Button(description='Prev')\n    display_current_button = widgets.Button(description='Current')\n    current_index_text = widgets.Textarea(\n        value=str(current),\n        placeholder='current index goes here',\n        description='index',\n        disabled=False\n    )\n    \n    display(current_index_text, display_current_button, prev_button, next_button, output)\n    \n    def default_action():\n        global current\n        with output:\n            clear_output()\n            print(\"{0}: {1}/{2}\".format(images_path[current].split(\"/\")[0], current+1, len(images_path)))\n            image = cv2.imread(os.path.join(data_dir, images_path[current]))\n            # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n            imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n            image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n            \n            current_image = Image.fromarray(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA))\n            display(current_image)\n            \n    def on_next_button_clicked(_):\n        global current\n        if current+2 > len(images_path):\n            return None\n        current+=1\n        default_action()\n\n\n    def on_prev_button_clicked(_):\n        global current\n        if current-1 < 0:\n            return None\n        current-=1\n        default_action()\n        \n        \n    def on_current_index_change(_):\n        update_index_change(current_index_text.value)\n\n    def update_index_change(indexString):\n        global current\n        try:\n            current = int(indexString)\n            default_action()\n        except Exception as wrong:\n            pass\n\n    next_button.on_click(on_next_button_clicked)\n    prev_button.on_click(on_prev_button_clicked)\n    display_current_button.on_click(on_current_index_change)\n    current_index_text.on_displayed(update_index_change(str(current)))\n    \n    \n    \n    \ndef order_images(main_dir, start=-1, end=-1, figsize=(30, 30), dimensions=(IMAGE_RES, IMAGE_RES)):\n    %matplotlib inline\n    from IPython.display import display, Markdown, clear_output\n    from IPython.display import Image as IImage \n    import ipywidgets as widgets\n\n    current  =  0\n    del_dir = os.path.join(main_dir, \".ipynb_checkpoints\")\n    !rm -r $del_dir\n    if start == -1 and end == -1:\n        images_path = os.listdir(main_dir)\n    elif start != -1 and end == -1:\n        images_path = os.listdir(main_dir)[start:len(os.listdir(main_dir))]\n    elif start == -1 and end != -1:\n        images_path = os.listdir(main_dir)[0:end]\n    else:\n        images_path = os.listdir(main_dir)\n        \n    next_button = widgets.Button(description='Next')\n    prev_button = widgets.Button(description='Prev')\n    move_button = widgets.Button(description='Move')\n    class_names = os.listdir(DATASET_PATH)\n    moving_paths = []\n\n    path_selector = widgets.SelectMultiple(\n        options=class_names,\n        value=[],\n        description='Fruits',\n        disabled=False\n    )\n    output = widgets.Output()\n    display(prev_button, next_button, output, path_selector, move_button)\n\n    def on_next_button_clicked(_):\n        global current\n        if current+2 > len(images_path):\n            return None\n        moving_paths = []\n        with output:\n            current+=1\n            clear_output()\n            print(\"{0}/{1}\".format(current+1, len(images_path)))\n            pil_img = IImage(filename=os.path.join(main_dir, images_path[current]), width = dimensions[0], height=dimensions[1])\n            display(pil_img)\n\n    def on_prev_button_clicked(_):\n        global current\n        if current-1 < 0:\n            return None\n        moving_paths = []\n        with output:\n            current-=1\n            clear_output()\n            print(\"{0}/{1}\".format(current+1, len(images_path)))\n            pil_img = IImage(filename=os.path.join(main_dir, images_path[current]), width = dimensions[0], height=dimensions[1])\n            display(pil_img)\n    def on_move_button_clicked(_):\n        with output:\n            print(path_selector.value)\n            for current_path in path_selector.value:\n                os.system(\"cp '{0}' '{1}'\".format(os.path.join(main_dir, DATASET_PATH+\"/\"+images_path[current]), current_path))\n\n    next_button.on_click(on_next_button_clicked)\n    prev_button.on_click(on_prev_button_clicked)\n    move_button.on_click(on_move_button_clicked)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:30:03.500441Z","iopub.execute_input":"2022-10-04T14:30:03.500840Z","iopub.status.idle":"2022-10-04T14:30:03.566284Z","shell.execute_reply.started":"2022-10-04T14:30:03.500797Z","shell.execute_reply":"2022-10-04T14:30:03.565283Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dump_dir = DATASET_DUMP_PATH\ndef clean_up_data_dir(data_dir):\n    data_sub_directories = os.listdir(data_dir)\n    for data_sub_directory in data_sub_directories:\n        path_to_delete = os.path.join(data_dir, data_sub_directory, \".*\")\n        !rm -r $path_to_delete\n\n    !rm -r $data_dir/.ipynb_checkpoints\n    !rm -r $data_dir/.DS_Store\n\n# CREATE FOLDER\ndef folder_create(images, given_folder_name=\"\"):\n    try:\n        folder_name = os.path.join(dump_dir, input(\"Enter Folder Name:- \") if given_folder_name == \"\" else given_folder_name)\n        # folder creation\n        os.mkdir(folder_name)\n \n    # if folder exists with that name, ask another name\n    except:\n        print(\"Folder Exist with that name!\")\n        folder_create()\n \n    # image downloading start\n    download_images(images, folder_name)\n \n \n# DOWNLOAD ALL IMAGES FROM THAT URL\ndef download_images(images, folder_name):\n   \n    # initial count is zero\n    count = 0\n \n    # print total images found in URL\n    print(f\"Total {len(images)} Image Found!\")\n \n    # checking if images is not zero\n    if len(images) != 0:\n        for i, image in enumerate(images):\n            # From image tag ,Fetch image Source URL\n \n                        # 1.data-srcset\n                        # 2.data-src\n                        # 3.data-fallback-src\n                        # 4.src\n \n            # Here we will use exception handling\n \n            # first we will search for \"data-srcset\" in img tag\n            try:\n                # In image tag ,searching for \"data-srcset\"\n                image_link = image[\"src\"]\n                 \n            # then we will search for \"data-src\" in img\n            # tag and so on..\n            except:\n                try:\n                    # In image tag ,searching for \"data-src\"\n                    image_link = image[\"data-src\"]\n                except:\n                    try:\n                        # In image tag ,searching for \"data-fallback-src\"\n                        image_link = image[\"data-fallback-src\"]\n                    except:\n                        try:\n                            # In image tag ,searching for \"src\"\n                            image_link = image[\"data-srcset\"]\n \n                        # if no Source URL found\n                        except:\n                            pass\n \n            # After getting Image Source URL\n            # We will try to get the content of image\n            try:\n                print(\"Downloading image: {0}/{1}; store => {2}\".format(count, len(images), folder_name))\n                r = requests.get(image_link).content\n                try:\n \n                    # possibility of decode\n                    r = str(r, 'utf-8')\n                except UnicodeDecodeError:\n \n                    # After checking above condition, Image Download start\n                    with open(f\"{folder_name}/images{i+1}.jpg\", \"wb+\") as f:\n                        f.write(r)\n \n                    # counting number of image downloaded\n                    count += 1\n            except:\n                pass\n \n        # There might be possible, that all\n        # images not download\n        # if all images download\n        if count == len(images):\n            print(\"All Images Downloaded!\")\n             \n        # if all images not download\n        else:\n            print(f\"Total {count} Images Downloaded Out of {len(images)}\")\n \n# MAIN FUNCTION START\ndef download_images_from_url(url, given_folder_name=\"\"):\n    if url == None or ( url.find(\"http\") == -1 and url.find(\"www\") == -1 ):\n        return\n    # content of URL\n    ua = UserAgent()\n\n    # Get list of user agents.\n\n\n    # headers = {'User-Agent': ua.random}\n    # r = requests.get(url, headers=headers)\n    r = requests.get(url)\n    print(url)\n    print(r)\n    # Parse HTML Code\n    soup = BeautifulSoup(r.text, 'html.parser')\n \n    # find all images in URL\n    images = soup.findAll('img')\n \n    # Call folder create function\n    folder_create(images, given_folder_name)\n\ndef remove_duplicates(dir, include_src=False):\n    hashMap = {}\n    # List to store deleted files\n    deletedFiles = []\n    source_dup_file = []\n    filelist = os.listdir(dir)\n    for f in filelist:\n        f = os.path.join(dir, f)\n        key = hashFile(f)\n        # If key already exists, it deletes the file\n        if key in hashMap.keys():\n            deletedFiles.append(f)\n            if include_src:\n                try:\n                    index = source_dup_file.index(key)\n                except Exception as e:\n                    source_dup_file.append(key)\n            os.remove(f)\n        else:\n            hashMap[key] = f\n    if include_src:\n        for key in source_dup_file:\n            deletedFiles.append(f)\n            os.remove(hashMap[key])\n            \n    if len(deletedFiles) != 0:  \n        for deleted_file in deletedFiles:\n            print('Deleted Files {0}'.format(deleted_file))\n        print(\"total deleted => {}\".format(len(deletedFiles)))\n    else:\n        print('No duplicate files found')\n    \n\ndef remove_small_files(dir, min_size=5):\n    for root, _, files in os.walk(dir):\n        for f in files:\n            fullpath = os.path.join(root, f)\n            try:\n                if os.path.getsize(fullpath) < min_size * 1024:   #set file size in kb\n                    print(fullpath)\n                    os.remove(fullpath)\n            except Exception as e:\n                print(\"Error\" + fullpath)\n\ndef rename_all_files(dir):\n    for root, _, files in os.walk(dir):\n        for f in files:\n            fullpath = os.path.join(root, f)\n            try:\n                filename, file_extension = os.path.splitext(fullpath)\n                newname = str(uuid.uuid1())+\".\"+file_extension\n                os.rename(fullpath, os.path.join(dir, newname))\n           \n            except Exception as e:\n                print(e)\n                print(\"Error\" + fullpath)\n                \ndef delete_unreadable_images(dir):\n    for root, _, files in os.walk(dir):\n        for f in files:\n            fullpath = os.path.join(root, f)\n            try:\n                img = Image.open(fullpath)\n            except Exception as e:\n                os.system(\"rm {}\".format(fullpath))\n                print(\"Removing => \" + fullpath)\n\ndef remove_randomly_dir_files(dir, limit=2, percentage=0):\n    files = os.listdir(dir)\n\n    if(percentage != 0):\n        limit = int((percentage * len(files)) / 100)\n\n    print(\"Total files found : {}\".format(len(files)))\n    deleted_indexes = [-1]\n    count = 0\n    if limit >= len(files):\n        print(\"limit >= len(files)\")\n        return \n\n    for i in range(0, limit):\n        if len(deleted_indexes) > limit:\n            print(\"len(deleted_index) > limit\")\n            break\n\n        random_index = -1\n\n        while ( random_index in deleted_indexes) == True:\n            random_index = random.randint(0, len(files)-1)\n\n        deleted_indexes.append(random_index)\n        count+=1\n\n        print(\"deleting {0}/{1}; index => {2}\".format(i+1, limit, random_index))\n        os.remove(os.path.join(dir, files[random_index]))\n\n    print(\"Total deleted files {}\".format(count))\n    print(\"Total files remaining {}\".format(len(os.listdir(dir))))\n    \ndef hashFile(filename):\n    # For large files, if we read it all together it can lead to memory overflow, So we take a blocksize to read at a time\n    BLOCKSIZE = 65536\n    hasher = hashlib.md5()\n    with open(filename, 'rb') as file:\n        # Reads the particular blocksize from file\n        buf = file.read(BLOCKSIZE)\n        while(len(buf) > 0):\n            hasher.update(buf)\n            buf = file.read(BLOCKSIZE)\n    return hasher.hexdigest()\n\ndef predict_at_random_download(base_url=\"https://picsum.photos/{0}/{0}\".format(IMAGE_RES), store=DATASET_PATH, group=True):\n    selected_class = class_names[0]\n    selected_image = []\n    again_button = widgets.Button(description='Again')\n    download_button = widgets.Button(description='Download')\n    class_selector = widgets.Dropdown(\n        options=class_names,\n        value=selected_class,\n        description='Select a class',\n        disabled=False,\n    )\n\n    output = widgets.Output()\n    display(again_button, class_selector, download_button, output)\n\n    def on_again_button_clicked(_):\n        global selected_image\n        with output:\n            clear_output()\n            to_print, image = predict_single_image_from_url(base_url)\n            selected_image = image\n            print(to_print)\n            display(image)\n            \n    def on_download_button_clicked(_):\n        global selected_image\n        global selected_class\n        with output:\n            try:\n                if group:  \n                    export_path = \"{}.jpg\".format(os.path.join(store, selected_class, str(uuid.uuid1())))\n                else:\n                    export_path = \"{}.jpg\".format(os.path.join(store, str(uuid.uuid1())))\n                print(\"selected class => \", selected_class)\n                print(\"export path => \", export_path)\n                selected_image.save(export_path)\n                local_file = FileLink(export_path, result_html_prefix=\"Click here to download model: \")\n                display(local_file)\n            except Exception as wrong:\n                print(\"error while moving file to =>\", selected_class)\n                print(wrong)\n    def on_class_change(change):\n        global selected_class\n        try:\n            selected_class = class_names[change[\"new\"][\"index\"]]\n        except Exception as wrong:\n            pass\n        \n\n    with output:\n        clear_output()\n        to_print, image = predict_single_image_from_url(base_url)\n        selected_image = image\n        print(to_print)\n        display(image)\n    \n    again_button.on_click(on_again_button_clicked)\n    download_button.on_click(on_download_button_clicked)\n    class_selector.observe(on_class_change)\n    \ndef download_collection_from_unsplash(collection_id = \"500522\", selected_class=\"\", store=DATASET_COPY_PATH, group=True, perPage=10, page=1, image_width=IMAGE_RES, image_height=IMAGE_RES, fit=\"crop\", download_link=False):\n    api_key = '3E1O5xqWI-Opz3W81XdmIvZwPJ2qFTHggE5YUxZysDg'\n    url = \"https://api.unsplash.com/collections/{0}/photos?page={1}&per_page={2}\".format(collection_id, page, perPage)\n    # ua = UserAgent()\n    # headers = {'User-Agent': ua.random, 'Authorization': \"Client-ID {}\".format(api_key)}\n    headers = {\n        'Authorization': \"Client-ID {}\".format(api_key),\n        }\n    images = []\n    count = 0\n    total = 0\n    total_pages = 1\n    current_page = page\n    \n    try:\n        response = requests.get(url.format(collection_id, current_page, perPage), headers=headers)\n        total = int(response.headers['X-Total'])\n        \n        while(total_pages * perPage < total):\n            total_pages+=1\n    except Exception as wrong:\n        print(\"count error\")\n        print(wrong)\n        \n    while current_page <= total_pages:\n        print(\"processing page \", current_page, \"/\", total_pages)\n        try:\n            response = requests.get(url.format(collection_id, current_page, perPage), headers=headers)\n            response_json = response.json()\n            for image_data in response_json:\n                print(\"downloading image \",count+1, \"/\", total)\n                try:\n                    if group:  \n                        export_path = \"{}.jpg\".format(os.path.join(store, selected_class, str(uuid.uuid1())))\n                    else:\n                        export_path = \"{}.jpg\".format(os.path.join(store, str(uuid.uuid1())))\n                    image_response = requests.get(image_data[\"urls\"][\"raw\"]+\"&w={0}&h={1}&fit={2}\".format(image_width, image_height, fit))\n                    #raw,full, regular, small, thumb, small_s3    \n                    image = np.asarray(bytearray(image_response.content), dtype=\"uint8\")\n                    imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n                    imageRGB = cv2.cvtColor(imageBGR , cv2.COLOR_BGR2RGB)\n                    cv2.imwrite(export_path, imageBGR)\n                    if download_link:\n                        local_file = FileLink(export_path, result_html_prefix=\"Click here to download: \")\n                        display(local_file)            \n                except Exception as wrong:\n                    print(wrong)\n                    print(\"error while downloading image\")\n                count+=1\n        except Exception as wrong:\n            print(\"error while loading collections photos\")\n        current_page+=1","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:30:06.993701Z","iopub.execute_input":"2022-10-04T14:30:06.994055Z","iopub.status.idle":"2022-10-04T14:30:07.142852Z","shell.execute_reply.started":"2022-10-04T14:30:06.994018Z","shell.execute_reply":"2022-10-04T14:30:07.141776Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Download dataset","metadata":{}},{"cell_type":"code","source":"# if USE_UPDATED_DATASET:\n#     dwd_url = DATASET_DOWNLOAD_URL\n#     splitted = dwd_url.split(\"/\")\n#     dwd_file_name = splitted[len(splitted)-1]\n\n#     !wget $dwd_url\n#     !mv $dwd_file_name archive.zip\n#     import zipfile\n#     with zipfile.ZipFile(\"archive.zip\",\"r\") as zip_ref:\n#         zip_ref.extractall(\"./\")\n# else:\n#     !kaggle datasets download -d $DATASET_NAME\n#     !unzip -n $DATASET_ZIP","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-01T12:01:12.956938Z","iopub.execute_input":"2022-10-01T12:01:12.957201Z","iopub.status.idle":"2022-10-01T12:01:12.973788Z","shell.execute_reply.started":"2022-10-01T12:01:12.957170Z","shell.execute_reply":"2022-10-01T12:01:12.972886Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Download Assets","metadata":{}},{"cell_type":"code","source":"# if USE_UPDATED_DATASET:\n#     dwd_url = ASSETS_DOWNLOAD_URL\n#     splitted = dwd_url.split(\"/\")\n#     dwd_file_name = splitted[len(splitted)-1]\n\n#     !wget $dwd_url\n#     !mv $dwd_file_name archive.zip\n#     import zipfile\n#     with zipfile.ZipFile(\"archive.zip\",\"r\") as zip_ref:\n#         zip_ref.extractall(\"./\")","metadata":{"execution":{"iopub.status.busy":"2022-10-01T12:01:12.975118Z","iopub.execute_input":"2022-10-01T12:01:12.975426Z","iopub.status.idle":"2022-10-01T12:01:12.988892Z","shell.execute_reply.started":"2022-10-01T12:01:12.975383Z","shell.execute_reply":"2022-10-01T12:01:12.988090Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### creating directory architecture","metadata":{}},{"cell_type":"code","source":"!mkdir $MODEL_PATH\n!mkdir $MODEL_PATH/epoch\n!mkdir $DATASET_PATH\n!mkdir $TEST_SET_PATH\n!mkdir $STORE_PATH\n!mkdir $DATASET_COPY_PATH\n!mkdir $SAVED_MODEL_PATH\n!mkdir $ASSETS_PATH","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:30:13.140685Z","iopub.execute_input":"2022-10-04T14:30:13.141861Z","iopub.status.idle":"2022-10-04T14:30:22.068118Z","shell.execute_reply.started":"2022-10-04T14:30:13.141801Z","shell.execute_reply":"2022-10-04T14:30:22.066640Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘/kaggle/input/nsfw-content-moderation/images’: Read-only file system\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Moving files downloaded to dataset","metadata":{}},{"cell_type":"code","source":"# for path in os.listdir(DATASET_PATH):\n#     cmd = \"rm -r {}/\".format(os.path.join(DATASET_PATH, path))\n#     print(\"deleting => {}\".format(path))\n#     os.system(cmd)\n    \n# os.system(\"cp -r {1}/* {0}/ \".format(DATASET_PATH, DATASET_DUMP_PATH))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-01T12:01:21.748324Z","iopub.execute_input":"2022-10-01T12:01:21.748605Z","iopub.status.idle":"2022-10-01T12:01:21.753477Z","shell.execute_reply.started":"2022-10-01T12:01:21.748573Z","shell.execute_reply":"2022-10-01T12:01:21.752162Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Delete unwanted paths","metadata":{}},{"cell_type":"code","source":"# for path in UNWATED_PATHS:\n#     cmd = \"rm -r {}/\".format(os.path.join(DATASET_PATH, path))\n#     print(\"deleting => {}\".format(path))\n#     os.system(cmd)","metadata":{"execution":{"iopub.status.busy":"2022-10-01T12:01:21.754988Z","iopub.execute_input":"2022-10-01T12:01:21.755294Z","iopub.status.idle":"2022-10-01T12:01:21.766014Z","shell.execute_reply.started":"2022-10-01T12:01:21.755262Z","shell.execute_reply":"2022-10-01T12:01:21.764969Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### resolving dataset relashionships","metadata":{}},{"cell_type":"code","source":"DATA_RELATIONSHIP = [\n    {\n        \"output\": \"male_sexy\",\n        \"classes\": [\"male_underwear\", \"male_shirtless\"]\n    },\n    {\n        \"output\": \"female_sexy\",\n        \"classes\": [\"female_swimwear\", \"female_underwear\"]\n    }\n]\n\ncmds = [] #=> {\"label\": \"\", \"cmd\"}\nif USE_DATA_RELATIONSHIP:\n    for data_relationshp in DATA_RELATIONSHIP:\n        cmds.append({\n            \"label\": \"creating output dir => {}\".format(data_relationshp[\"output\"]),\n            \"cmd\": \"mkdir {0}/{1}\".format(DATASET_PATH, data_relationshp[\"output\"])\n        })\n\n        for current_class in data_relationshp[\"classes\"]:\n            cmds.append({\n                \"label\": \"copying images from {0} to {1}\".format(current_class, data_relationshp[\"output\"]),\n                \"cmd\": \"cp -r {0}/{1}/* {0}/{2}\".format(DATASET_PATH, current_class, data_relationshp[\"output\"])\n            })\n\n            cmds.append({\n                \"label\": \"removing {}\".format(current_class),\n                \"cmd\": \"rm -r {0}/{1}\".format(DATASET_PATH, current_class)\n            })\n        \nfor cmd in cmds:\n    print(cmd[\"label\"])\n    os.system(cmd[\"cmd\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:31:08.576317Z","iopub.execute_input":"2022-10-04T14:31:08.576749Z","iopub.status.idle":"2022-10-04T14:31:08.586953Z","shell.execute_reply.started":"2022-10-04T14:31:08.576707Z","shell.execute_reply":"2022-10-04T14:31:08.586010Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### adding more images","metadata":{}},{"cell_type":"code","source":"SUP_IMAGES_META = [\n    {\n        \"collection_ids\": [\"500522\", \"812584\", \"1450720\"],\n        \"class_name\": \"general_not_nsfw_not_suggestive\"\n    }\n]\n\nif DOWNLOAD_ADDITIONAL_IMAGES:\n    for sum_image_meta in SUP_IMAGES_META:\n        if not sum_image_meta[\"class_name\"] in os.listdir(DATASET_PATH):\n            print(\"skipping => \", sum_image_meta[\"class_name\"])\n            continue\n        for collection_id in sum_image_meta[\"collection_ids\"]:\n            print(\"downloading images for class => \", sum_image_meta[\"class_name\"], \"; collection_id => \", collection_id)\n            download_collection_from_unsplash(collection_id,sum_image_meta[\"class_name\"], store=DATASET_PATH)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-04T14:31:09.603618Z","iopub.execute_input":"2022-10-04T14:31:09.604784Z","iopub.status.idle":"2022-10-04T14:31:09.613068Z","shell.execute_reply.started":"2022-10-04T14:31:09.604717Z","shell.execute_reply":"2022-10-04T14:31:09.611926Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Handle image opening errors","metadata":{}},{"cell_type":"code","source":"data_sub_directories = os.listdir(DATASET_PATH)\nfor data_sub_directory in data_sub_directories:   \n    delete_unreadable_images(os.path.join(DATASET_PATH, data_sub_directory))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-04T14:31:13.699982Z","iopub.execute_input":"2022-10-04T14:31:13.700279Z","iopub.status.idle":"2022-10-04T14:31:55.192226Z","shell.execute_reply.started":"2022-10-04T14:31:13.700250Z","shell.execute_reply":"2022-10-04T14:31:55.190999Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Preview Images","metadata":{}},{"cell_type":"code","source":"preview_images_from_directory(DATASET_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:31:55.196936Z","iopub.execute_input":"2022-10-04T14:31:55.197210Z","iopub.status.idle":"2022-10-04T14:32:02.000297Z","shell.execute_reply.started":"2022-10-04T14:31:55.197180Z","shell.execute_reply":"2022-10-04T14:32:01.999153Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"rm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/neutral/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/neutral/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/porn/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/porn/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/hentai/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/hentai/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/sexy/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/sexy/..'\nrm: cannot remove '/kaggle/input/nsfw-content-moderation/images/.ipynb_checkpoints': No such file or directory\nrm: cannot remove '/kaggle/input/nsfw-content-moderation/images/.DS_Store': No such file or directory\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Textarea(value='0', description='index', placeholder='current index goes here')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d37947a120c64e25b68f34e1a5fcda32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Current', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a69a6b38357345cdb54b2f73c3b85d18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Prev', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211706fcdbd949c39a7c93793b5221ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Next', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f8bba6d1b8f4dc6a904da8672b79e6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07735ff27ce941d3b2ad8033ec077799"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Order Images","metadata":{}},{"cell_type":"code","source":"data_dir = DATASET_PATH\nclean_up_data_dir(data_dir)        \ndata_sub_directories = os.listdir(data_dir)\nif REDUCE_DATASET_IMAGES:\n    for data_sub_directory in data_sub_directories:\n        files = os.listdir(os.path.join(data_dir, data_sub_directory))\n        total_image_num = len(files)\n        max_image = MAX_IMAGE_PER_SEVERE_CLASS if (data_sub_directory in SEVERE_CLASSES) else MAX_IMAGE_PER_CLASS\n        if total_image_num > max_image:\n            remove_randomly_dir_files(os.path.join(data_dir, data_sub_directory), limit=(total_image_num - max_image))        \n            print(\"found {0} for class {1}; removing {2}\".format(total_image_num, data_sub_directory, total_image_num - max_image))\n        else:\n            print(\"found {0} for class {1}; removing 0\".format(total_image_num, data_sub_directory))","metadata":{"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-10-04T14:32:02.003292Z","iopub.execute_input":"2022-10-04T14:32:02.003607Z","iopub.status.idle":"2022-10-04T14:32:08.631617Z","shell.execute_reply.started":"2022-10-04T14:32:02.003573Z","shell.execute_reply":"2022-10-04T14:32:08.630358Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"rm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/neutral/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/neutral/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/porn/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/porn/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/hentai/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/hentai/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/sexy/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/sexy/..'\nrm: cannot remove '/kaggle/input/nsfw-content-moderation/images/.ipynb_checkpoints': No such file or directory\nrm: cannot remove '/kaggle/input/nsfw-content-moderation/images/.DS_Store': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"classes_meta = {\n#     \"female_nudity\": {\n#         \"childs\":[\"general_nsfw\"]\n#     },\n    \n#     \"general_nsfw\":{\n#         \"childs\": [\"female_nudity\"]\n#     },\n    \n#     \"female_underwear\":{\n#         \"childs\": [\"male_underwear\"]\n#     },\n#     \"male_underwear\":{\n#         \"childs\": [\"female_underwear\"]\n#     }\n}\n\n\ndata_dir = DATASET_PATH\ndata = []\ndata_sub_directories = os.listdir(data_dir)\nfor data_sub_directory in data_sub_directories:\n    files = os.listdir(os.path.join(data_dir, data_sub_directory))\n    for file in files:\n        file_meta = {}\n        file_meta[\"filenames\"]=os.path.join(data_sub_directory, file)\n        \n        class_childs = []\n        if data_sub_directory in classes_meta and USE_DATA_RELATIONSHIP:\n            class_childs = classes_meta[data_sub_directory][\"childs\"]\n\n        for current_class_name in data_sub_directories:\n            if current_class_name == data_sub_directory or current_class_name in class_childs:\n                file_meta[current_class_name] = str(1).replace(\".0\", \"\")                        \n            else:\n                file_meta[current_class_name] = str(0)\n        data.append(file_meta)\n\ndf = pd.DataFrame(data)\ndf.to_csv(CSV_DATASET_PATH, encoding='utf-8', index=False)\n\nprint(\"done => \", len(data))\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:32:57.880026Z","iopub.execute_input":"2022-10-04T14:32:57.880621Z","iopub.status.idle":"2022-10-04T14:32:57.994479Z","shell.execute_reply.started":"2022-10-04T14:32:57.880565Z","shell.execute_reply":"2022-10-04T14:32:57.993549Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"done =>  6698\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                filenames neutral  porn  \\\ncount                                                6698    6698  6698   \nunique                                               6698       2     2   \ntop     neutral/f3fe22ae-43e6-11ed-8c0b-0242ac13020240...       0     0   \nfreq                                                    1    4749  4751   \n\n       hentai  sexy  \ncount    6698  6698  \nunique      2     2  \ntop         0     0  \nfreq     5425  5169  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filenames</th>\n      <th>neutral</th>\n      <th>porn</th>\n      <th>hentai</th>\n      <th>sexy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6698</td>\n      <td>6698</td>\n      <td>6698</td>\n      <td>6698</td>\n      <td>6698</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>6698</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>neutral/f3fe22ae-43e6-11ed-8c0b-0242ac13020240...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>4749</td>\n      <td>4751</td>\n      <td>5425</td>\n      <td>5169</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"local_file = FileLink(CSV_DATASET_PATH, result_html_prefix=\"Click here to download: \")\ndisplay(local_file)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:33:01.051792Z","iopub.execute_input":"2022-10-04T14:33:01.052482Z","iopub.status.idle":"2022-10-04T14:33:01.060798Z","shell.execute_reply.started":"2022-10-04T14:33:01.052412Z","shell.execute_reply":"2022-10-04T14:33:01.059526Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"/kaggle/working/image_dataset.csv","text/html":"Click here to download: <a href='image_dataset.csv' target='_blank'>image_dataset.csv</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### reduce images  number for a custom class","metadata":{}},{"cell_type":"code","source":"# data_dir = DATASET_PATH\n# clean_up_data_dir(data_dir)\n# MAX_IMAGE_PER_CLASS = 1668\n# data_sub_directories = os.listdir(data_dir)\n# for unwanted_dir in UNWATED_PATHS:\n#     try:\n#         del data_sub_directories[data_sub_directories.index(unwanted_dir)]\n#     except Exception as e:\n#         pass\n\n# for data_sub_directory in data_sub_directories:\n#     files = os.listdir(os.path.join(data_dir, data_sub_directory))\n#     total_image_num = len(files)\n#     if total_image_num > MAX_IMAGE_PER_CLASS:\n#         remove_randomly_dir_files(os.path.join(data_dir, data_sub_directory), limit=(total_image_num - MAX_IMAGE_PER_CLASS))\n\n#         print(\"found {0} for class {1}; removing {2}\".format(total_image_num, data_sub_directory, total_image_num - MAX_IMAGE_PER_CLASS))\n#     else:\n#         print(\"found {0} for class {1}; removing 0\".format(total_image_num, data_sub_directory))","metadata":{"execution":{"iopub.status.busy":"2022-10-01T12:03:09.832778Z","iopub.execute_input":"2022-10-01T12:03:09.833296Z","iopub.status.idle":"2022-10-01T12:03:09.840731Z","shell.execute_reply.started":"2022-10-01T12:03:09.833259Z","shell.execute_reply":"2022-10-01T12:03:09.839625Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### rename files in datatset","metadata":{}},{"cell_type":"code","source":"# for data_sub_directory in data_sub_directories:\n#     print(\"1# renaming files in {}\".format(data_sub_directory))\n#     rename_all_files(os.path.join(data_dir, data_sub_directory))","metadata":{"execution":{"iopub.status.busy":"2022-10-01T12:03:09.842355Z","iopub.execute_input":"2022-10-01T12:03:09.842716Z","iopub.status.idle":"2022-10-01T12:03:09.856119Z","shell.execute_reply.started":"2022-10-01T12:03:09.842607Z","shell.execute_reply":"2022-10-01T12:03:09.855150Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Send data online","metadata":{}},{"cell_type":"code","source":"# data_dir = DATASET_PATH\n# # clean_up_data_dir(data_dir)        \n# data_sub_directories = os.listdir(data_dir)\n# dataset_api_access_token = \"ZWbw9GYgHG616YljqLtfDK9FPwZ\"\n# dataset_id = \"5710a157-6e60-4818-a749-c577c85d8164\"\n# dataset_api_url = \"https://4tro8cx1.directus.app/{0}?access_token={1}\"\n# dataset_id = \"5710a157-6e60-4818-a749-c577c85d8164\"\n# if DEPLOY_DATASET_TO_SERVER:\n#     for data_sub_directory in data_sub_directories:\n#         files = os.listdir(os.path.join(data_dir, data_sub_directory))\n#         total_files = len(files)\n#         print(\"processing {0}: {1} files\".format(data_sub_directory, total_files))\n#         count = 1\n#         for file in files:\n#             try:\n#                 file_path = os.path.join(data_dir, data_sub_directory, file)\n#                 file_name = id\n#                 files = {'file': (os.path.basename(file_path), open(file_path, 'rb'), mimetypes.MimeTypes().guess_type(file_path)[0])}\n#                 r=requests.post(dataset_api_url.format(\"files\", dataset_api_access_token),files=files)\n#                 image_id = r.json()[\"data\"][\"id\"]\n#                 payload = json.dumps(\n#                     {\n#                     \"dataset_id\": dataset_id,\n#                     \"class_names\": [data_sub_directory],\n#                     \"image\": image_id,\n#                     \"export_path\": file_path \n#                     }\n#                 )\n#                 headers = {\"Content-Type\": 'application/json'}\n#                 r=requests.post(dataset_api_url.format(\"items/image_dataset_save\", dataset_api_access_token), data=payload, headers=headers)\n#                 print(\"success: {0}/{1}: {2} => {3}\".format(count, total_files, data_sub_directory, file_path))\n#             except Exception as e:\n#                 print(\"error: {0}/{1}: {2} => {3}\".format(count, total_files, data_sub_directory, file_path))\n#             count+=1\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-01T12:03:09.857606Z","iopub.execute_input":"2022-10-01T12:03:09.857932Z","iopub.status.idle":"2022-10-01T12:03:09.869948Z","shell.execute_reply.started":"2022-10-01T12:03:09.857889Z","shell.execute_reply":"2022-10-01T12:03:09.868885Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### log dataset state","metadata":{}},{"cell_type":"code","source":"data_dir = DATASET_PATH\nclean_up_data_dir(data_dir)\ndata_sub_directories = os.listdir(data_dir)\nfor unwanted_dir in UNWATED_PATHS:\n    try:\n        del data_sub_directories[data_sub_directories.index(unwanted_dir)]\n    except Exception as e:\n        pass\n\nfor data_sub_directory in data_sub_directories:\n    print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-04T14:33:06.855498Z","iopub.execute_input":"2022-10-04T14:33:06.856109Z","iopub.status.idle":"2022-10-04T14:33:13.532280Z","shell.execute_reply.started":"2022-10-04T14:33:06.856049Z","shell.execute_reply":"2022-10-04T14:33:13.530732Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"rm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/neutral/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/neutral/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/porn/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/porn/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/hentai/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/hentai/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/sexy/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/sexy/..'\nrm: cannot remove '/kaggle/input/nsfw-content-moderation/images/.ipynb_checkpoints': No such file or directory\nrm: cannot remove '/kaggle/input/nsfw-content-moderation/images/.DS_Store': No such file or directory\nfound 1949 for class neutral\nfound 1947 for class porn\nfound 1273 for class hentai\nfound 1529 for class sexy\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## save dataset","metadata":{}},{"cell_type":"code","source":"# if DEPLOY_DATASET_TO_SERVER:\n#     os.system(\"cp {0} {1}\".format(CSV_DATASET_PATH, STORE_PATH)) \n#     os.system(\"cp {0}/*.h5 {1}/\".format(MODEL_PATH, SAVED_MODEL_PATH))\n#     for path in os.listdir(DATASET_PATH):\n#         cmd = \"rm -r {}/\".format(os.path.join(DATASET_COPY_PATH, path))\n#         print(\"deleting => {}\".format(path))\n#         os.system(cmd)\n#     os.system(\"cp -r {0}/* {1}\".format(DATASET_PATH, DATASET_COPY_PATH))\n#     os.system(\"rm -r {0}/{1}\".format(STORE_PATH, DATASET_DUMP_PATH.split(\"/\")[0]))\n#     os.system(\"cp -r {0} {1}/{2}\".format(DATASET_DUMP_PATH.split(\"/\")[0], STORE_PATH, DATASET_DUMP_PATH.split(\"/\")[0]))","metadata":{"execution":{"iopub.status.busy":"2022-10-01T12:03:20.822033Z","iopub.execute_input":"2022-10-01T12:03:20.822390Z","iopub.status.idle":"2022-10-01T12:03:20.828058Z","shell.execute_reply.started":"2022-10-01T12:03:20.822347Z","shell.execute_reply":"2022-10-01T12:03:20.827124Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"#### updating kaggle dataset version ","metadata":{}},{"cell_type":"code","source":"# if DEPLOY_DATASET_TO_SERVER:\n#     !kaggle datasets status $DATASET_NAME\n#     !kaggle datasets metadata -p $STORE_PATH $DATASET_NAME\n#     save_path = 'updated_data_{}'.format(time.time())\n#     !kaggle datasets version -p $STORE_PATH -m $save_path --dir-mode zip","metadata":{"execution":{"iopub.status.busy":"2022-10-01T12:03:20.829657Z","iopub.execute_input":"2022-10-01T12:03:20.829992Z","iopub.status.idle":"2022-10-01T12:03:20.841069Z","shell.execute_reply.started":"2022-10-01T12:03:20.829949Z","shell.execute_reply":"2022-10-01T12:03:20.839994Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#### zip dataset","metadata":{}},{"cell_type":"code","source":"\n# os.system(\"cp -r {1}/* {0}/ \".format(DATASET_COPY_PATH, DATASET_DUMP_PATH))\n# shutil.make_archive(DATASET_COPY_PATH.split()[len(DATASET_COPY_PATH.split())-1], 'zip', DATASET_COPY_PATH)\n# local_file = FileLink(\"{0}.zip\".format(DATASET_COPY_PATH.split()[len(DATASET_COPY_PATH.split())-1]), result_html_prefix=\"Download dataset: \")\n# display(local_file)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-01T12:03:20.842463Z","iopub.execute_input":"2022-10-01T12:03:20.842801Z","iopub.status.idle":"2022-10-01T12:03:20.854110Z","shell.execute_reply.started":"2022-10-01T12:03:20.842747Z","shell.execute_reply":"2022-10-01T12:03:20.853109Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Training part","metadata":{}},{"cell_type":"markdown","source":"## Import required modules","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport math\nimport tensorflow_hub as hub\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix\n# import tensorflow_addons as tfa\nimport pathlib\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.applications import imagenet_utils\n#from imutils.object_detection import non_max_suppression\nfrom PIL import Image \nimport scipy\nimport numpy as np\nimport argparse\nimport imutils\nimport time\nimport requests\nfrom io import BytesIO\nfrom IPython.display import display, Markdown, clear_output\nfrom IPython.display import Image as IImage \nimport ipywidgets as widgets\nfrom PIL import ImageFilter\nimport os\nimport pandas as pd\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom IPython.display import FileLink","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-10-04T14:33:23.489296Z","iopub.execute_input":"2022-10-04T14:33:23.490264Z","iopub.status.idle":"2022-10-04T14:33:24.368613Z","shell.execute_reply.started":"2022-10-04T14:33:23.490189Z","shell.execute_reply":"2022-10-04T14:33:24.367575Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Test tensorflow gpu","metadata":{}},{"cell_type":"code","source":"phisical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\nprint(phisical_devices)\nif len(phisical_devices) > 0: \n    tf.config.experimental.set_memory_growth(phisical_devices[0], True)\n    print(\"GPU activated with {}\".format(phisical_devices[0]))\nelse:\n    print(\"No compatible GPU device found\")\n# print(tf.test.is_gpu_available())\n# print(tf.config.list_pZZzhysical_devices('GPU'))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-10-04T14:33:28.751214Z","iopub.execute_input":"2022-10-04T14:33:28.751519Z","iopub.status.idle":"2022-10-04T14:33:28.768901Z","shell.execute_reply.started":"2022-10-04T14:33:28.751488Z","shell.execute_reply":"2022-10-04T14:33:28.768071Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[]\nNo compatible GPU device found\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Defining main variables","metadata":{}},{"cell_type":"code","source":"EPOCHS=30\nPATIENCE=3\nLR = 1e-4\ndimensions = (IMAGE_RES, IMAGE_RES)\nbatch_size = 32#32\ndata_dir = DATASET_PATH\ncsv_dataset = CSV_DATASET_PATH","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-10-04T14:33:33.095834Z","iopub.execute_input":"2022-10-04T14:33:33.096836Z","iopub.status.idle":"2022-10-04T14:33:33.102055Z","shell.execute_reply.started":"2022-10-04T14:33:33.096792Z","shell.execute_reply":"2022-10-04T14:33:33.100975Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Main functions","metadata":{}},{"cell_type":"code","source":"def sliding_window(image, step, ws):\n    # slide a window across the image\n    for y in range(0, image.shape[0] - ws[1], step):\n        for x in range(0, image.shape[1] - ws[0], step):\n            # yield the current window\n            yield (x, y, image[y:y + ws[1], x:x + ws[0]])\n            \ndef image_pyramid(image, scale=1.5, minSize=(IMAGE_RES, IMAGE_RES)):\n    # yield the original image\n    yield image\n    # keep looping over the image pyramid\n    while True:\n        # compute the dimensions of the next image in the pyramid\n        w = int(image.shape[1] / scale)\n        image = imutils.resize(image, width=w)\n        # if the resized image does not meet the supplied minimum\n        # size, then stop constructing the pyramid\n        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n            break\n        # yield the next image in the pyramid\n        yield image\n        \ndef sub_plot_images(image, title,elem_place=1,show = True, figsize=(1, 1), plt_hspace = 0.8, vertical=1, horizontal=5):\n    if show:\n        if not figsize == (1, 1):\n            plt.figure(figsize=figsize)\n\n        plt.subplot(vertical,horizontal,elem_place)\n        plt.subplots_adjust(hspace = plt_hspace)\n        plt.title(title)\n        plt.imshow(image)\n        \n        \ndef detect_adult_picture_from_url(url, prod=True, pass_neutral=True, figsize=(30, 30), WIDTH = 600, PYR_SCALE = 1.5, WIN_STEP = 16, ROI_SIZE = (250, 250), INPUT_SIZE = (IMAGE_RES, IMAGE_RES), probaLimit = 0.5):\n    req = requests.get(url, stream=True)\n    image = np.asarray(bytearray(req.content), dtype=\"uint8\")\n    imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n    imageRGB = cv2.cvtColor(imageBGR , cv2.COLOR_BGR2RGB)\n    detect_adult_picture(imageRGB, prod, pass_neutral, figsize, WIDTH, PYR_SCALE, WIN_STEP, ROI_SIZE, INPUT_SIZE, probaLimit)\n    \"\"\"\n    image = Image.open(requests.get(url, stream=True).raw)\n\n    image_loaded = tf.keras.preprocessing.image.img_to_array(image)\n    \n    detect_adult_picture(image_loaded/255, prod, plotprocess)\n    \"\"\"\n    \ndef predict_from_file_url(count_start=0, count_set = 10, src=\"validation-adult.txt\"):\n    figsize = (40, 40)\n    image_input_file = open(src, \"r\")\n    image_input_file = [image_input_fileS for image_input_fileS in image_input_file]\n    total = len(image_input_file)\n    \n    for url in image_input_file[count_start:count_set]:\n        try:\n            detect_adult_picture_from_url(url, True, False)\n        except Exception as wrong: \n            pass\n        \ndef detect_adult_picture_from_array(array, prod=True, pass_neutral=True, figsize=(30, 30), WIDTH = 600, PYR_SCALE = 1.5, WIN_STEP = 16, ROI_SIZE = (250, 250), INPUT_SIZE = (IMAGE_RES, IMAGE_RES), probaLimit = 0.5):\n    detect_adult_picture(array, prod, pass_neutral, figsize, WIDTH, PYR_SCALE, WIN_STEP, ROI_SIZE, INPUT_SIZE, probaLimit)\n\n\ndef calculate_average(pred):\n    if pred == 0:\n        return 1\n    elif pred < 0.5 and pred !=0:\n        return (0.5-pred)/0.5\n    elif pred >= 0.5 and pred !=1:\n         return (pred-0.5)/0.5\n    else:\n        return 1\n    \ndef decode_prediction(predictions):\n    decoded_class_index = []\n    decode_prediction_precision = []\n    \n    for prediction in predictions:\n        result = 0 if prediction < 0.5 else 1\n        precision = calculate_average(prediction)\n        decoded_class_index.append(result)\n        decode_prediction_precision.append(precision)\n    return np.array(decoded_class_index), np.array(decode_prediction_precision),predictions\n\n\ndef detect_adult_picture(image, prod=True, pass_neutral=True, figsize=(30, 30), WIDTH = 600, PYR_SCALE = 1.5, WIN_STEP = 16, ROI_SIZE = (250, 250), INPUT_SIZE = (IMAGE_RES, IMAGE_RES), probaLimit = 0.5):\n    plt.figure(figsize=figsize)\n    orig = image\n    scanned = orig.copy()\n    neutral = scanned\n    orig = imutils.resize(orig, width=WIDTH)\n    \n    sub_plot_images(orig, \"input\", 1, prod)\n\n    \n    (H, W) = orig.shape[:2]\n    pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)\n    # initialize two lists, one to hold the ROIs generated from the image\n    # pyramid and sliding window, and another list used to store the\n    # (x, y)-coordinates of where the ROI was in the original image\n    rois = []\n    locs = []\n    # time how long it takes to loop over the image pyramid layers and\n    # sliding window locations\n    start = time.time()\n    for image in pyramid:\n    # determine the scale factor between the *original* image\n    # dimensions and the *current* layer of the pyramid\n        scale = W / float(image.shape[1])\n        # for each layer of the image pyramid, loop over the sliding\n        # window locations\n        for (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n            # scale the (x, y)-coordinates of the ROI with respect to the\n            # *original* image dimensions\n            x = int(x * scale)\n            y = int(y * scale)\n            w = int(ROI_SIZE[0] * scale)\n            h = int(ROI_SIZE[1] * scale)\n            # take the ROI and preprocess it so we can later classify\n            # the region using Keras/TensorFlow\n            roi = cv2.resize(roiOrig, INPUT_SIZE)\n            roi = img_to_array(roi)\n            roi = preprocess_input(roi)\n            # update our list of ROIs and associated coordinates\n            rois.append(roi)\n            locs.append((x, y, x + w, y + h))\n    end = time.time()\n    print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(\n        end - start))\n    # convert the ROIs to a NumPy array\n    rois = np.array(rois, dtype=\"float32\")\n    # classify each of the proposal ROIs using ResNet and then show how\n    # long the classifications took\n    print(\"[INFO] classifying ROIs...\")\n    start = time.time()\n    preds = model.predict(rois)\n    end = time.time()\n    print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n        end - start))\n    # decode the predictions and initialize a dictionary which maps class\n    # labels (keys) to any ROIs associated with that label (values)\n    #preds = tf.keras.applications.mobilenet_v2.decode_predictions(preds, top=5)\n    labels = {}\n    count = 0\n    tot = len(preds)\n    probaLimit = 0.5\n\n    for i in range(0, tot):\n        label = class_names[int(np.argmax(preds[count], axis=-1))]\n        prob = 1\n        if prob >= probaLimit:\n            box = locs[i]\n            L = labels.get(label, [])\n            L.append((box, prob))\n            labels[label] = L\n        count+=1\n        \n    for label in labels.keys():\n        # clone the original image so that we can draw on it\n        print(\"[INFO] showing results for '{}'\".format(label))\n        clone = orig.copy()\n        # loop over all bounding boxes for the current label\n        for (box, prob) in labels[label]:\n            # draw the bounding box on the image\n            (startX, startY, endX, endY) = box\n            cv2.rectangle(clone, (startX, startY), (endX, endY),\n                (0, 255, 0), 2)\n        # show the results *before* applying non-maxima suppression, then\n        # clone the image again so we can display the results *after*\n        # applying non-maxima suppression\n        #plt.imshow(clone)\n        clone = orig.copy()\n    # extract the bounding boxes and associated prediction\n    # probabilities, then apply non-maxima suppression\n    boxes = np.array([p[0] for p in labels[label]])\n    proba = np.array([p[1] for p in labels[label]])\n    boxes = non_max_suppression(boxes, proba)\n    # loop over all bounding boxes that were kept after applying\n    # non-maxima suppression\n    \n    \n    for (startX, startY, endX, endY) in boxes:\n        # draw the bounding box and label on the image\n        cv2.rectangle(scanned, (startX, startY), (endX, endY),\n            (0, 255, 0), 2)\n        y = startY - 10 if startY - 10 > 10 else startY + 10\n        cv2.putText(scanned, label, (startX, y),\n            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n        # show the output after apply non-maxima suppression\n        \n    sub_plot_images(scanned, \"scanned\", 2, prod)\n    \n    for (startX, startY, endX, endY) in boxes:\n        if label==\"neutral\":\n            pass\n        else:\n            topLeft =  (startX, startY)\n            bottomRight = (endX, endY)\n            x, y = topLeft[0], topLeft[1]\n            w, h = bottomRight[0] - topLeft[0], bottomRight[1] - topLeft[1]\n\n            # Grab ROI with Numpy slicing and blur\n            ROI = clone[y:y+h, x:x+w]\n            blur = cv2.GaussianBlur(ROI, (51,51), 50) \n            clone[y:y+h, x:x+w] = blur\n            \n    sub_plot_images(clone, \"output\", 3, prod)\n    \n    \ndef detect_adult_picture_no_plot(image, prod=True, pass_neutral=True, figsize=(30, 30), WIDTH = 600, PYR_SCALE = 1.5, WIN_STEP = 16, ROI_SIZE = (250, 250), INPUT_SIZE = (IMAGE_RES, IMAGE_RES), probaLimit = 0.8, ksize = (51,51)):\n    \n    main_ids, main_probs, main_preds =  decode_prediction(model.predict(np.array([cv2.resize(image, INPUT_SIZE)])))\n    if main_probs[0] > probaLimit :\n        return cv2.blur(image, ksize) \n    \n    orig = image\n    copy = orig.copy()\n    orig = imutils.resize(orig, width=WIDTH)\n    \n    (H, W) = orig.shape[:2]\n    pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)\n    # initialize two lists, one to hold the ROIs generated from the image\n    # pyramid and sliding window, and another list used to store the\n    # (x, y)-coordinates of where the ROI was in the original image\n    rois = []\n    locs = []\n    # time how long it takes to loop over the image pyramid layers and\n    # sliding window locations\n    start = time.time()\n    for image in pyramid:\n    # determine the scale factor between the *original* image\n    # dimensions and the *current* layer of the pyramid\n        scale = W / float(image.shape[1])\n        # for each layer of the image pyramid, loop over the sliding\n        # window locations\n        for (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n            # scale the (x, y)-coordinates of the ROI with respect to the\n            # *original* image dimensions\n            x = int(x * scale)\n            y = int(y * scale)\n            w = int(ROI_SIZE[0] * scale)\n            h = int(ROI_SIZE[1] * scale)\n            # take the ROI and preprocess it so we can later classify\n            # the region using Keras/TensorFlow\n            roi = cv2.resize(roiOrig, INPUT_SIZE)\n            roi = img_to_array(roi)\n            roi = preprocess_input(roi)\n            # update our list of ROIs and associated coordinates\n            rois.append(roi)\n            locs.append((x, y, x + w, y + h))\n    end = time.time()\n    print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(\n        end - start))\n    # convert the ROIs to a NumPy array\n    rois = np.array(rois, dtype=\"float32\")\n    # classify each of the proposal ROIs using ResNet and then show how\n    # long the classifications took\n    print(\"[INFO] classifying ROIs...\")\n    start = time.time()\n    preds = model.predict(rois)\n    end = time.time()\n    print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n        end - start))\n    # decode the predictions and initialize a dictionary which maps class\n    # labels (keys) to any ROIs associated with that label (values)\n    #preds = tf.keras.applications.mobilenet_v2.decode_predictions(preds, top=5)\n    labels = {}\n    tot = len(preds)\n    probaLimit = 0.5\n\n    for i in range(0, tot):\n        label = class_names[int(preds[i])]\n        prob = 1\n        box = locs[i]\n        L = labels.get(label, [])\n        L.append((box, prob))\n        labels[label] = L\n        \n    for label in labels.keys():\n        # clone the original image so that we can draw on it\n        print(\"[INFO] showing results for '{}'\".format(label))\n        clone = orig.copy()\n        # loop over all bounding boxes for the current label\n        for (box, prob) in labels[label]:\n            # draw the bounding box on the image\n            (startX, startY, endX, endY) = box\n            cv2.rectangle(clone, (startX, startY), (endX, endY),\n                (0, 255, 0), 2)\n        # show the results *before* applying non-maxima suppression, then\n        # clone the image again so we can display the results *after*\n        # applying non-maxima suppression\n        #plt.imshow(clone)\n        clone = orig.copy()\n    # extract the bounding boxes and associated prediction\n    # probabilities, then apply non-maxima suppression\n    boxes = np.array([p[0] for p in labels[label]])\n    proba = np.array([p[1] for p in labels[label]])\n    boxes = non_max_suppression(boxes, proba)\n    # loop over all bounding boxes that were kept after applying\n    # non-maxima suppression\n    \n    \n    for (startX, startY, endX, endY) in boxes:\n        if label==\"neutral\":\n            pass\n        else:\n            topLeft =  (startX, startY)\n            bottomRight = (endX, endY)\n            x, y = topLeft[0], topLeft[1]\n            w, h = bottomRight[0] - topLeft[0], bottomRight[1] - topLeft[1]\n\n            # Grab ROI with Numpy slicing and blur\n            ROI = clone[y:y+h, x:x+w]\n            blur = cv2.GaussianBlur(ROI, (51,51), 50) \n            clone[y:y+h, x:x+w] = blur\n            \n    return clone\n\n\n\n\n\ndef predict_batch(images):\n    predicted_indexes, confidences, predictions = decode_prediction(model.predict(np.array(images)))\n    predicted_labels = []\n    for predicted_index in predicted_indexes:\n        #print(predictions[i])\n        predicted_labels.append(class_names[predicted_index])\n        \n    return predicted_labels, confidences, predicted_indexes\n\n\ndef predict_from_txt_urls(src='test-urls.txt', start=0, limit=10, figsize=(30, 30), verbose=False):\n    urls = []\n    \n    with open(src) as f:\n        lines = [line.rstrip() for line in f]\n        tot = len(lines)\n        count = 0\n        for url in lines[start:limit]:\n            count+=1\n            urls.append(url)\n            try:\n                if verbose:\n                    print(count, \"/\", tot, \"dwd => \", url)\n                \n            except Exception as wrong:\n                if verbose:\n                    print(count, \"/\", tot, \"error => \",wrong)\n                pass\n\n    predict_from_urls(urls, figsize=figsize, verbose=verbose)\n        \n        \ndef predict_from_urls(urls, figsize=(30, 30), verbose=False):\n    images = []\n    tot = len(urls)\n    count=0\n    for url in urls:\n            count+=1\n            try:\n                if verbose:\n                    print(count, \"/\", tot, \"dwd => \", url)\n                req = requests.get(url, stream=True)\n                image = np.asarray(bytearray(req.content), dtype=\"uint8\")\n                imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n                imageRGB = cv2.cvtColor(imageBGR , cv2.COLOR_BGR2RGB)\n\n                images.append(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255)\n            except Exception as wrong:\n                if verbose:\n                    print(count, \"/\", tot, \"error => \",wrong)\n                pass\n    predicted_labels, confidences, predicted_indexes = predict_batch(np.array(images))\n    \n    rangeTot = len(images)\n\n    plt.figure(figsize=figsize)\n    if len(images) == 1:\n        plt.title(predicted_labels[0]+\" \"+str(confidences[0]))\n        plt.imshow(images[0])\n    else:  \n        for i in range(rangeTot):\n            plt.subplot(rangeTot,int((rangeTot)/2),i+1)\n            plt.subplots_adjust(hspace = 0.8)\n            #color = \"blue\" if predicted_ids[i] == label_batch[i] else \"red\"\n            plt.title(predicted_labels[i]+\" \"+str(confidences[i]))#, color=color)\n            #plt.imshow(images[i]/255 if predicted_labels[i]==\"neutral\" else ndimage.gaussian_filter(images[i]/255, sigma=2))\n            plt.imshow(images[i])\n            \ndef clean_up_data_dir():\n    data_sub_directories = os.listdir(data_dir)\n    for data_sub_directory in data_sub_directories:\n        path_to_delete = os.path.join(data_dir, data_sub_directory, \".*\")\n        !rm -r $path_to_delete\n\n    !rm -r $data_dir/.ipynb_checkpoints\n    !rm -r $data_dir/.DS_Store\n\n@tf.function\ndef macro_soft_f1(y, y_hat):\n    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n    Use probability values instead of binary predictions.\n    \n    Args:\n        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n        \n    Returns:\n        cost (scalar Tensor): value of the cost function for the batch\n    \"\"\"\n    y = tf.cast(y, tf.float32)\n    y_hat = tf.cast(y_hat, tf.float32)\n    tp = tf.reduce_sum(y_hat * y, axis=0)\n    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n    macro_cost = tf.reduce_mean(cost) # average on all labels\n    return macro_cost\n@tf.function\ndef macro_f1(y, y_hat, thresh=0.5):\n    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n    \n    Args:\n        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n        thresh: probability value above which wse predict positive\n        \n    Returns:\n        macro_f1 (scalar Tensor): value of macro F1 for the batch\n    \"\"\"\n    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    macro_f1 = tf.reduce_mean(f1)\n    return macro_f1\n\n\n%matplotlib inline\ndef interpret_prediction(predicted_batch, get_images=False, image_set=[]):\n    # np_prediction = predicted_batch.numpy()\n    decoded_predictions = []\n    decoded_main_predictions_classes = []\n    max_indices = [(lambda pr: class_names[np.argmax(pr, axis=-1)])(predicton) for predicton in predicted_batch]\n    for count in range(0, len(predicted_batch)):\n        prd_btch = predicted_batch[count]\n        decoded_part = []\n        for i in range(0, num_classes):\n            decoded_prediction = {}\n            decoded_prediction[\"class_name\"] = class_names[i]\n            try:\n                decoded_prediction[\"probability\"] = prd_btch[i].numpy()\n            except Exception as e:\n                decoded_prediction[\"probability\"] = prd_btch[i]\n            decoded_prediction[\"precision\"] = np.sum(prd_btch[i]) / num_classes\n            \n            # decoded_prediction[\"count_index\"] = count\n        \n            if get_images:\n                decoded_prediction[\"image\"] = image_set[count]\n            decoded_part.append(decoded_prediction)\n        decoded_predictions.append(decoded_part)\n        \n        decoded_main_predictions_classes.append(decoded_part)\n    return decoded_predictions, decoded_main_predictions_classes, max_indices\n    \n\ndef predict_single_image_from_path(path, break_line=True):\n    image = cv2.imread(path)\n    # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n    imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n    image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n    prediction = model.predict(np.array([image_resized]))\n    decoded_predictions, decoded_main_predictions_classes, max_indices = interpret_prediction(prediction)\n\n    # to_print = \"{0} \\n {1} \\n {2}\".format(decoded_predictions, decoded_main_predictions_classes, max_indices )\n    to_print = \"\"\n    for i in range(0, len(class_names)):\n         \n        try:\n            prob_str = str(prediction[0][i]*100)[0:5]\n        except Exception as wrong: \n              prob_str = str(prediction[0][i]*100)\n        str_ouput = \"{0} => {1}%; \\n\" if break_line else \"{0} => {1}%;\"\n        to_print  += str_ouput.format( class_names[i], prob_str)\n    # to_print = \"{0} \\n {1}\".format( class_names,  prediction )\n    return to_print, Image.fromarray(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA))\n\ndef predict_single_raw_image(image, break_line=True):\n    prediction = model.predict(image)\n    decoded_predictions, decoded_main_predictions_classes, max_indices = interpret_prediction(prediction)\n\n    # to_print = \"{0} \\n {1} \\n {2}\".format(decoded_predictions, decoded_main_predictions_classes, max_indices )\n    to_print = \"\"\n    for i in range(0, len(class_names)):\n         \n        try:\n            prob_str = str(prediction[0][i]*100)[0:5]\n        except Exception as wrong: \n              prob_str = str(prediction[0][i]*100)\n        str_ouput = \"{0} => {1}%; \\n\" if break_line else \"{0} => {1}%;\"\n        to_print  += str_ouput.format( class_names[i], prob_str)\n    # to_print = \"{0} \\n {1}\".format( class_names,  prediction )\n    \n    return to_print, image\n\n\ndef predict_single_image_from_url(url, break_line=True):\n    image = imutils.url_to_image(url)\n    # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n    imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n    image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n    prediction = model.predict(np.array([image_resized]))\n    decoded_predictions, decoded_main_predictions_classes, max_indices = interpret_prediction(prediction)\n\n    # to_print = \"{0} \\n {1} \\n {2}\".format(decoded_predictions, decoded_main_predictions_classes, max_indices )\n    to_print = \"\"\n    for i in range(0, len(class_names)):\n         \n        try:\n            prob_str = str(prediction[0][i]*100)[0:5]\n        except Exception as wrong: \n              prob_str = str(prediction[0][i]*100)\n        str_ouput = \"{0} => {1}%; \\n\" if break_line else \"{0} => {1}%;\"\n        to_print  += str_ouput.format( class_names[i], prob_str)\n    # to_print = \"{0} \\n {1}\".format( class_names,  prediction )\n    return to_print, Image.fromarray(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA))\n\n\ndef predict_from_path(path=data_dir, group=True):\n    data_dir = path\n    clean_up_data_dir()\n    images_path = []\n    \n    if(group):\n        data_sub_directories = os.listdir(data_dir)\n        for data_sub_directory in data_sub_directories:\n            # images_path+=os.listdir(os.path.join(data_dir, data_sub_directory))\n            print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))\n            for current_dir in os.listdir(os.path.join(data_dir, data_sub_directory)):\n                images_path.append(os.path.join(data_sub_directory, current_dir))\n    else:\n        try:\n            for current_dir in os.listdir(data_dir):\n                images_path.append(os.path.join(data_dir, current_dir))\n        except Exception as wrong:\n            print(wrong)\n            pass\n\n    if not group:\n        data_dir = \".\"\n    \n    bulk_prediction(data_dir, images_path)\n    \ndef bulk_prediction(data_dir=\"\", images_path=[], images=[]):\n    current = 0\n    output = widgets.Output()\n    next_button = widgets.Button(description='Next')\n    prev_button = widgets.Button(description='Prev')\n    display_current_button = widgets.Button(description='Current')\n    current_index_text = widgets.Textarea(\n        value=str(current),\n        placeholder='current index goes here',\n        description='index',\n        disabled=False\n    )\n    \n    display(current_index_text, display_current_button, prev_button, next_button, output)\n    \n    def default_action():\n        global current\n        with output:\n            clear_output()\n            images_store = images_path if len(images_path) > 0 else images\n            \n            print(\"{0}/{1}\".format(current+1, len(images_store)))\n            if len(images_path) > 0:\n                to_print, image = predict_single_image_from_path(os.path.join(data_dir, images_path[current]))\n            else:\n                to_print, image = predict_single_raw_image(images[current])\n            print(to_print)\n            display(image)\n            \n    def on_next_button_clicked(_):\n        global current\n        if current+2 > len(images_path):\n            return None\n        current+=1\n        default_action()\n\n\n    def on_prev_button_clicked(_):\n        global current\n        if current-1 < 0:\n            return None\n        current-=1\n        default_action()\n        \n        \n    def on_current_index_change(_):\n        update_index_change(current_index_text.value)\n\n    def update_index_change(indexString):\n        global current\n        try:\n            current = int(indexString)\n            default_action()\n        except Exception as wrong:\n            print(wrong)\n            pass\n\n    next_button.on_click(on_next_button_clicked)\n    prev_button.on_click(on_prev_button_clicked)\n    display_current_button.on_click(on_current_index_change)\n    current_index_text.on_displayed(update_index_change(str(current)))\n    \n\ndef predict_at_random(base_url=\"https://picsum.photos/{0}/{0}\".format(IMAGE_RES)):\n    again_button = widgets.Button(description='Again')\n    output = widgets.Output()\n    display(again_button, output)\n\n    def on_again_button_clicked(_):\n        with output:\n            clear_output()\n            to_print, image = predict_single_image_from_url(base_url)\n            print(to_print)\n            display(image)\n    \n    with output:\n        clear_output()\n        to_print, image = predict_single_image_from_url(base_url)\n        print(to_print)\n        display(image)\n    \n    again_button.on_click(on_again_button_clicked)\n    \n    \ndef predict_url_batch(urls, figsize=(30, 30), verbose=False, break_line=True):\n    predictions_output = []    \n    images=[]\n    for url in urls:\n        try:\n            image = imutils.url_to_image(url)\n            # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n            imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n            image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n            images.append(np.array([image_resized]))\n        except Exception as wrong:\n            pass\n    bulk_prediction(images=images)\n    \ndef predict_from_txt_file(src='test-urls.txt', start=0, limit=10, figsize=(30, 30), verbose=False, break_line=True):\n    urls = []\n    with open(src) as f:\n        lines = [line.rstrip() for line in f]\n        tot = len(lines)\n        count = 0\n        for url in lines[start:limit]:\n            count+=1\n            urls.append(url)\n            try:\n                if verbose:\n                    print(count, \"/\", tot, \"dwd => \", url)       \n            except Exception as wrong:\n                if verbose:\n                    print(count, \"/\", tot, \"error => \",wrong)\n                pass\n    predict_url_batch(urls, figsize=figsize, verbose=verbose, break_line=break_line)\n    \ndef predict_at_random_download(base_url=\"https://picsum.photos/{0}/{0}\".format(IMAGE_RES), store=DATASET_DUMP_PATH, group=True):\n    selected_class = class_names[0]\n    selected_image = []\n    again_button = widgets.Button(description='Again')\n    download_button = widgets.Button(description='Download')\n    class_selector = widgets.Dropdown(\n        options=class_names,\n        value=selected_class,\n        description='Select a class',\n        disabled=False,\n    )\n\n    output = widgets.Output()\n    display(again_button, class_selector, download_button, output)\n\n    def on_again_button_clicked(_):\n        global selected_image\n        with output:\n            clear_output()\n            to_print, image = predict_single_image_from_url(base_url)\n            selected_image = image\n            print(to_print)\n            display(image)\n            \n    def on_download_button_clicked(_):\n        global selected_image\n        global selected_class\n        with output:\n            try:\n                if group:  \n                    export_path = \"{}.jpg\".format(os.path.join(store, selected_class, str(uuid.uuid1())))\n                else:\n                    export_path = \"{}.jpg\".format(os.path.join(store, str(uuid.uuid1())))\n                print(\"selected class => \", selected_class)\n                print(\"export path => \", export_path)\n                selected_image.save(export_path)\n                local_file = FileLink(export_path, result_html_prefix=\"Click here to download model: \")\n                display(local_file)\n            except Exception as wrong:\n                print(\"error while moving file to =>\", selected_class)\n    def on_class_change(change):\n        global selected_class\n        try:\n            selected_class = class_names[change[\"new\"][\"index\"]]\n        except Exception as wrong:\n            pass\n        \n\n    with output:\n        clear_output()\n        to_print, image = predict_single_image_from_url(base_url)\n        selected_image = image\n        print(to_print)\n        display(image)\n    \n    again_button.on_click(on_again_button_clicked)\n    download_button.on_click(on_download_button_clicked)\n    class_selector.observe(on_class_change)\n    \ndef build_model_sequence(model_config, cleanup=True):\n    print(\"working on => \", model_config[\"name\"])\n    ### LOAD TRAINING DATASET\n    print(\"LOADING TRAINING DATASET FOR \", model_config[\"name\"])\n    if cleanup:\n        clean_up_data_dir()\n    df=pd.read_csv(csv_dataset)\n    \n    base_class_df = df[df[model_config[\"base_class\"]] == 1]\n    base_class_max_sample = model_config[\"base_class_max_sample\"] if model_config[\"base_class_max_sample\"] != -1 else base_class_df.count[\"filenames\"]\n    base_class_df = base_class_df[:base_class_max_sample]\n\n\n    general_class_df = df[df[general_class] == 1]\n    general_class_max_sample = model_config[\"general_class_max_sample\"] if model_config[\"general_class_max_sample\"] != -1 else general_class_df.count[\"filenames\"]\n    general_class_df = general_class_df[:general_class_max_sample]\n    \n    df = base_class_df.append(general_class_df).astype(str)\n    \n    display(df.describe())\n    \n    columns = []\n    for column in data_sub_directories:\n        if column == model_config[\"base_class\"] or column == general_class:\n            columns.append(column)\n            \n    train_datagen = ImageDataGenerator(\n        featurewise_center=model_config[\"featurewise_center\"],\n        samplewise_center=model_config[\"samplewise_center\"],\n        featurewise_std_normalization=model_config[\"featurewise_std_normalization\"],\n        samplewise_std_normalization=model_config[\"samplewise_std_normalization\"],\n        zca_whitening=model_config[\"zca_whitening\"],\n        zca_epsilon=model_config[\"zca_epsilon\"],\n        rotation_range=model_config[\"rotation_range\"],\n        width_shift_range=model_config[\"width_shift_range\"],\n        height_shift_range=model_config[\"height_shift_range\"],\n        brightness_range=model_config[\"brightness_range\"],\n        shear_range=model_config[\"shear_range\"],\n        zoom_range=model_config[\"zoom_range\"],\n        channel_shift_range=model_config[\"channel_shift_range\"],\n        fill_mode=model_config[\"fill_mode\"],\n        cval=model_config[\"cval\"],\n        horizontal_flip=model_config[\"horizontal_flip\"],\n        vertical_flip=model_config[\"vertical_flip\"],\n        rescale=model_config[\"rescale\"],\n        preprocessing_function=model_config[\"preprocessing_function\"],\n        data_format=model_config[\"data_format\"],\n        validation_split=model_config[\"validation_split\"]\n      )\n\n    training_set=train_datagen.flow_from_dataframe(\n        dataframe=df,\n        directory=data_dir,\n        x_col=\"filenames\",\n        y_col=model_config[\"base_class\"],\n        target_size=dimensions,\n        batch_size=batch_size,\n        seed=42,\n        class_mode=\"binary\",\n        subset=\"training\"\n    )\n\n    validation_set=train_datagen.flow_from_dataframe(\n        dataframe=df,\n        directory=data_dir,\n        x_col=\"filenames\",\n        y_col=model_config[\"base_class\"],\n        target_size=dimensions,\n        batch_size=batch_size,\n        seed=42,\n        class_mode=\"binary\",\n        subset=\"validation\"\n    )\n    \n    class_names = columns\n    num_classes = len(class_names)\n    num_samples = training_set.samples + validation_set.samples\n    files_per_class = []\n    for folder in os.listdir(data_dir):\n        if not os.path.isfile(folder):\n                files_per_class.append(len(os.listdir(data_dir + '/' + folder)))\n    total_files = sum(files_per_class)\n    class_weights = {}\n    for i in range(len(files_per_class)):\n        class_weights[i] = 1 - (float(files_per_class[i]) / total_files)\n    print (\"class_weights => \", class_weights)\n    \n    URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n    # URL = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n    try:\n        MODEL_BASE_NAME = model_config[\"name\"]\n    except Exception as e:\n        MODEL_BASE_NAME=\"model_\"\n    feature_extractor = hub.KerasLayer(URL,\n                                   input_shape=(IMAGE_RES, IMAGE_RES, 3))\n    feature_extractor.trainable = False\n    model = tf.keras.Sequential([\n        feature_extractor,\n        tf.keras.layers.Flatten(),\n        layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.summary()\n    \n    print(\"COMPILING MODEL: \", model_config[\"name\"])\n    model.compile(\n      optimizer=tf.keras.optimizers.RMSprop(learning_rate=LR),\n      loss=\"binary_crossentropy\",\n      metrics=[\"accuracy\"]\n    )\n    \n    print(\"TRAINING MODEL: \", model_config[\"name\"])\n    steps_per_epoch = num_samples//model_config[\"batch_size\"]\n    checkpoint_filepath = 'models/epoch/chk.h5'\n\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_filepath,\n        save_weights_only=True,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True)\n\n    stop_training_callback = tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\",\n\n        #min_delta=0,\n        patience=model_config[\"overfitting_patience\"],\n        #verbose=0,\n        #mode=\"auto\",\n        #baseline=None,\n        restore_best_weights=model_config[\"restore_best_weights\"],\n    )\n\n    history = model.fit(training_set,\n                        epochs=model_config[\"epochs\"],\n#                         steps_per_epoch=model_config[\"steps_per_epoch\"],\n                        validation_data=validation_set,\n                        callbacks=[model_checkpoint_callback, stop_training_callback],\n                        # callbacks=[model_checkpoint_callback],\n#                         class_weight=class_weights\n                        )\n    MODELS[model_config[\"name\"]] = {\n        \"history\": history,\n        \"configs\": model_config,\n        \"df\": df,\n        \"model\": model,\n        \"class_names\": columns,\n        \"session_id\": SESSION_ID\n    }\n    \ndef plot_training_history():\n    for model_config in models_config:\n        try:\n            model_data = MODELS[model_config[\"name\"]]\n            print(\"history for => \" , model_config[\"name\"])\n            history = model_data[\"history\"]\n            acc = history.history['accuracy']\n            val_acc = history.history['accuracy']\n            # acc = history.history['accuracy']\n            # val_acc = history.history['accuracy']\n\n            loss = history.history['loss']\n            val_loss = history.history['val_loss']\n\n            plt.figure(figsize=(8, 8))\n            plt.subplot(1, 2, 1)\n            plt.plot(history.epoch, acc, label='Training Accuracy')\n            plt.plot(history.epoch, val_acc, label='Validation Accuracy')\n            plt.legend(loc='lower right')\n            plt.title('Training and Validation Accuracy')\n\n            plt.subplot(1, 2, 2)\n            plt.plot(history.epoch, loss, label='Training Loss')\n            plt.plot(history.epoch, val_loss, label='Validation Loss')\n            plt.legend(loc='upper right')\n            plt.title('Training and Validation Loss')\n            plt.show()\n        except Exception as e:\n            pass\n        \n        \n%matplotlib inline\n\n# def sequence_predict_raw(image_array):\n#     predictions = {}\n#     to_print = \"\"\n#     for model_name in MODELS.keys():\n#         model_data = MODELS[model_name]\n#         model = model_data[\"model\"]\n#         prediction = model.predict(image_array)\n#         class_name = model_data[\"configs\"][\"base_class\"]\n#         predictions[class_name] = prediction[0][0]\n#         try:\n#             prob_str = str(prediction[0][0]*100)[0:5]\n#         except Exception as wrong: \n#               prob_str = str(prediction[0][0]*100)\n#         to_print  += \"{0} => {1}%; \\n\".format( class_name, prob_str)\n#     return to_print, predictions\n\ndef sequence_predict_raw(image_array):\n    predictions = {}\n    raw_predictions = []\n    to_print = \"\"\n    for model_name in MODELS.keys():\n        model_data = MODELS[model_name]\n        model = model_data[\"model\"]\n        prediction = model.predict(image_array)\n        raw_predictions.append({\n            \"prediction\": prediction,\n            \"model_config\": model_data[\"configs\"]\n        })\n        \n        if(len(prediction[0]) < 3):\n            class_name = model_data[\"configs\"][\"base_class\"]\n            predictions[class_name] = prediction[0][0]\n            try:\n                prob_str = str(prediction[0][0]*100)[0:5]\n            except Exception as wrong: \n                  prob_str = str(prediction[0][0]*100)\n            to_print  += \"{0} => {1}%; \\n\".format(class_name, prob_str)\n        else:\n            to_print+= \"{}: \\n\".format(model_data[\"configs\"][\"name\"])\n            for i in range(0, len(prediction[0])):\n                try:\n                    prob_str = str(prediction[0][i]*100)[0:5]\n                except Exception as wrong: \n                    prob_str = str(prediction[0][i]*100)\n                    \n                to_print  += \"    {0} => {1}%; \\n\".format(model_data[\"configs\"][\"classes\"][i], prob_str)\n    return to_print, predictions, raw_predictions\n\ndef sequence_predict_single_image_from_url(url):\n    image = imutils.url_to_image(url)\n    imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n    image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n    to_print, predictions, raw_predictions = sequence_predict_raw(np.array([image_resized]))\n    return to_print, secure_user_view(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA), raw_predictions)\n\ndef sequence_predict_single_image_from_path(path, break_line=True):\n    image = cv2.imread(path)\n    imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n    image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n    to_print, predictions, raw_predictions = sequence_predict_raw(np.array([image_resized]))\n    return to_print, secure_user_view(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA), raw_predictions)\n\ndef sequence_predict_single_raw_image(image, break_line=True):\n    to_print, predictions, raw_predictions = sequence_predict_raw(image)\n    return to_print, secure_user_view(image, raw_predictions)\n\ndef sequence_predict_from_path(path=data_dir, group=True):\n    data_dir = path\n    clean_up_data_dir()\n    images_path = []\n    \n    if(group):\n        data_sub_directories = os.listdir(data_dir)\n        for data_sub_directory in data_sub_directories:\n            # images_path+=os.listdir(os.path.join(data_dir, data_sub_directory))\n            print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))\n            for current_dir in os.listdir(os.path.join(data_dir, data_sub_directory)):\n                images_path.append(os.path.join(data_sub_directory, current_dir))\n    else:\n        try:\n            for current_dir in os.listdir(data_dir):\n                images_path.append(os.path.join(data_dir, current_dir))\n        except Exception as wrong:\n            print(wrong)\n            pass\n\n    if not group:\n        data_dir = \".\"\n    \n    sequence_bulk_prediction(data_dir, images_path)\n    \n\ndef sequence_bulk_prediction(data_dir=\"\", images_path=[], images=[]):\n    current = 0\n    output = widgets.Output()\n    next_button = widgets.Button(description='Next')\n    prev_button = widgets.Button(description='Prev')\n    display_current_button = widgets.Button(description='Current')\n    current_index_text = widgets.Textarea(\n        value=str(current),\n        placeholder='current index goes here',\n        description='index',\n        disabled=False\n    )\n    \n    display(current_index_text, display_current_button, prev_button, next_button, output)\n    \n    def default_action():\n        global current\n        with output:\n            clear_output()\n            images_store = images_path if len(images_path) > 0 else images\n            \n            print(\"{0}/{1}\".format(current+1, len(images_store)))\n            if len(images_path) > 0:\n                to_print, image = sequence_predict_single_image_from_path(os.path.join(data_dir, images_path[current]))\n            else:\n                to_print, image = sequence_predict_single_raw_image(images[current])\n            print(to_print)\n            display(image)\n            \n    def on_next_button_clicked(_):\n        global current\n        if current+2 > len(images_path):\n            return None\n        current+=1\n        default_action()\n\n\n    def on_prev_button_clicked(_):\n        global current\n        if current-1 < 0:\n            return None\n        current-=1\n        default_action()\n        \n        \n    def on_current_index_change(_):\n        update_index_change(current_index_text.value)\n\n    def update_index_change(indexString):\n        global current\n        try:\n            current = int(indexString)\n            default_action()\n        except Exception as wrong:\n            print(wrong)\n            pass\n\n    next_button.on_click(on_next_button_clicked)\n    prev_button.on_click(on_prev_button_clicked)\n    display_current_button.on_click(on_current_index_change)\n    current_index_text.on_displayed(update_index_change(str(current)))\n    \ndef sequence_predict_at_random(base_url=\"https://picsum.photos/{0}/{0}\".format(IMAGE_RES)):\n    again_button = widgets.Button(description='Again')\n    output = widgets.Output()\n    display(again_button, output)\n\n    def on_again_button_clicked(_):\n        with output:\n            clear_output()\n            to_print, image = sequence_predict_single_image_from_url(base_url)\n            print(to_print)\n            display(image)\n    \n    with output:\n        clear_output()\n        to_print, image = sequence_predict_single_image_from_url(base_url)\n        print(to_print)\n        display(image)\n    \n    again_button.on_click(on_again_button_clicked)\n    \n    \ndef sequence_predict_url_batch(urls, figsize=(30, 30), verbose=False, break_line=True):\n    predictions_output = []    \n    images=[]\n    for url in urls:\n        try:\n            image = imutils.url_to_image(url)\n            # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n            imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n            image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n            images.append(np.array([image_resized]))\n        except Exception as wrong:\n            pass\n    sequence_bulk_prediction(images=images)\n    \n    \n    \ndef plot_probabilistic_training_history():\n    for model_config in models_config:\n        try:\n            model_data = MODELS[model_config[\"name\"]]\n            print(\"history for => \" , model_config[\"name\"])\n            history = model_data[\"history\"]\n            acc = history.history['accuracy']\n            val_acc = history.history['accuracy']\n            # acc = history.history['accuracy']\n            # val_acc = history.history['accuracy']\n\n            loss = history.history['loss']\n            val_loss = history.history['val_loss']\n\n            plt.figure(figsize=(8, 8))\n            plt.subplot(1, 2, 1)\n            plt.plot(history.epoch, acc, label='Training Accuracy')\n            plt.plot(history.epoch, val_acc, label='Validation Accuracy')\n            plt.legend(loc='lower right')\n            plt.title('Training and Validation Accuracy')\n\n            plt.subplot(1, 2, 2)\n            plt.plot(history.epoch, loss, label='Training Loss')\n            plt.plot(history.epoch, val_loss, label='Validation Loss')\n            plt.legend(loc='upper right')\n            plt.title('Training and Validation Loss')\n            plt.show()\n        except Exception as e:\n            pass\n        \n\ndef build_probabilistic_model_sequence(model_config, cleanup=True, model=None):\n#     build_probabilistic_model_sequence(model_config, False)\n    print(\"working on => \", model_config[\"name\"])\n    ### LOAD TRAINING DATASET\n    print(\"LOADING TRAINING DATASET FOR \", model_config[\"name\"])\n    if cleanup:\n        clean_up_data_dir()\n        \n    df=pd.read_csv(csv_dataset)\n    if model_config[\"max_samples\"] != 0:\n        base_class_df = df[df[model_config[\"classes\"][0]] == 1]\n        for i in range(1, len(model_config[\"classes\"])):\n            general_class_df = df[df[model_config[\"classes\"][i]] == 1]\n            if(len(general_class_df) > model_config[\"max_samples\"]):\n                general_class_df = general_class_df[:model_config[\"max_samples\"]]\n            base_class_df = base_class_df.append(general_class_df)\n        df = base_class_df\n#         df = df[:model_config[\"max_samples\"]]\n#     else:\n#         base_class_df = df[df[model_config[\"base_class\"]] == 1]\n#         base_class_max_sample = model_config[\"base_class_max_sample\"] if model_config[\"base_class_max_sample\"] != -1 else base_class_df.count[\"filenames\"]\n#         base_class_df = base_class_df[:base_class_max_sample]\n\n\n#         general_class_df = df[df[model_config[\"base_class\"]] != 1]\n#         general_class_max_sample = model_config[\"general_class_max_sample\"] if model_config[\"general_class_max_sample\"] != -1 else general_class_df.count[\"filenames\"]\n#         general_class_df = general_class_df[:general_class_max_sample]\n\n#         df = base_class_df.append(general_class_df)\n    \n\n    display(df.describe())\n    \n    columns = []\n    for column in data_sub_directories:\n        if column in model_config[\"classes\"]:\n            columns.append(column)\n            \n    train_datagen = ImageDataGenerator(\n        featurewise_center=model_config[\"featurewise_center\"],\n        samplewise_center=model_config[\"samplewise_center\"],\n        featurewise_std_normalization=model_config[\"featurewise_std_normalization\"],\n        samplewise_std_normalization=model_config[\"samplewise_std_normalization\"],\n        zca_whitening=model_config[\"zca_whitening\"],\n        zca_epsilon=model_config[\"zca_epsilon\"],\n        rotation_range=model_config[\"rotation_range\"],\n        width_shift_range=model_config[\"width_shift_range\"],\n        height_shift_range=model_config[\"height_shift_range\"],\n        brightness_range=model_config[\"brightness_range\"],\n        shear_range=model_config[\"shear_range\"],\n        zoom_range=model_config[\"zoom_range\"],\n        channel_shift_range=model_config[\"channel_shift_range\"],\n        fill_mode=model_config[\"fill_mode\"],\n        cval=model_config[\"cval\"],\n        horizontal_flip=model_config[\"horizontal_flip\"],\n        vertical_flip=model_config[\"vertical_flip\"],\n        rescale=model_config[\"rescale\"],\n        preprocessing_function=model_config[\"preprocessing_function\"],\n        data_format=model_config[\"data_format\"],\n        validation_split=model_config[\"validation_split\"]\n      )\n\n    training_set=train_datagen.flow_from_dataframe(\n        dataframe=df,\n        directory=data_dir,\n        x_col=\"filenames\",\n        y_col=model_config[\"classes\"],\n        target_size=dimensions,\n        batch_size=batch_size,\n        seed=42,\n        class_mode=\"raw\",\n        subset=\"training\"\n    )\n\n    validation_set=train_datagen.flow_from_dataframe(\n        dataframe=df,\n        directory=data_dir,\n        x_col=\"filenames\",\n        y_col=model_config[\"classes\"],\n        target_size=dimensions,\n        batch_size=batch_size,\n        seed=42,\n        class_mode=\"raw\",\n        subset=\"validation\"\n    )\n    \n    class_names = columns\n    num_classes = len(class_names)\n    num_samples = training_set.samples + validation_set.samples\n    files_per_class = []\n    for folder in os.listdir(data_dir):\n        if not os.path.isfile(folder):\n                files_per_class.append(len(os.listdir(data_dir + '/' + folder)))\n    total_files = sum(files_per_class)\n    class_weights = {}\n    for i in range(len(files_per_class)):\n        class_weights[i] = 1 - (float(files_per_class[i]) / total_files)\n    print (\"class_weights => \", class_weights)\n    if model is None:\n        URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n        # URL = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n        try:\n            MODEL_BASE_NAME = model_config[\"name\"]\n        except Exception as e:\n            MODEL_BASE_NAME=\"model_\"\n        feature_extractor = hub.KerasLayer(URL,\n                                       input_shape=(IMAGE_RES, IMAGE_RES, 3))\n\n        last_layer = layers.Dense(len(columns), activation='sigmoid') if model_config[\"multi_label\"] else layers.Dense(len(columns), activation='softmax')\n\n        feature_extractor.trainable = False\n        model = tf.keras.Sequential([\n            feature_extractor,\n            tf.keras.layers.Flatten(),\n            last_layer\n        ])\n\n        model.summary()\n\n\n\n        loss = \"binary_crossentropy\" if model_config[\"multi_label\"] else \"categorical_crossentropy\"\n        print(\"COMPILING MODEL: \", model_config[\"name\"])\n        model.compile(\n          optimizer=tf.keras.optimizers.RMSprop(learning_rate=model_config[\"lr\"]),\n          loss=loss,\n          metrics=[\"accuracy\"]\n        )\n    \n    print(\"TRAINING MODEL: \", model_config[\"name\"])\n    steps_per_epoch = num_samples//model_config[\"batch_size\"]\n    checkpoint_filepath = 'models/epoch/chk.h5'\n\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_filepath,\n        save_weights_only=True,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True)\n\n    stop_training_callback = tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\",\n\n        #min_delta=0,\n        patience=model_config[\"overfitting_patience\"],\n        #verbose=0,\n        #mode=\"auto\",\n        #baseline=None,\n        restore_best_weights=model_config[\"restore_best_weights\"],\n    )\n\n    history = model.fit(training_set,\n                        epochs=model_config[\"epochs\"],\n#                         steps_per_epoch=model_config[\"steps_per_epoch\"],\n                        validation_data=validation_set,\n                        callbacks=[model_checkpoint_callback, stop_training_callback],\n                        # callbacks=[model_checkpoint_callback],\n#                         class_weight=class_weights\n                        )\n    MODELS[model_config[\"name\"]] = {\n        \"history\": history,\n        \"configs\": model_config,\n        \"df\": df,\n        \"model\": model,\n        \"class_names\": columns,\n        \"session_id\": SESSION_ID\n    }\n    \n    \ndef sequence_bulk_prediction_from_url(urls=\"\"):\n    current = 0\n    output = widgets.Output()\n    next_button = widgets.Button(description='Next')\n    prev_button = widgets.Button(description='Prev')\n    display_current_button = widgets.Button(description='Current')\n    current_index_text = widgets.Textarea(\n        value=str(current),\n        placeholder='current index goes here',\n        description='index',\n        disabled=False\n    )\n    \n    display(current_index_text, display_current_button, prev_button, next_button, output)\n    \n    def default_action():\n        global current\n        with output:\n            clear_output()\n            try:\n                print(\"{0}/{1}\".format(current+1, len(urls)))\n                to_print, image = sequence_predict_single_image_from_url(urls[current])\n                print(to_print)\n                display(image)\n            except Exception as wrong: \n                print(wrong)\n                pass\n                    \n    def on_next_button_clicked(_):\n        global current\n        if current+2 > len(urls):\n            return None\n        current+=1\n        default_action()\n\n\n    def on_prev_button_clicked(_):\n        global current\n        if current-1 < 0:\n            return None\n        current-=1\n        default_action()\n        \n        \n    def on_current_index_change(_):\n        update_index_change(current_index_text.value)\n\n    def update_index_change(indexString):\n        global current\n        try:\n            current = int(indexString)\n            default_action()\n        except Exception as wrong:\n            print(wrong)\n            pass\n\n    next_button.on_click(on_next_button_clicked)\n    prev_button.on_click(on_prev_button_clicked)\n    display_current_button.on_click(on_current_index_change)\n    current_index_text.on_displayed(update_index_change(str(current)))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-10-04T14:33:34.812198Z","iopub.execute_input":"2022-10-04T14:33:34.812575Z","iopub.status.idle":"2022-10-04T14:33:36.295570Z","shell.execute_reply.started":"2022-10-04T14:33:34.812529Z","shell.execute_reply":"2022-10-04T14:33:36.294371Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Dataset Summary","metadata":{}},{"cell_type":"code","source":"clean_up_data_dir()\ndata_sub_directories = os.listdir(data_dir)\nfor data_sub_directory in data_sub_directories:\n    print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))","metadata":{"tags":[],"scrolled":true,"execution":{"iopub.status.busy":"2022-10-04T14:33:36.297640Z","iopub.execute_input":"2022-10-04T14:33:36.297977Z","iopub.status.idle":"2022-10-04T14:33:42.890432Z","shell.execute_reply.started":"2022-10-04T14:33:36.297934Z","shell.execute_reply":"2022-10-04T14:33:42.889534Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"rm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/neutral/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/neutral/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/porn/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/porn/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/hentai/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/hentai/..'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/sexy/.'\nrm: refusing to remove '.' or '..' directory: skipping '/kaggle/input/nsfw-content-moderation/images/sexy/..'\nrm: cannot remove '/kaggle/input/nsfw-content-moderation/images/.ipynb_checkpoints': No such file or directory\nrm: cannot remove '/kaggle/input/nsfw-content-moderation/images/.DS_Store': No such file or directory\nfound 1949 for class neutral\nfound 1947 for class porn\nfound 1273 for class hentai\nfound 1529 for class sexy\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Creating model sequence config","metadata":{}},{"cell_type":"code","source":"# SESSION_ID = str(time.time()).replace(\".\", \"_\")\n# MODELS = {\n    \n# }\n\n# os.system(\"mkdir {0}/{1}\".format(MODEL_PATH, SESSION_ID))\n# general_class = \"general_not_nsfw_not_suggestive\"\n# models_config = [\n#     {\n#         \"name\": \"nsfw_detector\",\n#         \"base_class\": \"general_nsfw\",\n#         \"batch_size\": 32,\n#         \"overfitting_patience\": 1,\n#         \"epochs\": 30,\n#         \"lr\": 0.0001,\n#         \"base_class_max_sample\": 2000,\n#         \"general_class_max_sample\": 2000,\n#         \"featurewise_center\": False,\n#         \"samplewise_center\": False,\n#         \"featurewise_std_normalization\": False,\n#         \"samplewise_std_normalization\": False,\n#         \"zca_whitening\": False,\n#         \"zca_epsilon\": 1e-06,\n#         \"rotation_range\": 0,\n#         \"width_shift_range\": 0.0,\n#         \"height_shift_range\": 0.0,\n#         \"brightness_range\": None,\n#         \"shear_range\": 0.0,\n#         \"zoom_range\": 0.0,\n#         \"channel_shift_range\": 0.0,\n#         \"fill_mode\": 'nearest',\n#         \"cval\": 0.0,\n#         \"horizontal_flip\": False,\n#         \"vertical_flip\": False,\n#         \"rescale\": 1./255,\n#         \"preprocessing_function\": None,\n#         \"data_format\": None,\n#         \"validation_split\": 0.2,\n#         \"restore_best_weights\": False\n#     },\n#     {\n#         \"name\": \"female_swimwear_detector\",\n#         \"base_class\": \"female_swimwear\",\n#         \"batch_size\": 32,\n#         \"overfitting_patience\": 1,\n#         \"epochs\": 30,\n#         \"lr\": 0.0001,\n#         \"base_class_max_sample\": 747,\n#         \"general_class_max_sample\": 747,\n#         \"featurewise_center\": False,\n#         \"samplewise_center\": False,\n#         \"featurewise_std_normalization\": False,\n#         \"samplewise_std_normalization\": False,\n#         \"zca_whitening\": False,\n#         \"zca_epsilon\": 1e-06,\n#         \"rotation_range\": 0,\n#         \"width_shift_range\": 0.0,\n#         \"height_shift_range\": 0.0,\n#         \"brightness_range\": None,\n#         \"shear_range\": 0.0,\n#         \"zoom_range\": 0.0,\n#         \"channel_shift_range\": 0.0,\n#         \"fill_mode\": 'nearest',\n#         \"cval\": 0.0,\n#         \"horizontal_flip\": False,\n#         \"vertical_flip\": False,\n#         \"rescale\": 1./255,\n#         \"preprocessing_function\": None,\n#         \"data_format\": None,\n#         \"validation_split\": 0.2,\n#         \"restore_best_weights\": False\n#     },\n#     {\n#         \"name\": \"female_nudity_detector\",\n#         \"base_class\": \"female_nudity\",\n#         \"batch_size\": 32,\n#         \"overfitting_patience\": 1,\n#         \"epochs\": 30,\n#         \"lr\": 0.0001,\n#         \"base_class_max_sample\": 2000,\n#         \"general_class_max_sample\": 2000,\n#         \"featurewise_center\": False,\n#         \"samplewise_center\": False,\n#         \"featurewise_std_normalization\": False,\n#         \"samplewise_std_normalization\": False,\n#         \"zca_whitening\": False,\n#         \"zca_epsilon\": 1e-06,\n#         \"rotation_range\": 0,\n#         \"width_shift_range\": 0.0,\n#         \"height_shift_range\": 0.0,\n#         \"brightness_range\": None,\n#         \"shear_range\": 0.0,\n#         \"zoom_range\": 0.0,\n#         \"channel_shift_range\": 0.0,\n#         \"fill_mode\": 'nearest',\n#         \"cval\": 0.0,\n#         \"horizontal_flip\": False,\n#         \"vertical_flip\": False,\n#         \"rescale\": 1./255,\n#         \"preprocessing_function\": None,\n#         \"data_format\": None,\n#         \"validation_split\": 0.2,\n#         \"restore_best_weights\": False\n#     },\n#     {\n#         \"name\": \"female_underwear_detector\",\n#         \"base_class\": \"female_underwear\",\n#         \"batch_size\": 32,\n#         \"overfitting_patience\": 1,\n#         \"epochs\": 30,\n#         \"lr\": 0.0001,\n#         \"base_class_max_sample\": 2000,\n#         \"general_class_max_sample\": 2000,\n#         \"featurewise_center\": False,\n#         \"samplewise_center\": False,\n#         \"featurewise_std_normalization\": False,\n#         \"samplewise_std_normalization\": False,\n#         \"zca_whitening\": False,\n#         \"zca_epsilon\": 1e-06,\n#         \"rotation_range\": 0,\n#         \"width_shift_range\": 0.0,\n#         \"height_shift_range\": 0.0,\n#         \"brightness_range\": None,\n#         \"shear_range\": 0.0,\n#         \"zoom_range\": 0.0,\n#         \"channel_shift_range\": 0.0,\n#         \"fill_mode\": 'nearest',\n#         \"cval\": 0.0,\n#         \"horizontal_flip\": False,\n#         \"vertical_flip\": False,\n#         \"rescale\": 1./255,\n#         \"preprocessing_function\": None,\n#         \"data_format\": None,\n#         \"validation_split\": 0.2,\n#         \"restore_best_weights\": False\n#     },\n# ]","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:33:42.892426Z","iopub.execute_input":"2022-10-04T14:33:42.892950Z","iopub.status.idle":"2022-10-04T14:33:42.901762Z","shell.execute_reply.started":"2022-10-04T14:33:42.892915Z","shell.execute_reply":"2022-10-04T14:33:42.900549Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Build model sequence","metadata":{}},{"cell_type":"code","source":"# for model_config in models_config:\n#     build_model_sequence(model_config, False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-04T14:33:42.904257Z","iopub.execute_input":"2022-10-04T14:33:42.904575Z","iopub.status.idle":"2022-10-04T14:33:42.919760Z","shell.execute_reply.started":"2022-10-04T14:33:42.904540Z","shell.execute_reply":"2022-10-04T14:33:42.918541Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### display training history","metadata":{}},{"cell_type":"code","source":"# plot_training_history()","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:33:42.921186Z","iopub.execute_input":"2022-10-04T14:33:42.921951Z","iopub.status.idle":"2022-10-04T14:33:42.930643Z","shell.execute_reply.started":"2022-10-04T14:33:42.921907Z","shell.execute_reply":"2022-10-04T14:33:42.929658Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Build single model sequence","metadata":{}},{"cell_type":"code","source":"# print(MODELS[\"nsfw_content_moderator\"][\"configs\"])\n# MODELS[\"nsfw_content_moderator\"][\"configs\"] = models_config[0]","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:33:42.932187Z","iopub.execute_input":"2022-10-04T14:33:42.932556Z","iopub.status.idle":"2022-10-04T14:33:42.944599Z","shell.execute_reply.started":"2022-10-04T14:33:42.932503Z","shell.execute_reply":"2022-10-04T14:33:42.943302Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"SESSION_ID = str(time.time()).replace(\".\", \"_\")\nMODELS = {\n    \n}\n\nos.system(\"mkdir {0}/{1}\".format(MODEL_PATH, SESSION_ID))\nmodels_config = [\n        {\n            \"name\": \"nsfw_content_moderator\",\n            \"multi_label\": False,\n            \"base_class\": \"neutral\",\n            \"classes\": [\"neutral\", \"sexy\", \"porn\", \"hentai\"],\n            \"sensitive_classe_indexes\": [0, 1],\n            \"prediction_threshold\": 0.5,\n            \"blur_sensitive_class\": True,\n            \"blur_ksize\": (10, 10),\n            \"batch_size\": 32,\n            \"overfitting_patience\": 5,\n            \"epochs\": 30,\n            \"lr\": 0.0001,\n            \"base_class_max_sample\": 1400,\n            \"general_class_max_sample\": 1400,\n            \"max_samples\": 1400,\n            \"featurewise_center\": False,\n            \"samplewise_center\": False,\n            \"featurewise_std_normalization\": False,\n            \"samplewise_std_normalization\": False,\n            \"zca_whitening\": False,\n            \"zca_epsilon\": 1e-06,\n            \"rotation_range\": 20,\n            \"width_shift_range\": 0.0,\n            \"height_shift_range\": 0.0,\n            \"brightness_range\": None,\n            \"shear_range\": 0.1,\n            \"zoom_range\": 0.2,\n            \"channel_shift_range\": 0.0,\n            \"fill_mode\": 'nearest',\n            \"cval\": 0.0,\n            \"horizontal_flip\": True,\n            \"vertical_flip\": True,\n            \"rescale\": 1./255,\n            \"preprocessing_function\": None,\n            \"data_format\": None,\n            \"validation_split\": 0.2,\n            \"restore_best_weights\": True\n        }\n    \n]","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:34:44.467735Z","iopub.execute_input":"2022-10-04T14:34:44.468064Z","iopub.status.idle":"2022-10-04T14:34:44.483396Z","shell.execute_reply.started":"2022-10-04T14:34:44.468025Z","shell.execute_reply":"2022-10-04T14:34:44.481842Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"cleanup=False\nfor model_config in models_config:\n    build_probabilistic_model_sequence(model_config, False)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T14:34:46.823446Z","iopub.execute_input":"2022-10-04T14:34:46.823771Z","iopub.status.idle":"2022-10-04T16:45:15.418096Z","shell.execute_reply.started":"2022-10-04T14:34:46.823731Z","shell.execute_reply":"2022-10-04T16:45:15.416682Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"working on =>  nsfw_content_moderator\nLOADING TRAINING DATASET FOR  nsfw_content_moderator\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"           neutral         porn       hentai         sexy\ncount  6022.000000  6022.000000  6022.000000  6022.000000\nmean      0.323647     0.232481     0.211392     0.232481\nstd       0.467906     0.422449     0.408329     0.422449\nmin       0.000000     0.000000     0.000000     0.000000\n25%       0.000000     0.000000     0.000000     0.000000\n50%       0.000000     0.000000     0.000000     0.000000\n75%       1.000000     0.000000     0.000000     0.000000\nmax       1.000000     1.000000     1.000000     1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>neutral</th>\n      <th>porn</th>\n      <th>hentai</th>\n      <th>sexy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6022.000000</td>\n      <td>6022.000000</td>\n      <td>6022.000000</td>\n      <td>6022.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.323647</td>\n      <td>0.232481</td>\n      <td>0.211392</td>\n      <td>0.232481</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.467906</td>\n      <td>0.422449</td>\n      <td>0.408329</td>\n      <td>0.422449</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Found 4818 validated image filenames.\nFound 1204 validated image filenames.\nclass_weights =>  {0: 0.709017617199164, 1: 0.7093162137951627, 2: 0.8099432666467602, 3: 0.7717229023589132}\n","output_type":"stream"},{"name":"stderr","text":"2022-10-04 14:34:52.500914: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nkeras_layer (KerasLayer)     (None, 1280)              2257984   \n_________________________________________________________________\nflatten (Flatten)            (None, 1280)              0         \n_________________________________________________________________\ndense (Dense)                (None, 4)                 5124      \n=================================================================\nTotal params: 2,263,108\nTrainable params: 5,124\nNon-trainable params: 2,257,984\n_________________________________________________________________\nCOMPILING MODEL:  nsfw_content_moderator\nTRAINING MODEL:  nsfw_content_moderator\n","output_type":"stream"},{"name":"stderr","text":"2022-10-04 14:34:55.896452: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n151/151 [==============================] - 322s 2s/step - loss: 1.0627 - accuracy: 0.5511 - val_loss: 1.1659 - val_accuracy: 0.4568\nEpoch 2/30\n151/151 [==============================] - 310s 2s/step - loss: 0.6680 - accuracy: 0.7576 - val_loss: 0.8756 - val_accuracy: 0.6586\nEpoch 3/30\n151/151 [==============================] - 309s 2s/step - loss: 0.5184 - accuracy: 0.8149 - val_loss: 0.7887 - val_accuracy: 0.7151\nEpoch 4/30\n151/151 [==============================] - 310s 2s/step - loss: 0.4536 - accuracy: 0.8391 - val_loss: 0.6975 - val_accuracy: 0.7666\nEpoch 5/30\n151/151 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.8543Epoch 6/30\n151/151 [==============================] - 319s 2s/step - loss: 0.3782 - accuracy: 0.8661 - val_loss: 0.6449 - val_accuracy: 0.7757\nEpoch 7/30\n151/151 [==============================] - 342s 2s/step - loss: 0.3605 - accuracy: 0.8755 - val_loss: 0.5855 - val_accuracy: 0.7915\nEpoch 8/30\n151/151 [==============================] - 323s 2s/step - loss: 0.3280 - accuracy: 0.8856 - val_loss: 0.6014 - val_accuracy: 0.8032\nEpoch 10/30\n151/151 [==============================] - 313s 2s/step - loss: 0.3235 - accuracy: 0.8850 - val_loss: 0.6133 - val_accuracy: 0.7865\nEpoch 11/30\n151/151 [==============================] - 335s 2s/step - loss: 0.3154 - accuracy: 0.8892 - val_loss: 0.5574 - val_accuracy: 0.8131\nEpoch 12/30\n151/151 [==============================] - 309s 2s/step - loss: 0.3061 - accuracy: 0.8931 - val_loss: 0.5759 - val_accuracy: 0.8015\nEpoch 13/30\n151/151 [==============================] - 305s 2s/step - loss: 0.3088 - accuracy: 0.8852 - val_loss: 0.6567 - val_accuracy: 0.7633\nEpoch 14/30\n151/151 [==============================] - 303s 2s/step - loss: 0.2979 - accuracy: 0.8948 - val_loss: 0.5224 - val_accuracy: 0.8214\nEpoch 15/30\n151/151 [==============================] - 303s 2s/step - loss: 0.3012 - accuracy: 0.8968 - val_loss: 0.5704 - val_accuracy: 0.8131\nEpoch 16/30\n151/151 [==============================] - 305s 2s/step - loss: 0.2919 - accuracy: 0.8966 - val_loss: 0.5722 - val_accuracy: 0.7973\nEpoch 17/30\n151/151 [==============================] - 307s 2s/step - loss: 0.2817 - accuracy: 0.8981 - val_loss: 0.5120 - val_accuracy: 0.8314\nEpoch 18/30\n151/151 [==============================] - 302s 2s/step - loss: 0.2802 - accuracy: 0.9006 - val_loss: 0.5104 - val_accuracy: 0.8256\nEpoch 19/30\n151/151 [==============================] - 302s 2s/step - loss: 0.2772 - accuracy: 0.9024 - val_loss: 0.4404 - val_accuracy: 0.8447\nEpoch 20/30\n151/151 [==============================] - 304s 2s/step - loss: 0.2751 - accuracy: 0.9014 - val_loss: 0.5064 - val_accuracy: 0.8331\nEpoch 21/30\n151/151 [==============================] - 306s 2s/step - loss: 0.2652 - accuracy: 0.9062 - val_loss: 0.5592 - val_accuracy: 0.8090\nEpoch 22/30\n151/151 [==============================] - 302s 2s/step - loss: 0.2753 - accuracy: 0.9031 - val_loss: 0.4764 - val_accuracy: 0.8530\nEpoch 23/30\n151/151 [==============================] - 300s 2s/step - loss: 0.2708 - accuracy: 0.9072 - val_loss: 0.5206 - val_accuracy: 0.8314\nEpoch 24/30\n151/151 [==============================] - 301s 2s/step - loss: 0.2689 - accuracy: 0.9043 - val_loss: 0.5108 - val_accuracy: 0.8281\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_probabilistic_training_history()","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:29:37.567843Z","iopub.execute_input":"2022-10-04T17:29:37.568214Z","iopub.status.idle":"2022-10-04T17:29:37.926115Z","shell.execute_reply.started":"2022-10-04T17:29:37.568177Z","shell.execute_reply":"2022-10-04T17:29:37.924977Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"history for =>  nsfw_content_moderator\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 576x576 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"MODELS[\"nsfw_content_moderator\"][\"model\"]","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:30:45.187409Z","iopub.execute_input":"2022-10-04T17:30:45.188248Z","iopub.status.idle":"2022-10-04T17:30:45.194690Z","shell.execute_reply.started":"2022-10-04T17:30:45.188201Z","shell.execute_reply":"2022-10-04T17:30:45.193784Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<keras.engine.sequential.Sequential at 0x7fcfc7cb3a50>"},"metadata":{}}]},{"cell_type":"code","source":"# build_probabilistic_model_sequence(model_config, False, MODELS[\"nsfw_content_moderator\"][\"model\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:30:45.510941Z","iopub.execute_input":"2022-10-04T17:30:45.511252Z","iopub.status.idle":"2022-10-04T17:30:45.516077Z","shell.execute_reply.started":"2022-10-04T17:30:45.511219Z","shell.execute_reply":"2022-10-04T17:30:45.514970Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## setup server settings","metadata":{}},{"cell_type":"code","source":"data_dir = DATASET_PATH\n# clean_up_data_dir(data_dir)        \nmgx_api_access_token = \"T3SHaywV1HOOhYg1GkPbVDy2dX1oqn6_\"\nmgx_api_url = \"https://mgx-api.karamokoisrael.tech\"\nmgx_models_folder_id = \"c2eef2be-c7fa-47b3-95a1-f40f1cc513d3\"\nheaders = {\"Authorization\": 'Bearer '+mgx_api_access_token}","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:53:56.343254Z","iopub.execute_input":"2022-10-04T17:53:56.343602Z","iopub.status.idle":"2022-10-04T17:53:56.348992Z","shell.execute_reply.started":"2022-10-04T17:53:56.343564Z","shell.execute_reply":"2022-10-04T17:53:56.347843Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## Backup project","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef decode_img_bytes(img):\n    img = tf.strings.regex_replace(img, \"\\+\", \"-\")\n    img = tf.strings.regex_replace(img, \"\\/\", \"_\")\n    image = tf.image.decode_jpeg(tf.io.decode_base64(img), channels=3)\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32) # 0-1\n    image = tf.image.resize(images=image, size=dimensions)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:40:27.674963Z","iopub.execute_input":"2022-10-04T17:40:27.675940Z","iopub.status.idle":"2022-10-04T17:40:27.687774Z","shell.execute_reply.started":"2022-10-04T17:40:27.675891Z","shell.execute_reply":"2022-10-04T17:40:27.686844Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import base64\n\nclass ExportModel(tf.keras.Model):\n    def __init__(self, model, img_classes):\n        super().__init__(self)       \n        self.model = model\n        self.img_classes = img_classes\n\n    @tf.function(input_signature=[\n        tf.TensorSpec(shape=(None,), dtype=tf.string, name=\"base64\")\n    ])\n    \n    def serving_fn(self, base64):\n        #a = np.array([x.lower() if isinstance(x, str) else x for x in arr])\n        base64_image = tf.map_fn(lambda x: decode_img_bytes(x), base64, fn_output_signature=tf.float32)\n        scores = self.model.call(base64_image)                \n        labels = tf.constant([self.img_classes]) \n        return {\n            'scores': scores,\n            'classes': tf.repeat(labels, repeats=tf.shape(scores)[0], axis=0, name=None)\n        }\n\n    def save(self, export_path):\n        sigs = {\n            'serving_default' : self.serving_fn\n        }\n        \n        \n        #tf.keras.backend.set_learning_phase(0) # inference only\n        tf.saved_model.save(self, export_path, signatures=sigs)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:40:28.066762Z","iopub.execute_input":"2022-10-04T17:40:28.067376Z","iopub.status.idle":"2022-10-04T17:40:28.080063Z","shell.execute_reply.started":"2022-10-04T17:40:28.067336Z","shell.execute_reply":"2022-10-04T17:40:28.078918Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"for model_name in [*MODELS]:\n    model_data = MODELS[model_name]\n    try:\n        file_path = \"{0}/{1}/{2}.h5\".format(MODEL_PATH, SESSION_ID, model_name)\n        print(\"backup => \", model_name)\n        model_data[\"model\"].save(file_path)\n        sm = ExportModel(model_data[\"model\"], model_data[\"configs\"][\"classes\"])\n        sm.save(file_path.replace(\".h5\", \"\"))\n        serving_file_path = file_path.replace(\".h5\", \"\")+\".zip\"\n        shutil.make_archive(file_path.replace(\".h5\", \"\"), 'zip', file_path.replace(\".h5\", \"\"))\n        \n        payload = {'title': model_name+\"_\"+SESSION_ID, \"folder\": mgx_models_folder_id}\n        file=serving_file_path\n        files = {'file': (os.path.basename(file), open(file, 'rb'), 'application/octet-stream')}\n        r = requests.post(mgx_api_url+\"/files\", files=files, data=payload, headers=headers)\n        \n        file=file_path\n        files = {'file': (os.path.basename(file), open(file, 'rb'), 'application/octet-stream')}\n        r = requests.post(mgx_api_url+\"/files\", files=files, data=payload, headers=headers)\n        \n        local_file = FileLink(serving_file_path, result_html_prefix=\"Click here to download model({0}/{1}) \".format(SESSION_ID, model_name))\n        display(local_file)\n        local_file = FileLink(file_path, result_html_prefix=\"Click here to download model({0}/{1}) \".format(SESSION_ID, model_name))\n        display(local_file)\n    except Exception as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:58:18.591159Z","iopub.execute_input":"2022-10-04T17:58:18.591964Z","iopub.status.idle":"2022-10-04T17:58:32.508696Z","shell.execute_reply.started":"2022-10-04T17:58:18.591916Z","shell.execute_reply":"2022-10-04T17:58:32.507499Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"backup =>  nsfw_content_moderator\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/models/1664894084_4746711/nsfw_content_moderator.zip","text/html":"Click here to download model(1664894084_4746711/nsfw_content_moderator) <a href='models/1664894084_4746711/nsfw_content_moderator.zip' target='_blank'>models/1664894084_4746711/nsfw_content_moderator.zip</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/models/1664894084_4746711/nsfw_content_moderator.h5","text/html":"Click here to download model(1664894084_4746711/nsfw_content_moderator) <a href='models/1664894084_4746711/nsfw_content_moderator.h5' target='_blank'>models/1664894084_4746711/nsfw_content_moderator.h5</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"!ls models","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:41:55.064364Z","iopub.execute_input":"2022-10-04T17:41:55.064738Z","iopub.status.idle":"2022-10-04T17:41:56.314926Z","shell.execute_reply.started":"2022-10-04T17:41:55.064701Z","shell.execute_reply":"2022-10-04T17:41:56.313725Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"1664894022_9556859  1664894084_4746711\tepoch\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm -r models/*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Restore project","metadata":{}},{"cell_type":"code","source":"MODEL_PATH = \"models\"\nsession_id = \"1664541550_729922\"\n!mkdir $MODEL_PATH/$session_id\n\n# !rm -r $MODEL_PATH/$session_id/*\n!\nfor model_config in models_config:\n    try:\n        model_path = \"{0}/{1}/{2}.h5\".format(MODEL_PATH, session_id, model_config[\"name\"])\n        open(model_path, 'wb').write(r.content)\n        model = tf.keras.models.load_model(\n              model_path, \n#               custom_objects={'KerasLayer': hub.KerasLayer} \n        )\n      \n        MODELS[model_config[\"name\"]] = {\n            \"configs\": model_config,\n            \"model\": model,\n            \"session_id\": session_id\n        }\n    except Exception as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T15:41:01.640338Z","iopub.execute_input":"2022-09-30T15:41:01.640737Z","iopub.status.idle":"2022-09-30T15:41:03.811559Z","shell.execute_reply.started":"2022-09-30T15:41:01.640691Z","shell.execute_reply":"2022-09-30T15:41:03.810420Z"},"trusted":true},"execution_count":155,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘models/1664541550_729922’: File exists\nSavedModel file does not exist at: models/1664541550_729922/nsfw_content_moderator.h5/{saved_model.pbtxt|saved_model.pb}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### image prediction on model sequence","metadata":{}},{"cell_type":"code","source":"def sequence_predict_raw(image_array):\n    predictions = {}\n    raw_predictions = []\n    to_print = \"\"\n    for model_name in MODELS.keys():\n        model_data = MODELS[model_name]\n        model = model_data[\"model\"]\n        prediction = model.predict(image_array)\n        raw_predictions.append({\n            \"prediction\": prediction,\n            \"model_config\": model_data[\"configs\"]\n        })\n        \n        if(len(prediction[0]) < 3):\n            class_name = model_data[\"configs\"][\"base_class\"]\n            predictions[class_name] = prediction[0][0]\n            try:\n                prob_str = str(prediction[0][0]*100)[0:5]\n            except Exception as wrong: \n                  prob_str = str(prediction[0][0]*100)\n            to_print  += \"{0} => {1}%; \\n\".format(class_name, prob_str)\n        else:\n            to_print+= \"{}: \\n\".format(model_data[\"configs\"][\"name\"])\n            for i in range(0, len(prediction[0])):\n                try:\n                    prob_str = str(prediction[0][i]*100)[0:5]\n                except Exception as wrong: \n                    prob_str = str(prediction[0][i]*100)\n                    \n                to_print  += \"    {0} => {1}%; \\n\".format(model_data[\"configs\"][\"classes\"][i], prob_str)\n    return to_print, predictions, raw_predictions\n\ndef secure_user_view(image, raw_predictions):\n    total = len(raw_predictions[0][\"prediction\"][0])\n    if total > 2:\n        model_config = raw_predictions[0][\"model_config\"]\n    if model_config[\"blur_sensitive_class\"]:\n        for i in range(0, total):   \n            if i in model_config[\"sensitive_classe_indexes\"] and raw_predictions[0][\"prediction\"][0][i] > model_config[\"prediction_threshold\"]:\n                image = cv2.blur(image, model_config[\"blur_ksize\"])\n                break\n    return Image.fromarray(image)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:42:01.779124Z","iopub.execute_input":"2022-10-04T17:42:01.779527Z","iopub.status.idle":"2022-10-04T17:42:01.796862Z","shell.execute_reply.started":"2022-10-04T17:42:01.779483Z","shell.execute_reply":"2022-10-04T17:42:01.795722Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"urls = [\"http://41.media.tumblr.com/e86aa471895a8b207e55158d3d2c72c7/tumblr_nj5zxiwMi61rti48uo1_1280.jpg\", \"http://i.imgur.com/3oNaAqX.jpg\"]\nsequence_bulk_prediction_from_url(urls)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:42:03.866865Z","iopub.execute_input":"2022-10-04T17:42:03.867491Z","iopub.status.idle":"2022-10-04T17:42:06.148152Z","shell.execute_reply.started":"2022-10-04T17:42:03.867417Z","shell.execute_reply":"2022-10-04T17:42:06.147546Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"Textarea(value='0', description='index', placeholder='current index goes here')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f46d0d118224dcea6b9a7428e89e78e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Current', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0a6e75c727044188b75dc9645a01cf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Prev', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e48bde699b418ca68fe83d3d71d921"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Next', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a00efcb94c24f30b608d5c072dc8da9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a3cc656600d4e2ca0e3dd1eb717f8df"}},"metadata":{}}]},{"cell_type":"code","source":"main_urls = [\n    \"https://raw.githubusercontent.com/alex000kim/nsfw_data_scraper/main/raw_data/neutral/urls_neutral.txt\",\n    \"https://raw.githubusercontent.com/EBazarov/nsfw_data_source_urls/master/raw_data/appearance_clothing_dresses/urls_appearance_clothing_dresses.txt\"\n]\ntotal = 0\ncount = 0\nall_urls = []\nfor main_url in main_urls:\n    r = requests.get(main_url)\n    urls = r.text.split(\"\\n\")\n    print(\"{0} from {1} to {2}\".format(count+1, total+1, total+1+len(urls)))\n    total = total+1+len(urls)\n    all_urls+=urls\n    count+=1\n    \nsequence_bulk_prediction_from_url(all_urls)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:46:05.988750Z","iopub.execute_input":"2022-10-04T17:46:05.989629Z","iopub.status.idle":"2022-10-04T17:46:07.144503Z","shell.execute_reply.started":"2022-10-04T17:46:05.989584Z","shell.execute_reply":"2022-10-04T17:46:07.143524Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"1 from 1 to 36839\n2 from 36840 to 41201\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Textarea(value='0', description='index', placeholder='current index goes here')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"424d696635fe48c88e4a379a5e4c8d71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Current', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88860b8979745e597d662cad52f9fc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Prev', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66aac4cc97d24b8db1ea564af9a49d56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Next', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe9f4f2dcd754e149ad98261d727fa95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2435726fa6d0413199c4bf83d7357df6"}},"metadata":{}}]},{"cell_type":"code","source":"main_urls = [\n    \"https://raw.githubusercontent.com/EBazarov/nsfw_data_source_urls/master/raw_data/appearance_clothing/urls_appearance_clothing.txt\",\n    \"https://raw.githubusercontent.com/EBazarov/nsfw_data_source_urls/master/raw_data/appearance_clothing_bodyparts-through-clothes/urls_appearance_clothing_bodyparts-through-clothes.txt\",\n    \"https://raw.githubusercontent.com/EBazarov/nsfw_data_source_urls/master/raw_data/body-parts_head_hair/urls_body-parts_head_hair.txt\"    \n]\ntotal = 0\ncount = 0\nall_urls = []\nfor main_url in main_urls:\n    r = requests.get(main_url)\n    urls = r.text.split(\"\\n\")\n    print(\"{0} from {1} to {2}\".format(count+1, total+1, total+1+len(urls)))\n    total = total+1+len(urls)\n    all_urls+=urls\n    count+=1\n    \nsequence_bulk_prediction_from_url(all_urls)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T16:41:00.486551Z","iopub.execute_input":"2022-06-07T16:41:00.48708Z","iopub.status.idle":"2022-06-07T16:41:03.248705Z","shell.execute_reply.started":"2022-06-07T16:41:00.487036Z","shell.execute_reply":"2022-06-07T16:41:03.247917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_urls = [\n    \"https://raw.githubusercontent.com/alex000kim/nsfw_data_scraper/main/raw_data/hentai/urls_hentai.txt\",\n    \"https://raw.githubusercontent.com/EBazarov/nsfw_data_source_urls/master/raw_data/artificial-images_hentai/urls_artificial-images_hentai.txt\"\n]\ntotal = 0\ncount = 0\nall_urls = []\nfor main_url in main_urls:\n    r = requests.get(main_url)\n    urls = r.text.split(\"\\n\")\n    print(\"{0} from {1} to {2}\".format(count+1, total+1, total+1+len(urls)))\n    total = total+1+len(urls)\n    all_urls+=urls\n    count+=1\n    \nsequence_bulk_prediction_from_url(all_urls)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T16:41:14.551222Z","iopub.execute_input":"2022-06-07T16:41:14.551482Z","iopub.status.idle":"2022-06-07T16:41:15.276281Z","shell.execute_reply.started":"2022-06-07T16:41:14.551445Z","shell.execute_reply":"2022-06-07T16:41:15.275347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_predict_from_path(DATASET_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T09:48:28.062778Z","iopub.execute_input":"2022-06-07T09:48:28.063316Z","iopub.status.idle":"2022-06-07T09:48:37.093289Z","shell.execute_reply.started":"2022-06-07T09:48:28.063277Z","shell.execute_reply":"2022-06-07T09:48:37.092413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_predict_at_random(\"https://random.imagecdn.app/{0}/{0}\".format(IMAGE_RES))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T16:41:20.231585Z","iopub.execute_input":"2022-06-07T16:41:20.234039Z","iopub.status.idle":"2022-06-07T16:41:23.150758Z","shell.execute_reply.started":"2022-06-07T16:41:20.233999Z","shell.execute_reply":"2022-06-07T16:41:23.150077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category = \"woman\"\n# https://loremflickr.com\n# https://lorempixel.com","metadata":{"execution":{"iopub.status.busy":"2022-06-07T16:49:42.409949Z","iopub.execute_input":"2022-06-07T16:49:42.41034Z","iopub.status.idle":"2022-06-07T16:49:42.414411Z","shell.execute_reply.started":"2022-06-07T16:49:42.4103Z","shell.execute_reply":"2022-06-07T16:49:42.413747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_predict_at_random(\"https://source.unsplash.com/category/{0}\".format(category))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T16:49:42.416283Z","iopub.execute_input":"2022-06-07T16:49:42.416596Z","iopub.status.idle":"2022-06-07T16:49:44.993027Z","shell.execute_reply.started":"2022-06-07T16:49:42.416563Z","shell.execute_reply":"2022-06-07T16:49:44.992327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unsplash collections => https://unsplash.com/s/collections/people\ncollections = [\n    \"8909560\",\n    \"1242151\", #https://unsplash.com/collections/1242151/sexy\n    \"1785701\",\n    \"8991200\", #https://unsplash.com/collections/8991200/sexy\n    \"5052004\"\n]","metadata":{"execution":{"iopub.status.busy":"2022-06-07T16:49:44.994233Z","iopub.execute_input":"2022-06-07T16:49:44.994695Z","iopub.status.idle":"2022-06-07T16:49:44.999593Z","shell.execute_reply.started":"2022-06-07T16:49:44.994639Z","shell.execute_reply":"2022-06-07T16:49:44.998821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_predict_at_random(\"https://source.unsplash.com/collection/{}\".format(collections[0]))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T16:49:45.001163Z","iopub.execute_input":"2022-06-07T16:49:45.001476Z","iopub.status.idle":"2022-06-07T16:49:47.720237Z","shell.execute_reply.started":"2022-06-07T16:49:45.001444Z","shell.execute_reply":"2022-06-07T16:49:47.71947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_predict_at_random(\"https://source.unsplash.com/collection/{}\".format(collections[randrange(len(collections)-1)]))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T16:51:24.735778Z","iopub.execute_input":"2022-06-07T16:51:24.736339Z","iopub.status.idle":"2022-06-07T16:51:28.007218Z","shell.execute_reply.started":"2022-06-07T16:51:24.736303Z","shell.execute_reply":"2022-06-07T16:51:28.006248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### main processing functions","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output, display\n\nimport ipywidgets\n\nimport cv2\n\ndef local_video_preprocess(src, wait_time=0.1):\n    stream = None\n#     if \"http\" in src:\n#         stream = CamGear(source=src, stream_mode = False, logging=True).start() # YouTube Video URL as input\n        \n    video = cv2.VideoCapture(src)\n    \n    display_handle=display(None, display_id=True)\n\n    image_widget = ipywidgets.Image(format='jpeg')\n\n    while True:\n\n        try:\n            clear_output(wait=True)\n            if \"http\" in src:\n#                 frame = stream.read()\n                _, frame = video.read()\n            else:\n                _, frame = video.read()\n                \n            if frame is None:\n                video.release()\n                break\n            lines, columns, _ =  frame.shape\n            frame = cv2.resize(frame, (int(columns/1.5), int(lines/1.5))) \n            image_widget.value = cv2.imencode('.jpeg', frame)[1].tobytes()\n            imageRGB = cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n            image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n            to_print, predictions, raw_predictions = sequence_predict_raw(np.array([image_resized]))\n            print(to_print)\n#             print(secure_user_view(image_resized, raw_predictions))\n            display(image_widget)\n            time.sleep(wait_time)\n        except KeyboardInterrupt:\n            video.release()\n            break","metadata":{"execution":{"iopub.status.busy":"2022-06-07T17:02:18.447672Z","iopub.execute_input":"2022-06-07T17:02:18.447991Z","iopub.status.idle":"2022-06-07T17:02:18.457399Z","shell.execute_reply.started":"2022-06-07T17:02:18.447949Z","shell.execute_reply":"2022-06-07T17:02:18.456739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Local video preprocessing","metadata":{}},{"cell_type":"code","source":"url = \"https://instagram.fabj4-1.fna.fbcdn.net/v/t50.16885-16/10000000_2212202748956557_6988754337939055544_n.mp4?efg=eyJ2ZW5jb2RlX3RhZyI6InZ0c192b2RfdXJsZ2VuLjcyMC5pZ3R2LmJhc2VsaW5lIiwicWVfZ3JvdXBzIjoiW1wiaWdfd2ViX2RlbGl2ZXJ5X3Z0c19vdGZcIl0ifQ&_nc_ht=instagram.fabj4-1.fna.fbcdn.net&_nc_cat=101&_nc_ohc=GR3CTwAaW4MAX8hWAL7&edm=ALQROFkBAAAA&vs=369312178565606_3600404313&_nc_vs=HBksFQAYJEdJQ1dtQUNOendXWC1Oc0hBTGpqVTljS0MtMWdidlZCQUFBRhUAAsgBABUAGCRHTW9TMUJDS3RrckhvdU1IQUxBWDg5VmtuUUJfYnZWQkFBQUYVAgLIAQAoABgAGwGIB3VzZV9vaWwBMRUAACbw4KHu2N%2BGQBUCKAJDMywXQEzu2RaHKwIYEmRhc2hfYmFzZWxpbmVfMV92MREAdewHAA%3D%3D&ccb=7-5&oe=62A1DE63&oh=00_AT-JVw8vpSzcLyFKhdjgiMqGOKtR9FbOhBJwGeC_Occytw&_nc_sid=30a2ef\"\nlocal_video_preprocess(url, 0.5)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:04:00.491546Z","iopub.execute_input":"2022-06-07T18:04:00.491832Z","iopub.status.idle":"2022-06-07T18:20:32.2252Z","shell.execute_reply.started":"2022-06-07T18:04:00.491801Z","shell.execute_reply":"2022-06-07T18:20:32.224437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_links = [\n    \"https://instagram.fabj4-1.fna.fbcdn.net/v/t50.2886-16/277264867_308902054518062_7041975200412646161_n.mp4?efg=eyJ2ZW5jb2RlX3RhZyI6InZ0c192b2RfdXJsZ2VuLjcyMC5jbGlwcy5iYXNlbGluZSIsInFlX2dyb3VwcyI6IltcImlnX3dlYl9kZWxpdmVyeV92dHNfb3RmXCJdIn0&_nc_ht=instagram.fabj4-1.fna.fbcdn.net&_nc_cat=102&_nc_ohc=nHW3_OTPaCsAX_V9dQ1&edm=ALQROFkBAAAA&vs=479413740502820_3851548042&_nc_vs=HBksFQAYJEdPTzVoaEF1M1RyZDhSZ0JBQkc3dElFaUg3cGhicV9FQUFBRhUAAsgBABUAGCRHRjMtaGhDNkNFbFdaMmdCQU56V05wcXhTT1luYnFfRUFBQUYVAgLIAQAoABgAGwAVAAAm7tD6p8%2B1tj8VAigCQzMsF0A%2BAAAAAAAAGBJkYXNoX2Jhc2VsaW5lXzFfdjERAHX%2BBwA%3D&ccb=7-5&oe=62A22036&oh=00_AT_CbmMIL3FkQXCvCUidfaWN6phH6nzegw3XKQgUk7N5bA&_nc_sid=30a2ef\"\n]","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:20:32.227253Z","iopub.execute_input":"2022-06-07T18:20:32.227533Z","iopub.status.idle":"2022-06-07T18:20:32.231632Z","shell.execute_reply.started":"2022-06-07T18:20:32.227496Z","shell.execute_reply":"2022-06-07T18:20:32.230744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"local_video_preprocess(video_links[len(video_links)-1], 0.5)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T17:51:44.274993Z","iopub.execute_input":"2022-06-07T17:51:44.275258Z","iopub.status.idle":"2022-06-07T17:53:08.039222Z","shell.execute_reply.started":"2022-06-07T17:51:44.275218Z","shell.execute_reply":"2022-06-07T17:53:08.038481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for video_link in video_links:\n    try:\n        local_video_preprocess(video_link)\n        break\n    except Exception as wrong: \n        pass","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:25:47.511125Z","iopub.execute_input":"2022-06-07T10:25:47.511914Z","iopub.status.idle":"2022-06-07T10:25:48.29672Z","shell.execute_reply.started":"2022-06-07T10:25:47.511873Z","shell.execute_reply":"2022-06-07T10:25:48.295821Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"local_video_preprocess(\"sex-3.mp4\", 0.3)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T17:43:00.943648Z","iopub.execute_input":"2022-06-07T17:43:00.943983Z","iopub.status.idle":"2022-06-07T17:47:30.94398Z","shell.execute_reply.started":"2022-06-07T17:43:00.943951Z","shell.execute_reply":"2022-06-07T17:47:30.943212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prepared_data = {\n    \"test\":{\n        \"local_prep_start\": 1,\n        \"local_prep_end\": 35,\n        \"base_name\": \"test-\"\n    },\n    \"sex-trip\":{\n        \"local_prep_start\": 1,\n        \"local_prep_end\": 35,\n        \"base_name\": \"sex-trip-\"\n    },\n    \"porn\":{\n        \"local_prep_start\": 1,\n        \"local_prep_end\": 3,\n        \"base_name\": \"porn-\"\n    },\n    \"sex\":{\n        \"local_prep_start\": 1,\n        \"local_prep_end\": 5,\n        \"base_name\": \"sex-\"\n    },\n    \"normal\":{\n        \"local_prep_start\": 1,\n        \"local_prep_end\": 7,\n        \"base_name\": \"normal-\"\n    },\n    \"normal-sexy\":{\n        \"local_prep_start\": 1,\n        \"local_prep_end\": 10,\n        \"base_name\": \"normal-sexy-\"\n    },\n    \"sexy-woman\":{\n        \"local_prep_start\": 1,\n        \"local_prep_end\": 13,\n        \"base_name\": \"sexy-woman-\"\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:23:31.198318Z","iopub.execute_input":"2022-06-06T22:23:31.198891Z","iopub.status.idle":"2022-06-06T22:23:31.205776Z","shell.execute_reply.started":"2022-06-06T22:23:31.19885Z","shell.execute_reply":"2022-06-06T22:23:31.204938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key in prepared_data.keys():\n    base_name = prepared_data[key][\"base_name\"]\n    local_prep_start = prepared_data[key][\"local_prep_start\"]\n    local_prep_end = prepared_data[key][\"local_prep_end\"]\n    for i in range(local_prep_start-1, local_prep_end-1):\n        try:\n            local_video_preprocess(\"assets/{0}{1}.mp4\".format(base_name, i))\n        except Exception as wrong: \n            continue","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:23:34.40791Z","iopub.execute_input":"2022-06-06T22:23:34.408448Z","iopub.status.idle":"2022-06-06T22:23:35.343778Z","shell.execute_reply.started":"2022-06-06T22:23:34.408412Z","shell.execute_reply":"2022-06-06T22:23:35.343127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:44:50.973710Z","iopub.execute_input":"2022-09-15T17:44:50.974064Z","iopub.status.idle":"2022-09-15T17:44:56.404962Z","shell.execute_reply.started":"2022-09-15T17:44:50.974030Z","shell.execute_reply":"2022-09-15T17:44:56.403937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:45:47.789664Z","iopub.execute_input":"2022-09-15T17:45:47.789948Z","iopub.status.idle":"2022-09-15T17:45:47.796397Z","shell.execute_reply.started":"2022-09-15T17:45:47.789917Z","shell.execute_reply":"2022-09-15T17:45:47.795707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip freeze","metadata":{"execution":{"iopub.status.busy":"2022-09-15T17:46:18.989295Z","iopub.execute_input":"2022-09-15T17:46:18.989842Z","iopub.status.idle":"2022-09-15T17:46:23.340303Z","shell.execute_reply.started":"2022-09-15T17:46:18.989806Z","shell.execute_reply":"2022-09-15T17:46:23.339253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:52:45.59193Z","iopub.execute_input":"2022-06-06T21:52:45.592163Z","iopub.status.idle":"2022-06-06T21:52:45.622675Z","shell.execute_reply.started":"2022-06-06T21:52:45.592135Z","shell.execute_reply":"2022-06-06T21:52:45.621994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:52:46.778877Z","iopub.execute_input":"2022-06-06T21:52:46.779574Z","iopub.status.idle":"2022-06-06T22:06:09.078262Z","shell.execute_reply.started":"2022-06-06T21:52:46.779511Z","shell.execute_reply":"2022-06-06T22:06:09.077563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:06:17.310903Z","iopub.execute_input":"2022-06-06T22:06:17.311191Z","iopub.status.idle":"2022-06-06T22:06:54.208055Z","shell.execute_reply.started":"2022-06-06T22:06:17.311144Z","shell.execute_reply":"2022-06-06T22:06:54.207378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}