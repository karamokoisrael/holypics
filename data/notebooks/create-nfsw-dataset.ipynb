{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Create nfsw dataset","metadata":{}},{"cell_type":"markdown","source":"## Resolve depencencies","metadata":{}},{"cell_type":"code","source":"!pip install fake_useragent\n!pip install imutils\n!pip install gdown\n!pip install kaggle --user\n!pip install gdown\n!pip install pyngrok flask\n# !pip install tensorflowjsimport json","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-11T13:39:17.842153Z","iopub.execute_input":"2022-10-11T13:39:17.843230Z","iopub.status.idle":"2022-10-11T13:40:52.950569Z","shell.execute_reply.started":"2022-10-11T13:39:17.843167Z","shell.execute_reply":"2022-10-11T13:40:52.948025Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting fake_useragent\n  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: fake_useragent\n  Building wheel for fake_useragent (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fake_useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=d6097715cc6242c410b977e761c01b99a67591aa29b4e0f67398f56c9ec1e485\n  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\nSuccessfully built fake_useragent\nInstalling collected packages: fake_useragent\nSuccessfully installed fake_useragent-0.1.11\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting imutils\n  Downloading imutils-0.5.4.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25858 sha256=462c7a2403cf544abf84288ccf8e62051fabac89153ecded71d13b1fc61c7be2\n  Stored in directory: /root/.cache/pip/wheels/86/d7/0a/4923351ed1cec5d5e24c1eaf8905567b02a0343b24aa873df2\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting gdown\n  Downloading gdown-4.5.1.tar.gz (14 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.7.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.6.15.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nBuilding wheels for collected packages: gdown\n  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14933 sha256=53bb08aa76be5b4bb122d8e19817f69207c78e662fd27fc61c3d51b44eb7fb93\n  Stored in directory: /root/.cache/pip/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\nSuccessfully built gdown\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: kaggle in /opt/conda/lib/python3.7/site-packages (1.5.12)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.8.2)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle) (6.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from kaggle) (4.64.0)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.15.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle) (2022.6.15.2)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.26.12)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.28.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (2.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: gdown in /opt/conda/lib/python3.7/site-packages (4.5.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.6.15.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.12)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pyngrok\n  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m745.3/745.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: flask in /opt/conda/lib/python3.7/site-packages (2.2.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from pyngrok) (6.0)\nRequirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.7/site-packages (from flask) (2.1.2)\nRequirement already satisfied: Werkzeug>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from flask) (2.2.2)\nRequirement already satisfied: click>=8.0 in /opt/conda/lib/python3.7/site-packages (from flask) (8.0.4)\nRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.7/site-packages (from flask) (3.1.2)\nRequirement already satisfied: importlib-metadata>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from flask) (4.12.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->flask) (4.3.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->flask) (3.8.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=3.0->flask) (2.1.1)\nBuilding wheels for collected packages: pyngrok\n  Building wheel for pyngrok (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=934dead54390b7b0c386bd0e3748c49db8b5738de9d387a39eef4ef0a15e1098\n  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\nSuccessfully built pyngrok\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-5.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import main packages","metadata":{}},{"cell_type":"code","source":"import gdown\nimport zipfile\nfrom pathlib import Path\nfrom urllib.request import urlopen\nimport uuid\nimport requests\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport hashlib\nimport sys\nimport random\nimport os\nimport tensorflow_hub as hub\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom fake_useragent import UserAgent\nfrom matplotlib.widgets import Button\nimport datetime\nfrom tensorflow.keras import layers\nimport pathlib\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.applications import imagenet_utils\nfrom imutils.object_detection import non_max_suppression\nfrom PIL import Image\nimport scipy\nimport numpy as np\nimport argparse\nimport imutils\nimport time\nimport cv2\nimport requests\nfrom IPython.display import clear_output\nfrom io import BytesIO\nfrom IPython.display import display, clear_output\n#from ipywidgets import interact\n#import ipywidgets as widgets\nfrom PIL import ImageFilter\nfrom bs4 import *\nimport uuid\nfrom IPython.display import display, Markdown, clear_output, FileLink, FileLinks\nfrom IPython.display import Image as IImage \nimport ipywidgets as widgets\nfrom PIL import Image\nimport pandas as pd\nimport gdown\nfrom random import randrange\nimport ipywidgets as widgets\nimport shutil\nfrom io import BytesIO\nimport json\nimport time\nimport mimetypes\nfrom ipywidgets import GridspecLayout, Layout, Button, HBox, VBox, HTML, Image as IpywidgetsImage\nimport functools","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:40:52.957602Z","iopub.execute_input":"2022-10-11T13:40:52.958046Z","iopub.status.idle":"2022-10-11T13:41:03.477880Z","shell.execute_reply.started":"2022-10-11T13:40:52.958004Z","shell.execute_reply":"2022-10-11T13:41:03.475928Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Kaggle api","metadata":{}},{"cell_type":"code","source":"credentials = {\"username\":\"jamesdame\",\"key\":\"157e2681cd07fe2460010b340d5a7504\"}\nkaggle_key_store='kaggle.json'\nwith open(kaggle_key_store, 'w', encoding='utf-8') as f:\n    json.dump(credentials, f, ensure_ascii=False, indent=4)\n\n!rm -rf /root/.kaggle     # when I created the folder, it says the file or dir already exits\n!mkdir /root/.kaggle        # successful\n!mv kaggle.json /root/.kaggle/kaggle.json    # not sure if I have to use full destination path, I previously only used /root/.kaggle and it failed. Don't have time to validate this thought.\n!ls /root/.kaggle/kaggle.json\n!chmod 600 /root/.kaggle/kaggle.json","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:41:03.480148Z","iopub.execute_input":"2022-10-11T13:41:03.481667Z","iopub.status.idle":"2022-10-11T13:41:09.162785Z","shell.execute_reply.started":"2022-10-11T13:41:03.481611Z","shell.execute_reply":"2022-10-11T13:41:09.160886Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/root/.kaggle/kaggle.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Declare global variables","metadata":{}},{"cell_type":"code","source":"dwd_url = \"https://drive.google.com/uc?id=1h1CeZ_tU5FhuSm4EvkLk1zqbHUOgPMuV\"\ndwd_file_name = \"nsfw-content-moderation-data.zip\"\ndwd_dir = dwd_file_name.replace(\".zip\", \"\")\n# paths = os.listdir(dwd_dir+\"/raw_data\")\nDATA_CLASSES = [\"sexy\", \"porn\", \"hentai\", \"neutral\"]\nDATA_ROOT_PATH = \"./data\"\nRAW_DATA_DIR = os.path.join(dwd_dir, \"raw_data\")\nDATA_DIR = os.path.join(DATA_ROOT_PATH, \"images\")\nDATASET_PATH = DATA_DIR\nDATASET_DUMP_PATH = \"./dump\"\nIMAGE_RES = 224\nCLEAN = True\nCSV_DATASET_PATH = os.path.join(DATA_ROOT_PATH, \"data.csv\")\nDATASET_NAME = \"nsfw-content-moderation\"","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:41:09.165939Z","iopub.execute_input":"2022-10-11T13:41:09.166378Z","iopub.status.idle":"2022-10-11T13:41:09.176557Z","shell.execute_reply.started":"2022-10-11T13:41:09.166332Z","shell.execute_reply":"2022-10-11T13:41:09.174788Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Create main functions","metadata":{}},{"cell_type":"code","source":"dump_dir = DATASET_DUMP_PATH\ndef preview_images_from_directory(path=DATASET_PATH, group=True):\n    dimensions=(IMAGE_RES, IMAGE_RES)\n    data_dir = path\n    clean_up_data_dir(data_dir)\n    images_path = []\n    \n    if(group):\n        data_sub_directories = os.listdir(data_dir)\n        for data_sub_directory in data_sub_directories:\n#             print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))\n            for current_dir in os.listdir(os.path.join(data_dir, data_sub_directory)):\n                images_path.append(os.path.join(data_sub_directory, current_dir))\n    else:\n        try:\n            for current_dir in os.listdir(data_dir):\n                images_path.append(os.path.join(data_dir, current_dir))\n        except Exception as wrong:\n            pass\n\n    if not group:\n        data_dir = \".\"\n        \n    current = 0        \n    output = widgets.Output()\n    next_button = widgets.Button(description='Next')\n    prev_button = widgets.Button(description='Prev')\n    display_current_button = widgets.Button(description='Current')\n    current_index_text = widgets.Textarea(\n        value=str(current),\n        placeholder='current index goes here',\n        description='index',\n        disabled=False\n    )\n    \n    display(current_index_text, display_current_button, prev_button, next_button, output)\n    \n    def default_action():\n        global current\n        with output:\n            clear_output()\n            print(\"{0}: {1}/{2}\".format(images_path[current].split(\"/\")[0], current+1, len(images_path)))\n            image = cv2.imread(os.path.join(data_dir, images_path[current]))\n            # imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n            imageRGB = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n            image_resized = cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA)/255\n            \n            current_image = Image.fromarray(cv2.resize(imageRGB, dimensions, interpolation = cv2.INTER_AREA))\n            display(current_image)\n            \n    def on_next_button_clicked(_):\n        global current\n        if current+2 > len(images_path):\n            return None\n        current+=1\n        default_action()\n\n\n    def on_prev_button_clicked(_):\n        global current\n        if current-1 < 0:\n            return None\n        current-=1\n        default_action()\n        \n        \n    def on_current_index_change(_):\n        update_index_change(current_index_text.value)\n\n    def update_index_change(indexString):\n        global current\n        try:\n            current = int(indexString)\n            default_action()\n        except Exception as wrong:\n            pass\n\n    next_button.on_click(on_next_button_clicked)\n    prev_button.on_click(on_prev_button_clicked)\n    display_current_button.on_click(on_current_index_change)\n    current_index_text.on_displayed(update_index_change(str(current)))\n    \n    \n    \n    \ndef order_images(main_dir, start=-1, end=-1, figsize=(30, 30), dimensions=(IMAGE_RES, IMAGE_RES)):\n    %matplotlib inline\n    from IPython.display import display, Markdown, clear_output\n    from IPython.display import Image as IImage \n    import ipywidgets as widgets\n\n    current  =  0\n    del_dir = os.path.join(main_dir, \".ipynb_checkpoints\")\n    !rm -r $del_dir\n    if start == -1 and end == -1:\n        images_path = os.listdir(main_dir)\n    elif start != -1 and end == -1:\n        images_path = os.listdir(main_dir)[start:len(os.listdir(main_dir))]\n    elif start == -1 and end != -1:\n        images_path = os.listdir(main_dir)[0:end]\n    else:\n        images_path = os.listdir(main_dir)\n        \n    next_button = widgets.Button(description='Next')\n    prev_button = widgets.Button(description='Prev')\n    move_button = widgets.Button(description='Move')\n    class_names = os.listdir(DATASET_PATH)\n    moving_paths = []\n\n    path_selector = widgets.SelectMultiple(\n        options=class_names,\n        value=[],\n        description='Fruits',\n        disabled=False\n    )\n    output = widgets.Output()\n    display(prev_button, next_button, output, path_selector, move_button)\n\n    def on_next_button_clicked(_):\n        global current\n        if current+2 > len(images_path):\n            return None\n        moving_paths = []\n        with output:\n            current+=1\n            clear_output()\n            print(\"{0}/{1}\".format(current+1, len(images_path)))\n            pil_img = IImage(filename=os.path.join(main_dir, images_path[current]), width = dimensions[0], height=dimensions[1])\n            display(pil_img)\n\n    def on_prev_button_clicked(_):\n        global current\n        if current-1 < 0:\n            return None\n        moving_paths = []\n        with output:\n            current-=1\n            clear_output()\n            print(\"{0}/{1}\".format(current+1, len(images_path)))\n            pil_img = IImage(filename=os.path.join(main_dir, images_path[current]), width = dimensions[0], height=dimensions[1])\n            display(pil_img)\n    def on_move_button_clicked(_):\n        with output:\n            print(path_selector.value)\n            for current_path in path_selector.value:\n                os.system(\"cp '{0}' '{1}'\".format(os.path.join(main_dir, DATASET_PATH+\"/\"+images_path[current]), current_path))\n\n    next_button.on_click(on_next_button_clicked)\n    prev_button.on_click(on_prev_button_clicked)\n    move_button.on_click(on_move_button_clicked)\n\ndef clean_up_data_dir(data_dir):\n    data_sub_directories = os.listdir(data_dir)\n    for data_sub_directory in data_sub_directories:\n        path_to_delete = os.path.join(data_dir, data_sub_directory, \".*\")\n        !rm -r $path_to_delete\n\n    !rm -r $data_dir/.ipynb_checkpoints\n    !rm -r $data_dir/.DS_Store\n\n# CREATE FOLDER\ndef folder_create(images, given_folder_name=\"\"):\n    try:\n        folder_name = os.path.join(dump_dir, input(\"Enter Folder Name:- \") if given_folder_name == \"\" else given_folder_name)\n        # folder creation\n        os.mkdir(folder_name)\n \n    # if folder exists with that name, ask another name\n    except:\n        print(\"Folder Exist with that name!\")\n        folder_create()\n \n    # image downloading start\n    download_images(images, folder_name)\n \n \n# DOWNLOAD ALL IMAGES FROM THAT URL\ndef download_images(images, folder_name):\n   \n    # initial count is zero\n    count = 0\n \n    # print total images found in URL\n    print(f\"Total {len(images)} Image Found!\")\n \n    # checking if images is not zero\n    if len(images) != 0:\n        for i, image in enumerate(images):\n            # From image tag ,Fetch image Source URL\n \n                        # 1.data-srcset\n                        # 2.data-src\n                        # 3.data-fallback-src\n                        # 4.src\n \n            # Here we will use exception handling\n \n            # first we will search for \"data-srcset\" in img tag\n            try:\n                # In image tag ,searching for \"data-srcset\"\n                image_link = image[\"src\"]\n                 \n            # then we will search for \"data-src\" in img\n            # tag and so on..\n            except:\n                try:\n                    # In image tag ,searching for \"data-src\"\n                    image_link = image[\"data-src\"]\n                except:\n                    try:\n                        # In image tag ,searching for \"data-fallback-src\"\n                        image_link = image[\"data-fallback-src\"]\n                    except:\n                        try:\n                            # In image tag ,searching for \"src\"\n                            image_link = image[\"data-srcset\"]\n \n                        # if no Source URL found\n                        except:\n                            pass\n \n            # After getting Image Source URL\n            # We will try to get the content of image\n            try:\n                print(\"Downloading image: {0}/{1}; store => {2}\".format(count, len(images), folder_name))\n                r = requests.get(image_link).content\n                try:\n \n                    # possibility of decode\n                    r = str(r, 'utf-8')\n                except UnicodeDecodeError:\n \n                    # After checking above condition, Image Download start\n                    with open(f\"{folder_name}/images{i+1}.jpg\", \"wb+\") as f:\n                        f.write(r)\n \n                    # counting number of image downloaded\n                    count += 1\n            except:\n                pass\n \n        # There might be possible, that all\n        # images not download\n        # if all images download\n        if count == len(images):\n            print(\"All Images Downloaded!\")\n             \n        # if all images not download\n        else:\n            print(f\"Total {count} Images Downloaded Out of {len(images)}\")\n \n# MAIN FUNCTION START\ndef download_images_from_url(url, given_folder_name=\"\"):\n    if url == None or ( url.find(\"http\") == -1 and url.find(\"www\") == -1 ):\n        return\n    # content of URL\n    ua = UserAgent()\n\n    # Get list of user agents.\n\n\n    # headers = {'User-Agent': ua.random}\n    # r = requests.get(url, headers=headers)\n    r = requests.get(url)\n    print(url)\n    print(r)\n    # Parse HTML Code\n    soup = BeautifulSoup(r.text, 'html.parser')\n \n    # find all images in URL\n    images = soup.findAll('img')\n \n    # Call folder create function\n    folder_create(images, given_folder_name)\n\ndef remove_duplicates(dir, include_src=False):\n    hashMap = {}\n    # List to store deleted files\n    deletedFiles = []\n    source_dup_file = []\n    filelist = os.listdir(dir)\n    for f in filelist:\n        f = os.path.join(dir, f)\n        key = hashFile(f)\n        # If key already exists, it deletes the file\n        if key in hashMap.keys():\n            deletedFiles.append(f)\n            if include_src:\n                try:\n                    index = source_dup_file.index(key)\n                except Exception as e:\n                    source_dup_file.append(key)\n            os.remove(f)\n        else:\n            hashMap[key] = f\n    if include_src:\n        for key in source_dup_file:\n            deletedFiles.append(f)\n            os.remove(hashMap[key])\n            \n    if len(deletedFiles) != 0:  \n        for deleted_file in deletedFiles:\n            print('Deleted Files {0}'.format(deleted_file))\n        print(\"total deleted => {}\".format(len(deletedFiles)))\n    else:\n        print('No duplicate files found')\n    \n\ndef remove_small_files(dir, min_size=5):\n    for root, _, files in os.walk(dir):\n        for f in files:\n            fullpath = os.path.join(root, f)\n            try:\n                if os.path.getsize(fullpath) < min_size * 1024:   #set file size in kb\n                    print(fullpath)\n                    os.remove(fullpath)\n            except Exception as e:\n                print(\"Error\" + fullpath)\n\ndef rename_all_files(dir):\n    for root, _, files in os.walk(dir):\n        for f in files:\n            fullpath = os.path.join(root, f)\n            try:\n                filename, file_extension = os.path.splitext(fullpath)\n                newname = str(uuid.uuid1())+\".\"+file_extension\n                os.rename(fullpath, os.path.join(dir, newname))\n           \n            except Exception as e:\n                print(e)\n                print(\"Error\" + fullpath)\n                \ndef delete_unreadable_images(dir):\n    for root, _, files in os.walk(dir):\n        for f in files:\n            fullpath = os.path.join(root, f)\n            try:\n                img = Image.open(fullpath)\n            except Exception as e:\n                os.system(\"rm {}\".format(fullpath))\n                print(\"Removing => \" + fullpath)\n\ndef remove_randomly_dir_files(dir, limit=2, percentage=0):\n    files = os.listdir(dir)\n\n    if(percentage != 0):\n        limit = int((percentage * len(files)) / 100)\n\n    print(\"Total files found : {}\".format(len(files)))\n    deleted_indexes = [-1]\n    count = 0\n    if limit >= len(files):\n        print(\"limit >= len(files)\")\n        return \n\n    for i in range(0, limit):\n        if len(deleted_indexes) > limit:\n            print(\"len(deleted_index) > limit\")\n            break\n\n        random_index = -1\n\n        while ( random_index in deleted_indexes) == True:\n            random_index = random.randint(0, len(files)-1)\n\n        deleted_indexes.append(random_index)\n        count+=1\n\n        print(\"deleting {0}/{1}; index => {2}\".format(i+1, limit, random_index))\n        os.remove(os.path.join(dir, files[random_index]))\n\n    print(\"Total deleted files {}\".format(count))\n    print(\"Total files remaining {}\".format(len(os.listdir(dir))))\n    \ndef hashFile(filename):\n    # For large files, if we read it all together it can lead to memory overflow, So we take a blocksize to read at a time\n    BLOCKSIZE = 65536\n    hasher = hashlib.md5()\n    with open(filename, 'rb') as file:\n        # Reads the particular blocksize from file\n        buf = file.read(BLOCKSIZE)\n        while(len(buf) > 0):\n            hasher.update(buf)\n            buf = file.read(BLOCKSIZE)\n    return hasher.hexdigest()\n\ndef predict_at_random_download(base_url=\"https://picsum.photos/{0}/{0}\".format(IMAGE_RES), store=DATASET_PATH, group=True):\n    selected_class = class_names[0]\n    selected_image = []\n    again_button = widgets.Button(description='Again')\n    download_button = widgets.Button(description='Download')\n    class_selector = widgets.Dropdown(\n        options=class_names,\n        value=selected_class,\n        description='Select a class',\n        disabled=False,\n    )\n\n    output = widgets.Output()\n    display(again_button, class_selector, download_button, output)\n\n    def on_again_button_clicked(_):\n        global selected_image\n        with output:\n            clear_output()\n            to_print, image = predict_single_image_from_url(base_url)\n            selected_image = image\n            print(to_print)\n            display(image)\n            \n    def on_download_button_clicked(_):\n        global selected_image\n        global selected_class\n        with output:\n            try:\n                if group:  \n                    export_path = \"{}.jpg\".format(os.path.join(store, selected_class, str(uuid.uuid1())))\n                else:\n                    export_path = \"{}.jpg\".format(os.path.join(store, str(uuid.uuid1())))\n                print(\"selected class => \", selected_class)\n                print(\"export path => \", export_path)\n                selected_image.save(export_path)\n                local_file = FileLink(export_path, result_html_prefix=\"Click here to download model: \")\n                display(local_file)\n            except Exception as wrong:\n                print(\"error while moving file to =>\", selected_class)\n                print(wrong)\n    def on_class_change(change):\n        global selected_class\n        try:\n            selected_class = class_names[change[\"new\"][\"index\"]]\n        except Exception as wrong:\n            pass\n        \n\n    with output:\n        clear_output()\n        to_print, image = predict_single_image_from_url(base_url)\n        selected_image = image\n        print(to_print)\n        display(image)\n    \n    again_button.on_click(on_again_button_clicked)\n    download_button.on_click(on_download_button_clicked)\n    class_selector.observe(on_class_change)\n    \ndef download_collection_from_unsplash(collection_id = \"500522\", selected_class=\"\", store=\"\", group=True, perPage=10, page=1, image_width=IMAGE_RES, image_height=IMAGE_RES, fit=\"crop\", download_link=False):\n    api_key = '3E1O5xqWI-Opz3W81XdmIvZwPJ2qFTHggE5YUxZysDg'\n    url = \"https://api.unsplash.com/collections/{0}/photos?page={1}&per_page={2}\".format(collection_id, page, perPage)\n    # ua = UserAgent()\n    # headers = {'User-Agent': ua.random, 'Authorization': \"Client-ID {}\".format(api_key)}\n    headers = {\n        'Authorization': \"Client-ID {}\".format(api_key),\n        }\n    images = []\n    count = 0\n    total = 0\n    total_pages = 1\n    current_page = page\n    \n    try:\n        response = requests.get(url.format(collection_id, current_page, perPage), headers=headers)\n        total = int(response.headers['X-Total'])\n        \n        while(total_pages * perPage < total):\n            total_pages+=1\n    except Exception as wrong:\n        print(\"count error\")\n        print(wrong)\n        \n    while current_page <= total_pages:\n        print(\"processing page \", current_page, \"/\", total_pages)\n        try:\n            response = requests.get(url.format(collection_id, current_page, perPage), headers=headers)\n            response_json = response.json()\n            for image_data in response_json:\n                print(\"downloading image \",count+1, \"/\", total)\n                try:\n                    if group:  \n                        export_path = \"{}.jpg\".format(os.path.join(store, selected_class, str(uuid.uuid1())))\n                    else:\n                        export_path = \"{}.jpg\".format(os.path.join(store, str(uuid.uuid1())))\n                    image_response = requests.get(image_data[\"urls\"][\"raw\"]+\"&w={0}&h={1}&fit={2}\".format(image_width, image_height, fit))\n                    #raw,full, regular, small, thumb, small_s3    \n                    image = np.asarray(bytearray(image_response.content), dtype=\"uint8\")\n                    imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n                    imageRGB = cv2.cvtColor(imageBGR , cv2.COLOR_BGR2RGB)\n                    cv2.imwrite(export_path, imageBGR)\n                    if download_link:\n                        local_file = FileLink(export_path, result_html_prefix=\"Click here to download: \")\n                        display(local_file)            \n                except Exception as wrong:\n                    print(wrong)\n                    print(\"error while downloading image\")\n                count+=1\n        except Exception as wrong:\n            print(\"error while loading collections photos\")\n        current_page+=1\n        \ndef dwd_images(destination, source_file=\"*.txt\", limitPoint = -1, count_set=0):\n    total = len(open(Path(source_file)).readlines())\n    image_input_file = open(source_file, \"r\")\n    count = count_set\n    image_input_file = [image_input_fileS for image_input_fileS in image_input_file]\n    ids = str(uuid.uuid1())\n    \n    if limitPoint != -1 and len(image_input_file) > limitPoint:\n        image_url_list = image_input_file[count_set:limitPoint]\n        \n    for url in image_url_list:\n        count+=1\n        try:\n            currentId = str(uuid.uuid1())\n            file = destination+\"/\"+ids+currentId+\".jpg\"\n            response = urlopen(url, timeout = 3)\n            with open(file, 'wb') as f:\n                f.write(response.read())\n            f.close()\n            \n            print(\"{0} / {1} success => {2} path => {3}\".format(count, total, url, file))\n\n        except Exception as wrong: \n            print(\"{0} / {1} req failure => {2} : {3}\".format(count, total, url, wrong))\n            pass\n        \n        \n        \ndef image_gallery_from_directory(path=DATASET_PATH, group=True, default_page=0):\n    dimensions=(IMAGE_RES, IMAGE_RES)\n    data_dir = path\n#     clean_up_data_dir(data_dir)\n    images_path = []\n    if(group):\n        data_sub_directories = os.listdir(data_dir)\n        for data_sub_directory in data_sub_directories:\n#             print(\"found {0} for class {1}\".format(len(os.listdir(os.path.join(data_dir, data_sub_directory))), data_sub_directory))\n            for current_dir in os.listdir(os.path.join(data_dir, data_sub_directory)):\n                images_path.append(os.path.join(data_sub_directory, current_dir))\n    else:\n        try:\n            for current_dir in os.listdir(data_dir):\n                images_path.append(os.path.join(data_dir, current_dir))\n        except Exception as wrong:\n            pass\n\n    if not group:\n        data_dir = \".\"\n        \n    current = default_page\n    output = widgets.Output()\n    next_button = widgets.Button(description='Next')\n    prev_button = widgets.Button(description='Prev')\n    display_current_button = widgets.Button(description='Current')\n    current_index_text = widgets.Textarea(\n        value=str(current),\n        placeholder='current index goes here',\n        description='index',\n        disabled=False\n    )\n    \n    delete_button = widgets.Button(description='Delete')\n    \n    display(current_index_text, display_current_button, prev_button, next_button, output)\n    \n    deleted_images = []\n    \n    def get_button(description):\n        return widgets.Button(description=description, style=dict(\n                                            font_style='italic',\n                                            font_weight='bold',\n                                            font_variant=\"small-caps\",\n                                            text_color='red',\n                                            text_decoration='underline',\n                                            font_size=20,\n#                                             width=100\n                    ))\n    items_per_page = 24\n    num_rows = 4\n    total_pages = int(len(images_path)/items_per_page)\n   \n        \n    def default_action():\n\n        global current\n#         global images_path\n        with output:\n            clear_output()\n            print(\"{0}: {1}/{2}\".format(images_path[current*items_per_page].split(\"/\")[0], current, total_pages))\n            num_images = 0\n            images_line_1 =  []\n            buttons_line_1 =  []\n            images_line_2 =  []\n            buttons_line_2 =  []\n            images_line_3 =  []\n            buttons_line_3 =  []\n            images_line_4 =  []\n            buttons_line_4 =  []\n            while num_images < items_per_page:\n                try:\n                    image_path = os.path.join(data_dir, images_path[current*items_per_page+num_images])\n                    cat = images_path[current*items_per_page+num_images].split(\"/\")[0]\n                    file = open(image_path, \"rb\")\n                    image = file.read()\n                    image = IpywidgetsImage(\n                        value=image,\n                        format='jpeg',\n                        width=160,\n                        height=140,\n                    )\n                    \n                    def on_current_delete_button_click(_, path=\"\"):\n                        os.remove(path)\n                        default_action()\n\n                    button = get_button(\"Delete {0} {1} forever\".format(cat, num_images))\n                    button.on_click(functools.partial(on_current_delete_button_click, path=image_path))\n                    \n\n                    if num_images < items_per_page/num_rows:\n                        images_line_1.append(image)\n                        buttons_line_1.append(button)\n                    elif num_images < items_per_page/num_rows*2:\n                        images_line_2.append(image)\n                        buttons_line_2.append(button)\n                    elif num_images < items_per_page/num_rows*3:\n                        images_line_3.append(image)\n                        buttons_line_3.append(button)\n                    else:\n                        images_line_4.append(image)\n                        buttons_line_4.append(button)\n                        \n                except Exception as wrong:\n#                     print(wrong)\n                    pass\n                num_images+=1\n                \n            display(HBox(images_line_1))\n            display(HBox(buttons_line_1))\n            display(HBox(images_line_2))\n            display(HBox(buttons_line_2))\n            display(HBox(images_line_3))\n            display(HBox(buttons_line_3))\n            display(HBox(images_line_4))\n            display(HBox(buttons_line_4))\n            display(current_index_text, display_current_button, prev_button, next_button, output)\n            \n    def on_next_button_clicked(_):\n        global current\n        if current+2 > len(images_path):\n            return None\n        current+=1\n        default_action()\n\n\n    def on_prev_button_clicked(_):\n        global current\n        if current-1 < 0:\n            return None\n        current-=1\n        default_action()\n        \n        \n    def on_current_index_change(_):\n        update_index_change(current_index_text.value)\n\n    def update_index_change(indexString):\n        global current\n        try:\n            current = int(indexString)\n            default_action()\n        except Exception as wrong:\n            pass\n\n    next_button.on_click(on_next_button_clicked)\n    prev_button.on_click(on_prev_button_clicked)\n    display_current_button.on_click(on_current_index_change)\n    current_index_text.on_displayed(update_index_change(str(current)))","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:41:09.179369Z","iopub.execute_input":"2022-10-11T13:41:09.179825Z","iopub.status.idle":"2022-10-11T13:41:09.596614Z","shell.execute_reply.started":"2022-10-11T13:41:09.179790Z","shell.execute_reply":"2022-10-11T13:41:09.595044Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Download dataset","metadata":{}},{"cell_type":"code","source":"gdown.download(dwd_url, dwd_file_name, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:41:09.599519Z","iopub.execute_input":"2022-10-11T13:41:09.601146Z","iopub.status.idle":"2022-10-11T13:41:10.341488Z","shell.execute_reply.started":"2022-10-11T13:41:09.601088Z","shell.execute_reply":"2022-10-11T13:41:10.339935Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1h1CeZ_tU5FhuSm4EvkLk1zqbHUOgPMuV\nTo: /kaggle/working/nsfw-content-moderation-data.zip\n100%|██████████| 59.9M/59.9M [00:00<00:00, 221MB/s]\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'nsfw-content-moderation-data.zip'"},"metadata":{}}]},{"cell_type":"code","source":"with zipfile.ZipFile(dwd_file_name,\"r\") as zip_ref:\n    zip_ref.extractall(\"./\")","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:41:10.342677Z","iopub.execute_input":"2022-10-11T13:41:10.343005Z","iopub.status.idle":"2022-10-11T13:41:12.895021Z","shell.execute_reply.started":"2022-10-11T13:41:10.342974Z","shell.execute_reply":"2022-10-11T13:41:12.893655Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"##  Get current dataset version","metadata":{}},{"cell_type":"code","source":"!cp -a /kaggle/input/nsfw-content-moderation/. $DATA_ROOT_PATH","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:41:12.896567Z","iopub.execute_input":"2022-10-11T13:41:12.896915Z","iopub.status.idle":"2022-10-11T13:42:22.053031Z","shell.execute_reply.started":"2022-10-11T13:41:12.896884Z","shell.execute_reply":"2022-10-11T13:42:22.048637Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"\n## Create main directories","metadata":{}},{"cell_type":"code","source":"!mkdir $DATA_ROOT_PATH\n!mkdir $DATA_DIR\n!touch $CSV_DATASET_PATH","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:42:22.057775Z","iopub.execute_input":"2022-10-11T13:42:22.058540Z","iopub.status.idle":"2022-10-11T13:42:25.381721Z","shell.execute_reply.started":"2022-10-11T13:42:22.058454Z","shell.execute_reply":"2022-10-11T13:42:25.380351Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘./data’: File exists\nmkdir: cannot create directory ‘./data/images’: File exists\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## See available classes","metadata":{}},{"cell_type":"code","source":"!ls $dwd_dir/raw_data","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-11T13:42:25.385809Z","iopub.execute_input":"2022-10-11T13:42:25.386966Z","iopub.status.idle":"2022-10-11T13:42:26.491360Z","shell.execute_reply.started":"2022-10-11T13:42:25.386907Z","shell.execute_reply":"2022-10-11T13:42:26.489772Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":" age_college\n age_mature\n age_milf\n age_teen\n amateur\n amateur_self-shots\n appearance\n appearance_appearance-modification\n appearance_appearance-modification_piercings\n appearance_appearance-modification_tattoos\n appearance_clothing\n appearance_clothing_bodyparts-through-clothes\n appearance_clothing_bottomless\n appearance_clothing_clothed-naked-pair\n appearance_clothing_dresses\n appearance_clothing_shoes\n appearance_clothing_stockings\n appearance_clothing_swimwear\n appearance_clothing_tight-clothing\n appearance_clothing_topless\n appearance_clothing_underwear\n appearance_clothing_underwear_panties\n appearance_clothing_underwear_thongs\n appearance_clothing_uniforms-outfits\n appearance_clothing_uniforms-outfits_cosplay\n appearance_clothing_upskirt-downblouse\n appearance_expressions\n appearance_pose\n'appearance_wet-&-messy'\n artificial-images\n artificial-images_fictional-characters-shows\n artificial-images_hentai\n artificial-images_my-little-pony\n artificial-images_photoshop\n body-parts_head_hair\n body-parts_head_hair_blonde\n body-parts_head_hair_brunette\n body-parts_head_hair_dyed\n body-parts_head_hair_hairstyle\n body-parts_head_hair_redhead\n body-parts_head_lips-mouth\n body-parts_lower-body\n body-parts_lower-body_ass\n body-parts_lower-body_ass_large\n body-parts_lower-body_asshole\n body-parts_lower-body_feet\n body-parts_lower-body_gap\n body-parts_lower-body_genitalia_penis\n body-parts_lower-body_genitalia_penis_large\n body-parts_lower-body_genitalia_penis_small\n body-parts_lower-body_genitalia_vulva\n body-parts_lower-body_genitalia_vulva_hair\n body-parts_lower-body_genitalia_vulva_labia\n body-parts_lower-body_hips\n body-parts_lower-body_legs\n body-parts_upper-body\n body-parts_upper-body_breasts\n body-parts_upper-body_breasts_from-an-angle\n body-parts_upper-body_breasts_implants\n body-parts_upper-body_breasts_large\n body-parts_upper-body_breasts_nipples\n body-parts_upper-body_breasts_small\n body-traits_complexion_freckles\n body-traits_complexion_light-skin\n body-traits_complexion_tan\n body-traits_traits\n body-traits_traits_flexible\n body-traits_traits_pregnant\n body-traits_types_bbw\n body-traits_types_chubby\n body-traits_types_curvy\n body-traits_types_petite\n body-traits_types_skinny-thin\n classic-vintage\n communities\n communities_identification\n communities_personals\n communities_role-play\n cum-play_cum\n cum-play_cum_creampie\n cum-play_cum_cum-shot\n cum-play_cum_cum-shot_bukkake\n cum-play_cum_cum-shot_facial\n cum-play_cum_swallowing\n cum-play_female\n drawings\n ethnicity\n ethnicity_asian\n ethnicity_black\n ethnicity_euro\n ethnicity_indian\n ethnicity_japanese\n exhibition\n exhibition_gonewild\n exhibition_public\n fetish\n fetish_bdsm\n fetish_bdsm_bondage\n'fetish_bdsm_domination-&-submission'\n'fetish_bdsm_domination-&-submission_femdom'\n fetish_drugs\n fetish_role-enactment\n fetish_role-enactment_age-play\n fetish_role-enactment_furry\n fetish_role-enactment_pet-play\n fetish_role-enactment_rape-abuse\n fetish_watersports\n general-categories\n general-categories_artistic-or-borderline-porn\n general-categories_desktop-wallpaper\n general-categories_gifs\n general-categories_humorous\n general-categories_p.o.v.\n general-categories_passionate\n general-categories_porn-for-women\n general-categories_videos\n groups\n groups_alt\n groups_athlete\n groups_camgirl\n groups_celebrity\n groups_country\n groups_nerd\n groups_pornstar\n groups_pornstar_pornstar-lookalike\n groups_religious\n groups_specific-personality\n hentai\n illegal-taboo\n illegal-taboo_bestiality\n illegal-taboo_incest\n illegal-taboo_voyeurism\n lgbt_bisexual\n lgbt_crossdressing\n lgbt_gay\n lgbt_lesbian\n lgbt_transgender\n lgbt_transsexual\n literary\n locations_man-made\n locations_nature\n locations_nature_beach\n neutral\n non-porn-nsfw\n porn\n sex\n sex_anal\n sex_anal_gaping\n sex_anal_rimming\n sex_breasts\n sex_fisting\n sex_group\n sex_group_large-group\n sex_group_swinging\n sex_group_threesome\n sex_insertion\n sex_interracial\n sex_masturbation\n sex_oral\n sex_orgasm\n sex_toys\n sexy\n specific-actor-actress\n specific-company\n wtf\n","output_type":"stream"}]},{"cell_type":"code","source":"cat = \"neutral\"\npath = \"{0}/raw_data/{1}/urls_{1}.txt\".format(dwd_dir, cat)\n!wc -l $path","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:42:26.493458Z","iopub.execute_input":"2022-10-11T13:42:26.493863Z","iopub.status.idle":"2022-10-11T13:42:27.649579Z","shell.execute_reply.started":"2022-10-11T13:42:26.493819Z","shell.execute_reply":"2022-10-11T13:42:27.647930Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"36837 nsfw-content-moderation-data/raw_data/neutral/urls_neutral.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Initialize dataset creation","metadata":{}},{"cell_type":"code","source":"for path in DATA_CLASSES:\n    try:\n        data_path = os.path.join(dwd_dir, \"raw_data\", path)\n        store_path = os.path.join(DATA_DIR, path)\n        !mkdir $store_path\n        if CLEAN:\n            !rm -r $store_path/* \n        files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n        dwd_images(store_path, source_file=os.path.join(data_path, files[0]), count_set=2002, limitPoint=36837)\n    except Exception as wrong: \n        print(wrong)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Delete corrupted files","metadata":{}},{"cell_type":"code","source":"data_sub_directories = os.listdir(DATASET_PATH)\nfor data_sub_directory in data_sub_directories:   \n    delete_unreadable_images(os.path.join(DATASET_PATH, data_sub_directory))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-11T11:29:28.095320Z","iopub.status.idle":"2022-10-11T11:29:28.095809Z","shell.execute_reply.started":"2022-10-11T11:29:28.095587Z","shell.execute_reply":"2022-10-11T11:29:28.095614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove duplicates","metadata":{}},{"cell_type":"code","source":"data_sub_directories = os.listdir(DATASET_PATH)\nfor data_sub_directory in data_sub_directories:   \n    remove_duplicates(os.path.join(DATASET_PATH, data_sub_directory))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-11T11:29:28.097972Z","iopub.status.idle":"2022-10-11T11:29:28.098400Z","shell.execute_reply.started":"2022-10-11T11:29:28.098192Z","shell.execute_reply":"2022-10-11T11:29:28.098210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove small files","metadata":{}},{"cell_type":"code","source":"data_sub_directories = os.listdir(DATASET_PATH)\nfor data_sub_directory in data_sub_directories:   \n    remove_small_files(os.path.join(DATASET_PATH, data_sub_directory))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-11T11:29:28.099681Z","iopub.status.idle":"2022-10-11T11:29:28.100125Z","shell.execute_reply.started":"2022-10-11T11:29:28.099891Z","shell.execute_reply":"2022-10-11T11:29:28.099911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Edit data relationship","metadata":{}},{"cell_type":"code","source":"classes_meta = {\n#     \"female_nudity\": {\n#         \"childs\":[\"general_nsfw\"]\n#     },\n    \n#     \"general_nsfw\":{\n#         \"childs\": [\"female_nudity\"]\n#     },\n    \n#     \"female_underwear\":{\n#         \"childs\": [\"male_underwear\"]\n#     },\n#     \"male_underwear\":{\n#         \"childs\": [\"female_underwear\"]\n#     }\n}\n\n\ndata_dir = DATASET_PATH\ndata = []\ndata_sub_directories = os.listdir(data_dir)\nfor data_sub_directory in data_sub_directories:\n    files = os.listdir(os.path.join(data_dir, data_sub_directory))\n    for file in files:\n        file_meta = {}\n        file_meta[\"filenames\"]=os.path.join(data_sub_directory, file)\n        \n        class_childs = []\n        if data_sub_directory in classes_meta and USE_DATA_RELATIONSHIP:\n            class_childs = classes_meta[data_sub_directory][\"childs\"]\n\n        for current_class_name in data_sub_directories:\n            if current_class_name == data_sub_directory or current_class_name in class_childs:\n                file_meta[current_class_name] = str(1).replace(\".0\", \"\")                        \n            else:\n                file_meta[current_class_name] = str(0)\n        data.append(file_meta)\n\ndf = pd.DataFrame(data)\ndf.to_csv(CSV_DATASET_PATH, encoding='utf-8', index=False)\n\nprint(\"done => \", len(data))\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2022-10-11T11:29:28.102117Z","iopub.status.idle":"2022-10-11T11:29:28.102727Z","shell.execute_reply.started":"2022-10-11T11:29:28.102411Z","shell.execute_reply":"2022-10-11T11:29:28.102440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preview Dataset","metadata":{}},{"cell_type":"code","source":"preview_images_from_directory(DATASET_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-10-11T13:39:09.448737Z","iopub.execute_input":"2022-10-11T13:39:09.449433Z","iopub.status.idle":"2022-10-11T13:39:09.567881Z","shell.execute_reply.started":"2022-10-11T13:39:09.449302Z","shell.execute_reply":"2022-10-11T13:39:09.566088Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/420841845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreview_images_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'preview_images_from_directory' is not defined"],"ename":"NameError","evalue":"name 'preview_images_from_directory' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"## updating kaggle dataset version ","metadata":{}},{"cell_type":"code","source":"!kaggle datasets status $DATASET_NAME\n!kaggle datasets metadata -p $DATA_ROOT_PATH $DATASET_NAME\nsave_path = 'updated_data_{}'.format(time.time())\n!kaggle datasets version -p $DATA_ROOT_PATH -m $save_path --dir-mode zip","metadata":{"execution":{"iopub.status.busy":"2022-10-11T11:29:28.106779Z","iopub.status.idle":"2022-10-11T11:29:28.107204Z","shell.execute_reply.started":"2022-10-11T11:29:28.107003Z","shell.execute_reply":"2022-10-11T11:29:28.107024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download images from server","metadata":{}},{"cell_type":"code","source":"domain = \"https://mgx-api.karamokoisrael.tech\"","metadata":{"execution":{"iopub.status.busy":"2022-10-09T19:03:26.348305Z","iopub.execute_input":"2022-10-09T19:03:26.348743Z","iopub.status.idle":"2022-10-09T19:03:26.354861Z","shell.execute_reply.started":"2022-10-09T19:03:26.348708Z","shell.execute_reply":"2022-10-09T19:03:26.353532Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"req = requests.get(domain+\"/items/feedbacks?filter[moderation_classes][_nnull]=true&filter[downloaded_for_dataset][_eq]=false&filter[image][_nnull]=true\")\ndata = req.json()[\"data\"]","metadata":{"execution":{"iopub.status.busy":"2022-10-09T19:03:26.716404Z","iopub.execute_input":"2022-10-09T19:03:26.717677Z","iopub.status.idle":"2022-10-09T19:03:27.582083Z","shell.execute_reply.started":"2022-10-09T19:03:26.717632Z","shell.execute_reply":"2022-10-09T19:03:27.580791Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"count = 0\ntotal = len(data)\nfor fileData in data: \n    try:\n        file =  \"data/images/{0}/hp-{1}.jpg\" .format(fileData[\"moderation_classes\"][0], fileData[\"image\"])\n        print(\"processing {0}/{1} => {2}\".format(count+1, total, file))\n        dwd_url = \"{0}/file/{1}\".format(domain, fileData[\"image\"])\n        image_response = requests.get(dwd_url)  \n        image = np.asarray(bytearray(image_response.content), dtype=\"uint8\")\n        imageBGR = cv2.imdecode(image, cv2.IMREAD_COLOR)\n        imageRGB = cv2.cvtColor(imageBGR , cv2.COLOR_BGR2RGB)\n        cv2.imwrite(file, imageBGR)            \n        local_file = FileLink(file, result_html_prefix=\"Download {0}/{1}\".format(count+1, total))\n        display(local_file)  \n        count+=1\n    except Exception as wrong:\n        print(\"error for {0}/{1} => {2}\".format(count+1, total, wrong))\n        count+=1\n        pass","metadata":{"execution":{"iopub.status.busy":"2022-10-09T19:03:27.584764Z","iopub.execute_input":"2022-10-09T19:03:27.585157Z","iopub.status.idle":"2022-10-09T19:03:28.290984Z","shell.execute_reply.started":"2022-10-09T19:03:27.585106Z","shell.execute_reply":"2022-10-09T19:03:28.289891Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"processing 1/1 => data/images/neutral/hp-8794f052-6c2f-43df-b943-7bb757b267d3.jpg\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/data/images/neutral/hp-8794f052-6c2f-43df-b943-7bb757b267d3.jpg","text/html":"Download 1/1<a href='data/images/neutral/hp-8794f052-6c2f-43df-b943-7bb757b267d3.jpg' target='_blank'>data/images/neutral/hp-8794f052-6c2f-43df-b943-7bb757b267d3.jpg</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"## File Manager","metadata":{}},{"cell_type":"code","source":"!jupyter labextension list\n!pip uninstall jupyterlab_widgets -y\n!pip install jupyterlab_widgets","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-11T14:05:34.747219Z","iopub.execute_input":"2022-10-11T14:05:34.747813Z","iopub.status.idle":"2022-10-11T14:05:56.284510Z","shell.execute_reply.started":"2022-10-11T14:05:34.747762Z","shell.execute_reply":"2022-10-11T14:05:56.282268Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"JupyterLab v3.2.9\n/opt/conda/share/jupyter/labextensions\n        nbdime-jupyterlab v2.1.1 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        jupyterlab-jupytext v1.3.8+dev \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupytext)\n        jupyterlab_pygments v0.2.2 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupyterlab_pygments)\n        jupyter-threejs v2.4.0 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, pythreejs)\n        bqplot v0.5.37 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, bqplot)\n        jupyter-vuetify v1.8.4 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        jupyter-vue v1.7.0 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        jupyter-matplotlib v0.9.0 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        jupyterlab-datawidgets v7.1.2 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        jupyter-webrtc v0.6.0 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        jupyter-leaflet v0.17.1 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        catboost-widget v1.0.0 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        jupyterlab-plotly v5.10.0 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        @jupyter-widgets/jupyterlab-manager v3.1.1 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupyterlab_widgets)\n        @jupyterlab/server-proxy v3.2.1 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        @jupyterlab/git v0.37.1 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupyterlab-git)\n        @krassowski/jupyterlab-lsp v3.10.2 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, jupyterlab-lsp)\n        @pyviz/jupyterlab_pyviz v2.2.1 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m (python, pyviz_comms)\n\nOther labextensions (built into JupyterLab)\n   app dir: /opt/conda/share/jupyter/lab\n        beatrix_jupyterlab v3.1.7 \u001b[31mdisabled\u001b[0m \u001b[32mOK\u001b[0m\n        plotlywidget v4.14.3 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        tensorflow_model_analysis v0.35.0 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n        wit-widget v1.8.1 \u001b[32menabled\u001b[0m \u001b[32mOK\u001b[0m\n\n\nDisabled extensions:\n    beatrix_jupyterlab (all plugins)\n\nBuild recommended, please run `jupyter lab build`:\n    tensorflow_model_analysis needs to be included in build\nFound existing installation: jupyterlab-widgets 1.1.1\nUninstalling jupyterlab-widgets-1.1.1:\n  Successfully uninstalled jupyterlab-widgets-1.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting jupyterlab_widgets\n  Downloading jupyterlab_widgets-3.0.3-py3-none-any.whl (384 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.1/384.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: jupyterlab_widgets\nSuccessfully installed jupyterlab_widgets-3.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"image_gallery_from_directory(default_page=53)","metadata":{"execution":{"iopub.status.busy":"2022-10-11T14:13:08.802615Z","iopub.execute_input":"2022-10-11T14:13:08.803096Z","iopub.status.idle":"2022-10-11T14:13:09.335784Z","shell.execute_reply.started":"2022-10-11T14:13:08.803061Z","shell.execute_reply":"2022-10-11T14:13:09.334593Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"hentai: 53/279\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xe2\\x0cX…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d891b9e18f04695aecc62bed24d8689"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Button(description='Delete hentai 0 forever', style=ButtonStyle(font_weight='bold')), Button(de…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43180270fa87493b9f69edc410b8f5a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x02X\\x02X\\x00\\x00\\xff\\xdb\\x00C\\x00\\x…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"934a94b0f2784ddb9cdf89bfa1ce0814"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Button(description='Delete porn 6 forever', style=ButtonStyle(font_weight='bold')), Button(desc…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eefc0c3b986b4c108953816af133ef05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xfe\\x00;CREATO…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cde98ffed954d03ab4552304783e707"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Button(description='Delete porn 12 forever', style=ButtonStyle(font_weight='bold')), Button(des…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b62acb58faa3435fa76918890656f335"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00\\xf0\\x00\\xf0\\x00\\x00\\xff\\xdb\\x00C…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6ffc2d6daf64c0ea237d111300230d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Button(description='Delete porn 18 forever', style=ButtonStyle(font_weight='bold')), Button(des…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98b1d26735c7458584485fcb8d0d474c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Textarea(value='53', description='index', placeholder='current index goes here')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c462ffba9254a8b8780ac0816754e58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Current', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c406a80e2b3440cea722df2a73f4b93b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Prev', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0921f4fc51849939793d6034408e48b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Next', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be2ee05b2af04ed39a571faa0dedf124"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output(msg_id='9d2f3e7e-33c9-4382-a74c-a6cb36160f1d')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85d8b8d03e7d4a838994b0807c942106"}},"metadata":{}}]},{"cell_type":"markdown","source":"## updating kaggle dataset version ","metadata":{}},{"cell_type":"code","source":"!kaggle datasets status $DATASET_NAME\n!kaggle datasets metadata -p $DATA_ROOT_PATH $DATASET_NAME\nsave_path = 'updated_data_{}'.format(time.time())\n!kaggle datasets version -p $DATA_ROOT_PATH -m $save_path --dir-mode zip","metadata":{},"execution_count":null,"outputs":[]}]}